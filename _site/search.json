[
  {
    "objectID": "Take-home_Ex/Take-home_Ex03/Take-home_Ex03.html",
    "href": "Take-home_Ex/Take-home_Ex03/Take-home_Ex03.html",
    "title": "Take-home Exercise 3",
    "section": "",
    "text": "See link below for additional details on this challenge!\nhttps://vast-challenge.github.io/2024/index.html"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex03/Take-home_Ex03.html#project-vast-challenge-2024---mini-challenge-2",
    "href": "Take-home_Ex/Take-home_Ex03/Take-home_Ex03.html#project-vast-challenge-2024---mini-challenge-2",
    "title": "Take-home Exercise 3",
    "section": "",
    "text": "See link below for additional details on this challenge!\nhttps://vast-challenge.github.io/2024/index.html"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex03/Take-home_Ex03.html#project-overview",
    "href": "Take-home_Ex/Take-home_Ex03/Take-home_Ex03.html#project-overview",
    "title": "Take-home Exercise 3",
    "section": "Project Overview",
    "text": "Project Overview\nIn Oceanus, the routine life of islanders is defined by the movements of commercial fishing vessels, which usually indicate a healthy economy. However, this routine was disrupted when SouthSeafood Express Corp was caught fishing illegally, causing a significant scandal in the fishing community. FishEye International, a non-profit dedicated to combating illegal fishing, is collecting and analyzing data on ship movements and shipping records to understand this disruption better. They have compiled this data into CatchNet: the Oceanus Knowledge Graph. FishEye’s analysts need assistance in creating analytical capabilities to make sense of this data and better understand local commercial fishing behavior."
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex03/Take-home_Ex03.html#project-objectives",
    "href": "Take-home_Ex/Take-home_Ex03/Take-home_Ex03.html#project-objectives",
    "title": "Take-home Exercise 3",
    "section": "Project Objectives",
    "text": "Project Objectives\nThis study aims to use visual analytics to understand patterns of groups in the knowledge graph. This will endeavour to:\n\nFishEye analysts have long wanted to better understand the flow of commercially caught fish through Oceanus’s many ports. But as they were loading data into CatchNet, they discovered they had purchased the wrong port records. They wanted to get the ship off-load records, but they instead got the port-exit records (essentially trucks/trains leaving the port area). Port exit records do not include which vessel that delivered the products. Given this limitation, develop a visualization system to associate vessels with their probable cargos. Which vessels deliver which products and when? What are the seasonal trends and anomalies in the port exit records?\nDevelop visualizations that illustrate the inappropriate behavior of SouthSeafood Express Corp vessels. How do their movement and catch contents compare to other fishing vessels? When and where did SouthSeafood Express Corp vessels perform their illegal fishing? How many different types of suspicious behaviors are observed? Use visual evidence to justify your conclusions.\nTo support further Fisheye investigations, develop visual analytics workflows that allow you to discover other vessels engaging in behaviors similar to SouthSeafood Express Corp’s illegal activities? Provide visual evidence of the similarities.\nHow did fishing activity change after SouthSeafood Express Corp was caught? What new behaviors in the Oceanus commercial fishing community are most suspicious and why?"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex03/Take-home_Ex03.html#installing-packages",
    "href": "Take-home_Ex/Take-home_Ex03/Take-home_Ex03.html#installing-packages",
    "title": "Take-home Exercise 3",
    "section": "Installing Packages",
    "text": "Installing Packages\nLet’s install the required packages for addressing the challenges.\n\n\nShow the code\npacman::p_load(jsonlite, tidygraph, ggraph, igraph,\n               visNetwork, graphlayouts, tidyverse, sf, leaflet, plotly, gganimate,\n               gifski)"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex03/Take-home_Ex03.html#importing-the-data",
    "href": "Take-home_Ex/Take-home_Ex03/Take-home_Ex03.html#importing-the-data",
    "title": "Take-home Exercise 3",
    "section": "Importing the data",
    "text": "Importing the data\nLet’s import the data given for the challenges\n\nmc2_data &lt;- fromJSON(\"data/MC2.json\")\ngeog &lt;- st_read(\"data/Oceanus Geography.geojson\")\n\nReading layer `Oceanus Geography' from data source \n  `C:\\sarthakjn1\\ISSS608-VAA\\Take-home_Ex\\Take-home_Ex03\\data\\Oceanus Geography.geojson' \n  using driver `GeoJSON'\nSimple feature collection with 29 features and 7 fields\nGeometry type: GEOMETRY\nDimension:     XY\nBounding box:  xmin: -167.0654 ymin: 38.07452 xmax: -163.2723 ymax: 40.67775\nGeodetic CRS:  WGS 84\n\n\n\nData Preparation\nFirst we have the data from the Transponder pings. Let us isolate out that data so that we can use it in the future as and when required.\n\n\nShow the code\nmc2_ping &lt;-\n  as_tibble(mc2_data$links) %&gt;%\n  distinct() %&gt;%\n  mutate(source =\n           as.character(source),\n         target=\n           as.character(target),\n         type = as.character(type),\n         time = as.character(time),\n         arrivaldate = as.character(as.Date(time, format = \"%Y-%m-%dT%H:%M:%S\"))\n  ) %&gt;%\n  filter((source != target) & type == 'Event.TransportEvent.TransponderPing') %&gt;%\n  select(source, target, type, time, dwell, arrivaldate)"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex03/Take-home_Ex03.html#investigating-southseafoodcorp-vessels",
    "href": "Take-home_Ex/Take-home_Ex03/Take-home_Ex03.html#investigating-southseafoodcorp-vessels",
    "title": "Take-home Exercise 3",
    "section": "Investigating SouthSeaFoodCorp Vessels",
    "text": "Investigating SouthSeaFoodCorp Vessels\nNext, let us prepare the data for visualizing the pings of SouthSeaFood Corp Vessels. They are snappersnatcher7be and roachrobberdb6. Here we should be able to identify some suspicious behaviour.\n\nSnappersnatcher7beRoachrobberdb6\n\n\n\n\nShow the code\nmc2ping_nodes &lt;- mc2_data$nodes\nmc2ping_nodes &lt;- mc2ping_nodes %&gt;% filter(type == 'Entity.Location.Region' | type =='Entity.Location.City' | type == 'Entity.Location.Point' | id == 'snappersnatcher7be' | id == 'roachrobberdb6') %&gt;% rename(Location = id) \nmc2ping_nodes &lt;- mc2ping_nodes %&gt;% mutate(id = seq_len(nrow(mc2ping_nodes)))\n\nmc2ping_edges &lt;- mc2_ping %&gt;%\n  group_by(source, target) %&gt;%\n    summarise(weight = n()) %&gt;%\n  filter(source!=target) %&gt;%\n  filter(target == \"snappersnatcher7be\") %&gt;%\n  filter(weight &gt; 1) %&gt;%\n  ungroup()\n\nmc2ping_edges_agg &lt;- mc2ping_edges %&gt;%\n  left_join(mc2ping_nodes, by= c(\"source\" = \"Location\")) %&gt;%\n  rename(from = id) %&gt;%\n  left_join(mc2ping_nodes, by= c(\"target\" = \"Location\")) %&gt;%\n  rename(to = id)\nsnappergraph &lt;- tbl_graph(nodes = mc2ping_nodes,\n                           edges = mc2ping_edges_agg,\n                           directed = TRUE)\n\nsnappergraph &lt;- snappergraph %&gt;% \n  activate(nodes) %&gt;% \n  filter(!node_is_isolated())\ng &lt;- snappergraph %&gt;% \n  ggraph(layout = \"nicely\") +\n  geom_edge_link(aes(width=weight), \n                 alpha=0.8) +\n   scale_edge_width(range = c(0.1,5)) +\n  geom_node_point(aes(colour = Location, size = 5)) +\n  geom_node_text(aes(label = Location), vjust = 1.5)\ng + theme_graph()\n\n\n\n\n\n\n\n\n\n\n\n\n\nShow the code\nmc2ping_roach_edges &lt;- mc2_ping %&gt;%\n  group_by(source, target) %&gt;%\n    summarise(weight = n()) %&gt;%\n  filter(source!=target) %&gt;%\n  filter(target == \"roachrobberdb6\") %&gt;%\n  filter(weight &gt; 1) %&gt;%\n  ungroup()\n\nmc2ping_roach_edges_agg &lt;- mc2ping_roach_edges %&gt;%\n  left_join(mc2ping_nodes, by= c(\"source\" = \"Location\")) %&gt;%\n  rename(from = id) %&gt;%\n  left_join(mc2ping_nodes, by= c(\"target\" = \"Location\")) %&gt;%\n  rename(to = id)\n\nroachrobbergraph &lt;- tbl_graph(nodes = mc2ping_nodes,\n                           edges = mc2ping_roach_edges_agg,\n                           directed = TRUE)\nroachrobbergraph &lt;- roachrobbergraph %&gt;% \n  activate(nodes) %&gt;% \n  filter(!node_is_isolated())\ng &lt;- roachrobbergraph %&gt;% \n  ggraph(layout = \"nicely\") +\n  geom_edge_link(aes(width=weight), \n                 alpha=0.8) +\n   scale_edge_width(range = c(0.1,5)) +\n  geom_node_point(aes(colour = Location, size = 5)) +\n  geom_node_text(aes(label = Location), vjust = 1.5)\ng + theme_graph()\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nInsights:\n\n\n\n\nSnappersnatcher7be has made some visits to Ghoti Preserve and looking at the dwell time spent from the dataset there it clearly shows that a higher amount of time was spent there. Hence it could possibly be a suspicious illegal fishing activity carried out at Ghoti Preserve by snappersnatcher7be.\nRoachrobberdb6 has made frequent visits to Wrasse Beds and Nav C. This is a suspicious behaviour as the fish caught at Wrasse Beds isn’t seeming to go to the port directly for offloading but is going to Nav C and it seems it is going to be offloaded to another vessel at Nav C. This indicates a possible transshipment hapenning at point Nav C.\n\n\n\n\nPrepare data for plotting paths of vessels\n\ncentroids &lt;- st_centroid(geog)\ngeog$centroid_x &lt;- st_coordinates(centroids)[, 1]\ngeog$centroid_y &lt;- st_coordinates(centroids)[, 2]\nmc2_vessel_mov &lt;- mc2_ping %&gt;%\n  left_join(geog,\n            by = c(\"source\" = \"Name\"))\nvessel_movement_sf &lt;- mc2_vessel_mov %&gt;%\n  filter(!is.na(centroid_x) & !is.na(centroid_y)) %&gt;%\n  st_as_sf(coords = c(\"centroid_x\", \"centroid_y\"), crs = 4326)\n\nvessel_movement_sf &lt;- vessel_movement_sf %&gt;%\n  arrange(target, time)\n\n\n\nInvestigating paths of SouthSeaFoodCorp Vessels\n\nSnappersnatcher7beRoachrobberdb6\n\n\n\n\nShow the code\ngeog2 &lt;- st_read(\"data/Oceanus Geography.geojson\")\n\n\nReading layer `Oceanus Geography' from data source \n  `C:\\sarthakjn1\\ISSS608-VAA\\Take-home_Ex\\Take-home_Ex03\\data\\Oceanus Geography.geojson' \n  using driver `GeoJSON'\nSimple feature collection with 29 features and 7 fields\nGeometry type: GEOMETRY\nDimension:     XY\nBounding box:  xmin: -167.0654 ymin: 38.07452 xmax: -163.2723 ymax: 40.67775\nGeodetic CRS:  WGS 84\n\n\nShow the code\ngeog2 &lt;- st_centroid(geog2)\n\nvessel_trajectory &lt;- vessel_movement_sf %&gt;%\n  group_by(target) %&gt;%\n  summarize(do_union = FALSE) %&gt;%\n  st_cast(\"LINESTRING\")\nvessel_trajectory_selected &lt;- vessel_trajectory %&gt;%\n  filter(target == \"snappersnatcher7be\")\n\n\nggplot(data = geog2) +\n  geom_sf(data = geog2) +\n  geom_sf(data = vessel_trajectory_selected, \n          aes(color = factor(target)), \n          size = 1) +\n   geom_sf_text(aes(label = Name, geometry = geometry), size = 3, color = \"black\") +\n  theme_minimal() +\n  labs(title = \"Trajectories of snappersnacther7be\", \n  x = \"Longitude\", y = \"Latitude\", color = \"ID\")\n\n\n\n\n\n\n\n\n\n\n\n\n\nShow the code\nvessel_trajectory_selected &lt;- vessel_trajectory %&gt;%\n  filter(target == \"roachrobberdb6\")\n\n\np &lt;- ggplot(data = geog2) +\n  geom_sf(aes(geometry = geometry)) +\n  geom_sf_text(aes(label = Name, geometry = geometry), size = 3, color = \"black\") +\n  geom_sf(data = vessel_trajectory_selected, \n          aes(color = factor(target)), \n          size = 1) +\n  theme_minimal() +\n  labs(title = \"Trajectories of roachrobberdb6\", \n  x = \"Longitude\", y = \"Latitude\", color = \"ID\")\np\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nInsights:\n\n\n\n\nRoachrobberdb6 which visits Nav C and Wrasse Beds at a very high frequency suggests that these two locations should be geographically close for it to carry out possible suspicious activities. From the vessel path we can already confirm that these points are geographically close.\n\n\n\n\n\nInvestigating the illegal activities and the time when they were caught.\n\n\nShow the code\nmc2_nodes &lt;- as_tibble(mc2_data$nodes) %&gt;%\n  mutate(name = as.character(name),\n         id = as.character(id),\n         type = as.character(type),\n         date = as.character(as.Date(date)),\n         qty = as.character(as.double(qty_tons),\n         company = as.character(company)\n                            )) %&gt;%\n  select(id, name, type, date, qty, company)\n\nmc2_transaction &lt;-\n  as_tibble(mc2_data$links) %&gt;%\n  distinct() %&gt;%\n  mutate(source =\n           as.character(source),\n         target=\n           as.character(target),\n         type = as.character(type),\n         date = as.character(date)\n  ) %&gt;%\n  group_by(source, target, type) %&gt;%\n  filter((source != target) & type == 'Event.Transaction') %&gt;%\n  select(source, target, type, date)\nmc2_deliveryreport &lt;- mc2_nodes %&gt;% filter(type == 'Entity.Document.DeliveryReport')\nmc2_fish &lt;- mc2_nodes %&gt;% filter(type == 'Entity.Commodity.Fish')\nmc2_loc &lt;- mc2_nodes %&gt;% filter(type == 'Entity.Location.City')\nmc2_transaction_loc &lt;- inner_join(mc2_loc, mc2_transaction, by = c(\"id\" = \"target\"))\nmc2_transaction_fish &lt;- inner_join(mc2_fish, mc2_transaction, by = c(\"id\" = \"target\"))\nmc2_transaction_loc &lt;- inner_join(mc2_transaction_fish, mc2_transaction_loc, by = c(\"source\" = \"source\"))\nmc2_transaction_loc &lt;- inner_join(mc2_transaction_loc, mc2_deliveryreport, by = c(\"source\" = \"id\"))\nmc2_transaction_loc &lt;- mc2_transaction_loc %&gt;%\n  mutate(suspect_arrival = as.character(as.Date(date,format = \"%Y-%m-%d\") - 1),\n         suspect_arrival2 = as.character(as.Date(date,format = \"%Y-%m-%d\")),\n         month = month(date))\n\n\n\n\nShow the code\nmc2_vessels &lt;- mc2_nodes %&gt;% filter(type == 'Entity.Vessel.CargoVessel' |\n                                           type == 'Entity.Vessel.Ferry.Cargo' |\n                                      type == 'Entity.Vessel.FishingVessel' |\n                                      type == 'Entity.Vessel.Research' |\n                                      type == 'Entity.Vessel.Tour' |\n                                      type == 'Entity.Vessel.Other')\nmc2_vessels_ping &lt;- mc2_vessels %&gt;%\n  inner_join(mc2_ping, by = c(\"id\" = \"target\"))\nmc2_vessels_ping &lt;- mc2_vessels_ping %&gt;%\n  mutate(month = month(arrivaldate))\nmc2_southsea_pings &lt;- mc2_vessels_ping %&gt;% filter(company == 'SouthSeafood Express Corp')\n\nmc2_southsea_calls &lt;- mc2_southsea_pings %&gt;%\n  group_by(id, month) %&gt;%\n  summarise(totalcalls = n()) %&gt;%\n  select(id, month, totalcalls)\n\nggplot(data = mc2_southsea_calls,\n       aes(x = month, y = totalcalls, fill = id)) +\n  geom_bar(stat = \"identity\") + \n  theme_minimal()\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nInsights:\n\n\n\n\nThere are no pings by both SouthSeaFood Corp Vessels to any ports after month of May(05). This indicates a very clear possibility that SouthSeaFood Corp was caught in May.\nRoachrobberdb6 has made an irregularly high number of pings in Feb and March indicating that a high number of the suspicious activities were made by it during Feb and March.\n\n\n\n\n\nInvestigating region-wise calls for SouthSeaFood Corp Vessels\nPrepare the data for region-wise calls for SouthSeaFood Corp Vessels.\n\n\nShow the code\nmc2_southsea &lt;- inner_join(mc2_southsea_pings, geog,\n                           by = c(\"source\" = \"Name\"))\nmc2_southsea_illegalact &lt;- mc2_southsea %&gt;% filter((X.Kind != 'city') &\n                                          (X.Kind != 'Fishing Ground') )\nmc2_southsea_susp_calls &lt;- mc2_southsea %&gt;%\n  group_by(id, month, source) %&gt;%\n  summarise(totalcalls = n()) %&gt;%\n  select(id, month, source, totalcalls)\n\n\n\n\nShow the code\nggplot(data = mc2_southsea_susp_calls,\n       aes(x = month, y = totalcalls, fill = id)) +\n  facet_wrap(~ source) + \n  geom_bar(stat = \"identity\") + \n  theme_minimal()\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nInsights:\n\n\n\n\nInvestigating region wise calls validates findings from the network graph as well as the time based plots plotted earlier. There seems to be an abnormally high number of pings by Roachrobberdb6 to Wrasse Beds and Nav C during February and March. The number of pings reduced thereafter in months of April and May.\nAnother insight is snappersnatcher7be visited and spent an abnormally high amount of time at Ghoti Preserve only in Feb and March. Later months of April and May never saw any visits to Ghoti Preserve.\nThis indicates the possibility of illegal and suspicious fishing activities occuring in Feb and March for both the SouthSeaFood Corp Vessels."
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex03/Take-home_Ex03.html#investigating-fishing-vessels-at-nemo-reef-and-ghoti-preserve",
    "href": "Take-home_Ex/Take-home_Ex03/Take-home_Ex03.html#investigating-fishing-vessels-at-nemo-reef-and-ghoti-preserve",
    "title": "Take-home Exercise 3",
    "section": "Investigating Fishing Vessels at Nemo Reef and Ghoti Preserve",
    "text": "Investigating Fishing Vessels at Nemo Reef and Ghoti Preserve\nFrom this initial analysis of Snappersnatcher7be, we find that it is pinging Ghoti Preserve and spending a considerable amount of time there. This is suspicious because Ghoti Preserve is an ecological preserve and fishing here is illegal.\nFollowing a similar line of thought, let us identify the fishing vessels that spent a considerable amount of time(dwell &gt; 200000) at ecological preserves indicating that they might be possibly engaged in illegal fishing.\n\nNemo ReefGhoti Preserve\n\n\n\n\nShow the code\nmc2ping_nemo_nodes &lt;- mc2_data$nodes %&gt;% filter(id == 'Nemo Reef' | type == 'Entity.Vessel.FishingVessel') %&gt;% rename(Location = id)\nmc2ping_nemo_nodes &lt;- mc2ping_nemo_nodes %&gt;% mutate(id = seq_len(nrow(mc2ping_nemo_nodes))) \n\nmc2ping_nemo_edges &lt;- mc2_ping %&gt;%\n  group_by(source, target) %&gt;%\n    summarise(weight = max(dwell)) %&gt;%\n  filter(source!=target) %&gt;%\n  filter(source == \"Nemo Reef\") %&gt;%\n  filter(weight &gt; 200000) %&gt;%\n  ungroup()\n\nmc2ping_nemo_edges_agg &lt;- mc2ping_nemo_edges %&gt;%\n  inner_join(mc2ping_nemo_nodes, by= c(\"source\" = \"Location\")) %&gt;%\n  rename(from = id) %&gt;%\n  inner_join(mc2ping_nemo_nodes, by= c(\"target\" = \"Location\")) %&gt;%\n  rename(to = id)\n\nnemograph &lt;- tbl_graph(nodes = mc2ping_nemo_nodes,\n                           edges = mc2ping_nemo_edges_agg,\n                           directed = TRUE)\nnemograph &lt;- nemograph %&gt;% \n  activate(nodes) %&gt;% \n  filter(!node_is_isolated())\ng &lt;- nemograph %&gt;% \n  ggraph(layout = \"nicely\") +\n  geom_edge_link(aes(width=weight), \n                 alpha=0.8) +\n   scale_edge_width(range = c(0.1,5)) +\n  geom_node_point(aes(colour = company, size = 5)) +\n  geom_node_text(aes(label = Location), vjust = 2)\ng + theme_graph()\n\n\n\n\n\n\n\n\n\n\n\n\n\nShow the code\nmc2ping_ghoti &lt;- mc2_data$nodes %&gt;% filter(id == 'Ghoti Preserve' | type == 'Entity.Vessel.FishingVessel') %&gt;% rename(Location = id)\nmc2ping_ghoti_nodes &lt;- mc2ping_ghoti %&gt;% mutate(id = seq_len(nrow(mc2ping_ghoti))) \n\nmc2ping_edges &lt;- mc2_ping %&gt;%\n  group_by(source, target) %&gt;%\n    summarise(weight = max(dwell)) %&gt;%\n  filter(source!=target) %&gt;%\n  filter(source == \"Ghoti Preserve\") %&gt;%\n  filter(weight &gt; 200000) %&gt;%\n  ungroup()\n\nmc2ping_ghoti_edges_agg &lt;- mc2ping_edges %&gt;%\n  inner_join(mc2ping_ghoti_nodes, by= c(\"source\" = \"Location\")) %&gt;%\n  rename(from = id) %&gt;%\n  inner_join(mc2ping_ghoti_nodes, by= c(\"target\" = \"Location\")) %&gt;%\n  rename(to = id)\n\nghotigraph &lt;- tbl_graph(nodes = mc2ping_ghoti_nodes,\n                           edges = mc2ping_ghoti_edges_agg,\n                           directed = TRUE)\nghotigraph &lt;- ghotigraph %&gt;% \n  activate(nodes) %&gt;% \n  filter(!node_is_isolated())\ng &lt;- ghotigraph %&gt;% \n  ggraph(layout = \"nicely\") +\n  geom_edge_link(aes(width=weight), \n                 alpha=0.8) +\n   scale_edge_width(range = c(0.1,5)) +\n  geom_node_point(aes(colour = company, size = 5)) +\n  geom_node_text(aes(label = Location), vjust = 1.5)\ng + theme_graph()\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nInsights:\n\n\n\n\nbarracudabandit836, solesseker47a, redfishraider677, sailfishseeker8d5 all seem to spend a considerable amount of time at Nemo Reef. Hence these fishing vessels and the companies they belong to are the most suspicious. The behaviour of these fishing vessels need to be investigated further.\nbrilliantbandit0a1,seabassbandit9ad, fishfinderb9d, salmonsnatcher19d and several others seem to be suspicious as identified by the Network Graph based on their higher dwell times at Ghoti Preserve.\nAs such the network cllearly helps us identify vessels and companies that are suspicious by looking at higher dwell time at the ecological preserves Ghoti Preserve and Nemo Reef. Further insights can be obtained by looking at the network graph.\n\n\n\n\nObserving anomalies in Port Offloading records\nPreparing the data for investigating port offloading records\n\n\nShow the code\nmc2_nodes &lt;- as_tibble(mc2_data$nodes) %&gt;%\n  mutate(name = as.character(name),\n         id = as.character(id),\n         type = as.character(type),\n         date = as.character(as.Date(date)),\n         qty = as.character(as.double(qty_tons),\n         company = as.character(company)\n                            )) %&gt;%\n  select(id, name, type, date, qty, company)\n\nmc2_transaction &lt;-\n  as_tibble(mc2_data$links) %&gt;%\n  distinct() %&gt;%\n  mutate(source =\n           as.character(source),\n         target=\n           as.character(target),\n         type = as.character(type),\n         date = as.character(date)\n  ) %&gt;%\n  group_by(source, target, type) %&gt;%\n  filter((source != target) & type == 'Event.Transaction') %&gt;%\n  select(source, target, type, date)\n\n\n\n\nShow the code\nmc2_deliveryreport &lt;- mc2_nodes %&gt;% filter(type == 'Entity.Document.DeliveryReport')\nmc2_fish &lt;- mc2_nodes %&gt;% filter(type == 'Entity.Commodity.Fish')\nmc2_loc &lt;- mc2_nodes %&gt;% filter(type == 'Entity.Location.City')\nmc2_transaction_loc &lt;- inner_join(mc2_loc, mc2_transaction, by = c(\"id\" = \"target\"))\nmc2_transaction_fish &lt;- inner_join(mc2_fish, mc2_transaction, by = c(\"id\" = \"target\"))\nmc2_transaction_loc &lt;- inner_join(mc2_transaction_fish, mc2_transaction_loc, by = c(\"source\" = \"source\"))\nmc2_transaction_loc &lt;- inner_join(mc2_transaction_loc, mc2_deliveryreport, by = c(\"source\" = \"id\"))\nmc2_transaction_loc &lt;- mc2_transaction_loc %&gt;%\n  mutate(suspect_arrival = as.character(as.Date(date,format = \"%Y-%m-%d\") - 1),\n         suspect_arrival2 = as.character(as.Date(date,format = \"%Y-%m-%d\")),\n         month = month(date))\n\nmc2_portoffloadtotal &lt;- mc2_transaction_loc %&gt;%\n  group_by(month, id.y) %&gt;%\n  summarize(totalqty = sum(as.double(qty)),\n            totalcalls = n()) %&gt;%\n  select(id.y, month, totalqty, totalcalls)\n\nmc2_portoffload &lt;- mc2_transaction_loc %&gt;%\n  group_by(month, id.y, name.x) %&gt;%\n  summarize(totalqty = sum(as.double(qty)),\n            totalcalls = n()) %&gt;%\n  select(id.y, name.x, month, totalqty, totalcalls)\n\n\n\n\nHistogram of Cargo Offload Transactions\n\nmc2_transaction_loc &lt;- mc2_transaction_loc %&gt;% mutate(qty = as.double(qty))\n# Calculate median\nmedian_value &lt;- median(mc2_transaction_loc$qty)\n\n# Calculate Q3 and IQR\nQ3 &lt;- quantile(mc2_transaction_loc$qty, 0.75)\nIQR &lt;- IQR(mc2_transaction_loc$qty)\nupper_whisker &lt;- Q3 + 1.5 * IQR\nggplot(mc2_transaction_loc, aes(x = as.double(qty))) +\n  geom_histogram(binwidth = 5, fill = \"blue\", color = \"black\", alpha = 0.7) +\n  geom_vline(aes(xintercept = median_value), linetype = \"dotted\", color = \"red\", size = 1) +\n  geom_vline(aes(xintercept = upper_whisker), linetype = \"dotted\", color = \"red\", size = 1) +\n  labs(title = \"Histogram of Cargo offload transactions\", x = \"Quantity\", y = \"Frequency\") +\n  annotate(\"text\", x = median_value, y = Inf, label = paste(\"Median:\", round(median_value, 2)), vjust = 1, color = \"red\") +\n  annotate(\"text\", x = upper_whisker, y = Inf, label = paste(\"Upper Whisker:\", round(upper_whisker, 2)), vjust = 1, color = \"red\") +\n  theme_minimal()\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nInsights:\n\n\n\n\nRecords above the Upper Whisker of Quantity 69 tonnes need to be investigated further as they seem to be outliers. There could be possible smuggling or suspicious transshipment which has caused the cargo qty to increase substantially."
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex03/Take-home_Ex03.html#plotting-the-cargo-offload-for-various-ports-by-time",
    "href": "Take-home_Ex/Take-home_Ex03/Take-home_Ex03.html#plotting-the-cargo-offload-for-various-ports-by-time",
    "title": "Take-home Exercise 3",
    "section": "Plotting the Cargo offload for various ports by time",
    "text": "Plotting the Cargo offload for various ports by time\n\nggplot(data = mc2_portoffloadtotal,\n       aes(x = month, y = totalqty)) +\n  facet_wrap(~id.y) +\n  geom_bar(stat = \"identity\") + \n  theme_minimal()\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nInsights:\n\n\n\n\nThere is an abnormally high increase in the cargo offload quantity at City of Paackland, City of South Paackland and City of Lomark in the months August(08), September(09), October(10), November(11).\nThis coincides after SouthSeaFood Corp vessels stop pinging them in May(05). So this is possibly a illegal activity after SouthSeaFoodCorp was caught.\n\n\n\n\nDiving deep into Cargo offload as per Fish species\n\nggplot(data = mc2_portoffload,\n       aes(x = month, y = totalqty, fill = name.x)) +\n  facet_wrap(~id.y) +\n  geom_bar(stat=\"identity\") +\n  theme_minimal()\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nInsights:\n\n\n\n\nThe abnormal rise in cargo offload at City of Paackland, City of South Paackland and City of Lomark is primarily due to abnromal increase in Cod/Gadus n.specificatae and Beauvoir/Habeas pisces.\nThese fish species and the vessels that possibly carry these fish species need to be investigated further."
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex03/Take-home_Ex03.html#conclusion",
    "href": "Take-home_Ex/Take-home_Ex03/Take-home_Ex03.html#conclusion",
    "title": "Take-home Exercise 3",
    "section": "Conclusion",
    "text": "Conclusion\nWe have been able to identify some suspicious activities through this analysis. There needs to be further investigation on insights mentioned in the previous points to confirm the illegal activities and drill down on the kind of illegal activities."
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html",
    "href": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html",
    "title": "Take-home Exercise 1",
    "section": "",
    "text": "There are two major residential property market in Singapore, namely public and private housing. Public housing aims to meet the basic need of the general public with monthly household income less than or equal to S$14,000. For families with monthly household income more than S$14,000, they need to turn to the private residential market.\n\n\n\nAssuming the role of a graphical editor of a median company, this post aims to reveal the insights from private residential market and sub-markets of Singapore for the 1st quarter of 2024.\n\n\n\nTo accomplish the task, transaction data of REALIS will be used. A complete set of the private residential property transaction data from 1st January 2023 to 31st March 2024 will be used.\n\n\n\nThe data is processed by using appropriate tidyverse family of packages and the statistical graphics are prepared using ggplot2 and its extensions."
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#overview",
    "href": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#overview",
    "title": "Take-home Exercise 1",
    "section": "",
    "text": "There are two major residential property market in Singapore, namely public and private housing. Public housing aims to meet the basic need of the general public with monthly household income less than or equal to S$14,000. For families with monthly household income more than S$14,000, they need to turn to the private residential market.\n\n\n\nAssuming the role of a graphical editor of a median company, this post aims to reveal the insights from private residential market and sub-markets of Singapore for the 1st quarter of 2024.\n\n\n\nTo accomplish the task, transaction data of REALIS will be used. A complete set of the private residential property transaction data from 1st January 2023 to 31st March 2024 will be used.\n\n\n\nThe data is processed by using appropriate tidyverse family of packages and the statistical graphics are prepared using ggplot2 and its extensions."
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#loading-packages",
    "href": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#loading-packages",
    "title": "Take-home Exercise 1",
    "section": "2 Loading Packages",
    "text": "2 Loading Packages\n\npacman::p_load(ggrepel, patchwork, ggthemes, ggridges, hrbrthemes, colorspace,ggdist, tidyr, tidyverse, htmltools)"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#reading-data",
    "href": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#reading-data",
    "title": "Take-home Exercise 1",
    "section": "3 Reading Data",
    "text": "3 Reading Data\n\nrealis_data_2023Q1 &lt;- read_csv(\"data/ResidentialTransaction20240308160536.csv\")\nrealis_data_2023Q1 &lt;- mutate(realis_data_2023Q1, Quarter='2023-Q1')\nrealis_data_2023Q2 &lt;- read_csv(\"data/ResidentialTransaction20240308160736.csv\")\nrealis_data_2023Q2 &lt;- mutate(realis_data_2023Q2, Quarter='2023-Q2')\nrealis_data_2023Q3 &lt;- read_csv(\"data/ResidentialTransaction20240308161009.csv\")\nrealis_data_2023Q3 &lt;- mutate(realis_data_2023Q3, Quarter='2023-Q3')\nrealis_data_2023Q4 &lt;- read_csv(\"data/ResidentialTransaction20240308161109.csv\")\nrealis_data_2023Q4 &lt;- mutate(realis_data_2023Q4, Quarter='2023-Q4')\nrealis_data_2024Q1 &lt;- read_csv(\"data/ResidentialTransaction20240414220633.csv\")\nrealis_data_2024Q1 &lt;- mutate(realis_data_2024Q1, Quarter='2024-Q1')\n\n\nrealis_data &lt;- rbind(realis_data_2023Q1, realis_data_2023Q2, realis_data_2023Q3, realis_data_2023Q4, realis_data_2024Q1)\nrealis_data$Month &lt;- substr(realis_data$`Sale Date`,3,6)\n\n\n3.1 Identify Duplicates\n\nsum(duplicated(realis_data))\n\n[1] 0\n\n\n\n\n3.2 Identify Missing Values\n\nsum(is.na(realis_data))\n\n[1] 6\n\n\nRemoving the identified records with missing values.\n\nrealis_data &lt;- realis_data %&gt;% \n  drop_na()\nsum(is.na(realis_data))\n\n[1] 0"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#deriving-insights-based-on-visual-analysis",
    "href": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#deriving-insights-based-on-visual-analysis",
    "title": "Take-home Exercise 1",
    "section": "4 Deriving insights based on Visual Analysis",
    "text": "4 Deriving insights based on Visual Analysis\n\n4.1 Number of Properties sold for each type with previous quarters.\nAs our objective is to analyse property market in 2024 Q1, let us first compare the number of properties sold for each property type. We attempt to answer the questions: “Have the number of properties sold increased or decreased compared to the same period previous year? What about the previous quarter?”\nWe do this by creating faceted bar chart. First the ggplot(), geom_plot() are used to create a bar chart indicating number of properties of each type of sale(Sub Sale, Resale, New Sale) sold. Then we use the facet_wrap() function and passing in Property type to generate the faceted bar chart. The ggtitle(), theme(), xlab(), and ylab() functions in the ggplot2 package are then used to make aesthetic adjustments to the plot.\n\nThe plotThe code\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n# | eval: false \nggplot(realis_data, aes(x = Quarter, fill =`Type of Sale`)) + \n  geom_bar() +  \n  theme_minimal() + \n  theme(axis.text.x = element_text(angle = 45, hjust = 1)) +  \n  facet_wrap(~`Property Type`,scales = \"free_y\") + \n  ggtitle(label = \"Number of properties sold for each type per quarter\") +    ylab(\"Number of properties sold\") + xlab(\"Quarter\")\n\n\n\n\n\n\n\n\n\n\n\nObservation: Based on the plot we observe that, for semi-detached houses and terrace houses the number of properties sold in 2024 Q1 is almost same as the same period last year(2023 Q1) with slight increase compared to 2023-Q4. For executive condos there has been a significant jump of almost 300 in number of properties sold in 2024-Q1 compared to 2023-Q1. This rise can be attributed to more number of new sales as the resale and sub sales almost remained the same. For detached houses, the number of properties dropped from roughly 60 to 40. The drop was majorly due to fewer number of Resale properties sold. For Condos the number of properties in 2024-Q1 dropped to around 1900 compared to 2200 in 2023-Q1. The drop was majorly due to lower new sales. For Apartments, there was a slight rise in number of properties sold compared to 2023-Q1 due to higher new sales.\n\n\n4.2 Visualizing distribution of Unit Price of properties based on Type of Sale and Type of Area.\nAs our objective is to analyse property market in 2024 Q1, let us compare the unit price of properties based on the type of area and the type of sale. We attempt to answer the questions: “Are properties on land more expensive as compared to strata? How about comparison of prices within subsale, resale and new sales”\nWe do this by creating half eye plot. First the ggplot(), stat_halfeye(), geom_boxplot() are used to create a half eye plot and boxplot of price of properties with each type of sale. We use type of Area as fill to see how area plays a part. The ggtitle(), theme(), xlab(), and ylab() functions in the ggplot2 package are then used to make aesthetic adjustments to the plot.\n\nThe plotThe code\n\n\n\n\n\n\n\n\n\n\n\n\n\n\np1 &lt;- ggplot(data = realis_data_2024Q1,\n             aes(y = `Type of Sale`,x = `Unit Price ($ PSM)`, fill = `Type of Area`)) +\n  stat_halfeye(adjust = 5,\n               justification = -0.2,\n               .width = 0,\n               point_colour = NA,alpha = 0.5) +\n  geom_boxplot(width = .20,\n               outlier.shape = NA,alpha = 0.5) +\n  ggtitle(label= \"Distribution of Price of properties with Type of Area and Type of Sale\") + \n  theme_minimal()\np1\n\n\n\n\nObservation: Based on the plot, we see that the median and mode of the distrbutions clearly indicate thatNew Sales are the most expensive followed by Sub Sale and Resales being the least expensive in terms of buying property. Sub sale properties are available only on Strata. In general, the median unit price of properties on land is higher than median unit price of properties on strata. This holds both for New Sales as well as Resales. The median unit price of New Sales for strata is higher than both strata and land properties for Resale. There are properties priced above 25000 $ PSM on Strata for New sale. These properties are more expensive than the ones on land for New sale.\n\n\n4.3 Distribution of Property Prices across regions in Singapore\nAs our objective is to analyse property market in 2024 Q1, let us compare the unit price of properties across regions in Singapore and the type of sale. We attempt to answer the questions: “Which regions are the most expensive and least expensive in terms of unit prices to buy properties in? How do the unit prices compare across regions and type of sale?”\nWe do this by creating half eye plot. First the ggplot(), stat_halfeye(), geom_boxplot() are used to create a half eye plot and boxplot of price of properties with different regions. We use Type of Sale as fill to see how prices vary with type of sale. The ggtitle(), theme(), xlab(), and ylab() functions in the ggplot2 package are then used to make aesthetic adjustments to the plot.\n\nThe plotThe code\n\n\n\n\n\n\n\n\n\n\n\n\n\n\noptions(repr.plot.width = 40, repr.plot.height = 100)\np1 &lt;- ggplot(realis_data_2024Q1, \n       aes(x = `Planning Region`, \n           y = `Unit Price ($ PSM)`, fill=`Type of Sale`)) +\n  stat_halfeye(adjust = 7,\n               justification = -0.2,\n               .width = 0,\n               point_colour = NA,\n               alpha = 0.5) +\n  geom_boxplot(width = .50,\n               outlier.shape = NA, aes(x = `Planning Region`, \n           y = `Unit Price ($ PSM)`, fill=`Type of Sale`), alpha = 0.5 ) +\n  coord_flip() +\n  theme_minimal() +\n  ggtitle(label= \"Distribution of Price of properties with Regions in Signapore and Type of Sale for 2024 Q1\")\np1\n\n\n\n\nObservation: Based on the plot, we see that the median and mode of the distributions clearly indicate that properties in the Central region are most expensive in terms of Unit Price ($ PSM) in terms of types of New Sale and Resale. The Sub sale properties in the Western region have a higher median unit price than the ones in all other regions. Also the Subsale median price here is higher than the New Sale median price. This needs to be investigated further. Properties in the North region are the least expensive based on the median prices for New sale and Resale. Deeper dive based on median and mode shows that purchasing a new property in the northern region might actually be cheaper than purchasing a resale property in the Central, Western or North-eastern region. There is a higher variation in the price of properties in the price of properties in the central region compared to all other regions."
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#summary",
    "href": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#summary",
    "title": "Take-home Exercise 1",
    "section": "5 Summary",
    "text": "5 Summary\nOur analysis of the private property market for Singapore based on Regions, Type of Sale, Area of Sale, yielded several insights. Overall, our analysis revealed uneven distributions of unit prices with different regions, type of sale, area of sale. Our analysis also revealed how many properties of each property type were sold in 2024 Q1 compared to 2023 Q1 and other quarters.\nKey Findings:\n\nThere has been a gradual reduction in number of properties of Detached houses sold in every quarter. The reason behind this needs to be investigated.\nThe number of properties of executive condos sold has grown significantly in 2024 Q1 as compared to 2023 Q1. A deeper study into the reasoning could reveal further insights.\nUnit Prices of properties on Land are higher as compared to prices on Strata in 2024 Q1.\nUnit Prices for New Sales are higher than Sub sales which in turn are higher than resales in 2024 Q1.\nUnit Prices of properties are highest in Central Region whereas they are lowest in the North region. Sub sale prices in the Western Region are surprisingly higher than New Sales in the region and highest overall among other regions.\nThere is a correlation between prices of private properties across various regions, across various types of sale and type of area of the property.\n\nRecommendations for future research:\n\nConfirmatory data analysis: Future studies should incorporate statistical tests to validate the findings from this exploratory data analysis and establish more definitive correlations and causation.\nExploring Additional Variables: A more exhaustive analysis that includes a wider range of variables could yield deeper insights into private property market. Understanding factors that drive prices of properties could help gain more insights and recommend a property to a particular class of purchasers based on demographics the appropriate property type.\nUnderstanding customer demographics: Understanding the customer demographics like age, income, gender, educational purpose will help reveal what type of customers will purchase a specific type of property in a region and how they would react to changes in market prices.\n\nBy addressing these areas, future research can provide a more comprehensive understanding of the various factors that contribute to price variation in private property market in Singapore and customer behavior."
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#references-and-inspiration",
    "href": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#references-and-inspiration",
    "title": "Take-home Exercise 1",
    "section": "6 References and inspiration",
    "text": "6 References and inspiration\n\nURA releases flash estimate of 1st Quarter 2024 private residential property price index\nUnsold private housing stock on the rise ahead of ramp-up in new launches in 2024\nHDB resale prices rise 1.7%; private home prices up 1.5% in first quarter: Flash estimates"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex06/In-class_Ex06_partb.html",
    "href": "In-class_Ex/In-class_Ex06/In-class_Ex06_partb.html",
    "title": "In-class Exercise 6: Part B",
    "section": "",
    "text": "pacman::p_load(jsonlite, tidygraph, ggraph,\n               visNetwork, graphlayouts, tidyverse)"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex06/In-class_Ex06_partb.html#reading-data",
    "href": "In-class_Ex/In-class_Ex06/In-class_Ex06_partb.html#reading-data",
    "title": "In-class Exercise 6: Part B",
    "section": "Reading data",
    "text": "Reading data\n\nmc3_data &lt;- fromJSON(\"data/MC3.json\")\n\n\nclass(mc3_data)\n\n[1] \"list\"\n\n\n\nmc3_edges &lt;-\n  as_tibble(mc3_data$links) %&gt;%\n  distinct() %&gt;%\n  mutate(source =\n           as.character(source),\n         target=\n           as.character(target),\n         type = as.character(type)) %&gt;%\n  group_by(source, target, type) %&gt;%\n  summarise(weights = n()) %&gt;%\n  filter(source != target) %&gt;%\n  ungroup()\n\n\nmc3_nodes &lt;- as_tibble(mc3_data$nodes) %&gt;%\n  mutate(country = as.character(country),\n         id = as.character(id),\n         product_services = as.character(product_services),\n         revenue_omu = as.numeric(as.character(revenue_omu)),\n         type = as.character(type)) %&gt;%\n  select(id, country, type, revenue_omu, product_services)\n\n\nid1 &lt;- mc3_edges %&gt;%\n  select(source) %&gt;%\n  rename(id = source)\nid2 &lt;- mc3_edges %&gt;%\n  select(target) %&gt;%\n  rename(id = target)\nmc3_nodes1 &lt;- rbind(id1, id2) %&gt;%\n  distinct() %&gt;%\n  left_join(mc3_nodes,\n            unmatched = \"drop\")\n\n\nmc3_graph &lt;- tbl_graph(nodes = mc3_nodes1,\n                       edges = mc3_edges,\n                       directed = FALSE) %&gt;%\n  mutate(betweenness_centrality = centrality_betweenness(),\n         closeness_centrality = centrality_closeness())\n\n\nmc3_graph %&gt;%\n  filter(betweenness_centrality &gt;= 300000) %&gt;%\n  ggraph(layout = \"fr\") +\n  geom_edge_link(aes(alpha = 0.5)) +\n  geom_node_point(aes(\n    size = betweenness_centrality,\n    colors = 'lightblue',\n    alpha = 0.5)) +\n  scale_size_continuous(range=c(1,10)) +\n  theme_graph()"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex05/In-class_Ex05_partb.html",
    "href": "In-class_Ex/In-class_Ex05/In-class_Ex05_partb.html",
    "title": "In-class Exercise 5: B",
    "section": "",
    "text": "pacman:: p_load(jsonlite, tidyverse)\n\n\nmc1_data &lt;- fromJSON(\"data/mc1.json\")"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex04/In-class_Ex04.html",
    "href": "In-class_Ex/In-class_Ex04/In-class_Ex04.html",
    "title": "In-class Exercise 4",
    "section": "",
    "text": "pacman::p_load(tidyverse, ggstatsplot)\n\n\nexam &lt;- read_csv(\"data/Exam_data.csv\")\n\n\n#set.seed(1234)\n\np &lt;- gghistostats(\n  data = exam,\n  x = ENGLISH,\n  type = \"parametric\",\n  test.value = 60,\n  bin.args = list(color = \"black\",\n                  fill = \"grey50\",\n                  alpha = 0.7),\n  normal.curve = FALSE,\n  normal.curve.args = list(linewidth = 2),\n  xlab = \"English Scores\"\n)\np\n\n\n\n\n\n\n\n\n\nextract_stats(p)\n\n$subtitle_data\n# A tibble: 1 × 15\n     mu statistic df.error  p.value method            alternative effectsize\n  &lt;dbl&gt;     &lt;dbl&gt;    &lt;dbl&gt;    &lt;dbl&gt; &lt;chr&gt;             &lt;chr&gt;       &lt;chr&gt;     \n1    60      8.77      321 1.04e-16 One Sample t-test two.sided   Hedges' g \n  estimate conf.level conf.low conf.high conf.method conf.distribution n.obs\n     &lt;dbl&gt;      &lt;dbl&gt;    &lt;dbl&gt;     &lt;dbl&gt; &lt;chr&gt;       &lt;chr&gt;             &lt;int&gt;\n1    0.488       0.95    0.372     0.603 ncp         t                   322\n  expression\n  &lt;list&gt;    \n1 &lt;language&gt;\n\n$caption_data\n# A tibble: 1 × 16\n  term       effectsize      estimate conf.level conf.low conf.high    pd\n  &lt;chr&gt;      &lt;chr&gt;              &lt;dbl&gt;      &lt;dbl&gt;    &lt;dbl&gt;     &lt;dbl&gt; &lt;dbl&gt;\n1 Difference Bayesian t-test     7.16       0.95     5.58      8.77     1\n  prior.distribution prior.location prior.scale    bf10 method         \n  &lt;chr&gt;                       &lt;dbl&gt;       &lt;dbl&gt;   &lt;dbl&gt; &lt;chr&gt;          \n1 cauchy                          0       0.707 4.54e13 Bayesian t-test\n  conf.method log_e_bf10 n.obs expression\n  &lt;chr&gt;            &lt;dbl&gt; &lt;int&gt; &lt;list&gt;    \n1 ETI               31.4   322 &lt;language&gt;\n\n$pairwise_comparisons_data\nNULL\n\n$descriptive_data\nNULL\n\n$one_sample_data\nNULL\n\n$tidy_data\nNULL\n\n$glance_data\nNULL\n\n\n\nset.seed(1234)\n\ngghistostats(\n  data = exam,\n  x = ENGLISH,\n  type = \"np\",\n  test.value = 60,\n  bin.args = list(color = \"black\",\n                  fill = \"grey50\",\n                  alpha = 0.7),\n  normal.curve = FALSE,\n  normal.curve.args = list(linewidth = 2),\n  xlab = \"English Scores\"\n)\n\n\n\n\n\n\n\n\n\nset.seed(1234)\n\ngghistostats(\n  data = exam,\n  x = ENGLISH,\n  type = \"robust\",\n  test.value = 60,\n  bin.args = list(color = \"black\",\n                  fill = \"grey50\",\n                  alpha = 0.7),\n  normal.curve = FALSE,\n  normal.curve.args = list(linewidth = 2),\n  xlab = \"English Scores\"\n)\n\n\n\n\n\n\n\n\n\nset.seed(1234)\n\ngghistostats(\n  data = exam,\n  x = ENGLISH,\n  type = \"bayes\",\n  test.value = 60,\n  bin.args = list(color = \"black\",\n                  fill = \"grey50\",\n                  alpha = 0.7),\n  normal.curve = FALSE,\n  normal.curve.args = list(linewidth = 2),\n  xlab = \"English Scores\"\n)\n\n\n\n\n\n\n\n\n\nset.seed(1234)\n\ngghistostats(\n  data = exam,\n  x = ENGLISH,\n  type = \"robust\",\n  test.value = 60,\n  bin.args = list(color = \"black\",\n                  fill = \"grey50\",\n                  alpha = 0.7),\n  normal.curve = TRUE,\n  normal.curve.args = list(linewidth = 0.5),\n  xlab = \"English Scores\"\n)\n\n\n\n\n\n\n\n\n\nggdotplotstats(\n  data = exam,\n  x = ENGLISH,\n  y = CLASS\n)\n\n\n\n\n\n\n\n\n\nexam_long &lt;- exam %&gt;%\n  pivot_longer(\n    cols= ENGLISH:SCIENCE,\n    names_to = \"SUBJECT\",\n    values_to = \"SCORES\") %&gt;%\n  filter(CLASS == \"3A\")\n\n\nggwithinstats(\n  data = filter(exam_long,\n                SUBJECT %in%\n                  c(\"MATHS\", \"SCIENCE\")),\n  x = SUBJECT,\n  y = SCORES,\n  type = \"p\"\n)\n\n\n\n\n\n\n\n\n\nggscatterstats(\n  data = exam,\n  x = MATHS,\n  y = ENGLISH,\n  marginal = TRUE,\n  label.var = ID,\n  label.expression = ENGLISH &gt; 90 & MATHS &gt; 90\n)"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex01/In-class_Ex01.html",
    "href": "In-class_Ex/In-class_Ex01/In-class_Ex01.html",
    "title": "In-class Exercise 1",
    "section": "",
    "text": "In the code chunk below, p_load() of pacman package is used to load tidyverse family of packages.\n\npacman::p_load(tidyverse)\n\n\nrealis &lt;- read_csv(\"data/realis2019.csv\")\n\n\nrealis.csv &lt;- read.csv(\"data/realis2019.csv\")\n\n\nggplot(data = realis,\n       aes(x = `Unit Price ($ psm)`)) +\n  geom_histogram()"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex01/In-class_Ex01.html#loading-r-packages",
    "href": "In-class_Ex/In-class_Ex01/In-class_Ex01.html#loading-r-packages",
    "title": "In-class Exercise 1",
    "section": "",
    "text": "In the code chunk below, p_load() of pacman package is used to load tidyverse family of packages.\n\npacman::p_load(tidyverse)\n\n\nrealis &lt;- read_csv(\"data/realis2019.csv\")\n\n\nrealis.csv &lt;- read.csv(\"data/realis2019.csv\")\n\n\nggplot(data = realis,\n       aes(x = `Unit Price ($ psm)`)) +\n  geom_histogram()"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex08/Hands-on_Ex08_partb.html",
    "href": "Hands-on_Ex/Hands-on_Ex08/Hands-on_Ex08_partb.html",
    "title": "Hands-on Exercise 8: Part B",
    "section": "",
    "text": "Proportional symbol maps (also known as graduate symbol maps) are a class of maps that use the visual variable of size to represent differences in the magnitude of a discrete, abruptly changing phenomenon, e.g. counts of people. Like choropleth maps, you can create classed or unclassed versions of these maps. The classed ones are known as range-graded or graduated symbols, and the unclassed are called proportional symbols, where the area of the symbols are proportional to the values of the attribute being mapped. In this hands-on exercise, you will learn how to create a proportional symbol map showing the number of wins by Singapore Pools’ outlets using an R package called tmap.\n\n\nBy the end of this hands-on exercise, you will acquire the following skills by using appropriate R packages:\n\nTo import an aspatial data file into R.\nTo convert it into simple point feature data frame and at the same time, to assign an appropriate projection reference to the newly create simple point feature data frame.\nTo plot interactive proportional symbol maps.\n\n\n\n\nBefore we get started, we need to ensure that tmap package of R and other related R packages have been installed and loaded into R.\n\npacman::p_load(sf, tmap, tidyverse)\n\n\n\n\n\n\nThe data set use for this hands-on exercise is called SGPools_svy21. The data is in csv file format.\nFigure below shows the first 15 records of SGPools_svy21.csv. It consists of seven columns. The XCOORD and YCOORD columns are the x-coordinates and y-coordinates of SingPools outlets and branches. They are in Singapore SVY21 Projected Coordinates System.\n\n\n\nThe code chunk below uses read_csv() function of readr package to import SGPools_svy21.csv into R as a tibble data frame called sgpools.\n\nsgpools &lt;- read_csv(\"data/aspatial/SGPools_svy21.csv\")\n\nAfter importing the data file into R, it is important for us to examine if the data file has been imported correctly.\nThe code chunk below shows list() is used to do the job.\n\nlist(sgpools) \n\n[[1]]\n# A tibble: 306 × 7\n   NAME           ADDRESS POSTCODE XCOORD YCOORD `OUTLET TYPE` `Gp1Gp2 Winnings`\n   &lt;chr&gt;          &lt;chr&gt;      &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt; &lt;chr&gt;                     &lt;dbl&gt;\n 1 Livewire (Mar… 2 Bayf…    18972 30842. 29599. Branch                        5\n 2 Livewire (Res… 26 Sen…    98138 26704. 26526. Branch                       11\n 3 SportsBuzz (K… Lotus …   738078 20118. 44888. Branch                        0\n 4 SportsBuzz (P… 1 Sele…   188306 29777. 31382. Branch                       44\n 5 Prime Serango… Blk 54…   552542 32239. 39519. Branch                        0\n 6 Singapore Poo… 1A Woo…   731001 21012. 46987. Branch                        3\n 7 Singapore Poo… Blk 64…   370064 33990. 34356. Branch                       17\n 8 Singapore Poo… Blk 88…   370088 33847. 33976. Branch                       16\n 9 Singapore Poo… Blk 30…   540308 33910. 41275. Branch                       21\n10 Singapore Poo… Blk 20…   560202 29246. 38943. Branch                       25\n# ℹ 296 more rows\n\n\n\n\n\nThe code chunk below converts sgpools data frame into a simple feature data frame by using st_as_sf() of sf packages.\n\nsgpools_sf &lt;- st_as_sf(sgpools, \n                       coords = c(\"XCOORD\", \"YCOORD\"),\n                       crs= 3414)\n\nThings to learn from the arguments above:\n\nThe coords argument requires you to provide the column name of the x-coordinates first then followed by the column name of the y-coordinates.\nThe crs argument required you to provide the coordinates system in epsg format. EPSG: 3414 is Singapore SVY21 Projected Coordinate System. You can search for other country’s epsg code by refering to epsg.io.\n\nFigure below shows the data table of sgpools_sf. Notice that a new column called geometry has been added into the data frame.\n\nYou can display the basic information of the newly created sgpools_sf by using the code chunk below.\n\nlist(sgpools_sf)\n\n[[1]]\nSimple feature collection with 306 features and 5 fields\nGeometry type: POINT\nDimension:     XY\nBounding box:  xmin: 7844.194 ymin: 26525.7 xmax: 45176.57 ymax: 47987.13\nProjected CRS: SVY21 / Singapore TM\n# A tibble: 306 × 6\n   NAME                         ADDRESS POSTCODE `OUTLET TYPE` `Gp1Gp2 Winnings`\n * &lt;chr&gt;                        &lt;chr&gt;      &lt;dbl&gt; &lt;chr&gt;                     &lt;dbl&gt;\n 1 Livewire (Marina Bay Sands)  2 Bayf…    18972 Branch                        5\n 2 Livewire (Resorts World Sen… 26 Sen…    98138 Branch                       11\n 3 SportsBuzz (Kranji)          Lotus …   738078 Branch                        0\n 4 SportsBuzz (PoMo)            1 Sele…   188306 Branch                       44\n 5 Prime Serangoon North        Blk 54…   552542 Branch                        0\n 6 Singapore Pools Woodlands C… 1A Woo…   731001 Branch                        3\n 7 Singapore Pools 64 Circuit … Blk 64…   370064 Branch                       17\n 8 Singapore Pools 88 Circuit … Blk 88…   370088 Branch                       16\n 9 Singapore Pools Anchorvale … Blk 30…   540308 Branch                       21\n10 Singapore Pools Ang Mo Kio … Blk 20…   560202 Branch                       25\n# ℹ 296 more rows\n# ℹ 1 more variable: geometry &lt;POINT [m]&gt;\n\n\nThe output shows that sgpools_sf is in point feature class. It’s epsg ID is 3414. The bbox provides information of the extend of the geospatial data.\n\n\n\n\nTo create an interactive proportional symbol map in R, the view mode of tmap will be used.\nThe code churn below will turn on the interactive mode of tmap.\n\ntmap_mode(\"view\")\n\n\n\nThe code chunks below are used to create an interactive point symbol map.\n\ntm_shape(sgpools_sf)+\ntm_bubbles(col = \"red\",\n           size = 1,\n           border.col = \"black\",\n           border.lwd = 1)\n\n\n\n\n\n\n\n\nTo draw a proportional symbol map, we need to assign a numerical variable to the size visual attribute. The code chunks below show that the variable Gp1Gp2Winnings is assigned to size visual attribute.\n\ntm_shape(sgpools_sf)+\ntm_bubbles(col = \"red\",\n           size = \"Gp1Gp2 Winnings\",\n           border.col = \"black\",\n           border.lwd = 1)\n\n\n\n\n\n\n\n\nThe proportional symbol map can be further improved by using the colour visual attribute. In the code chunks below, OUTLET_TYPE variable is used as the colour attribute variable.\n\ntm_shape(sgpools_sf)+\ntm_bubbles(col = \"OUTLET TYPE\", \n          size = \"Gp1Gp2 Winnings\",\n          border.col = \"black\",\n          border.lwd = 1)\n\n\n\n\n\n\n\n\nAn impressive and little-know feature of tmap’s view mode is that it also works with faceted plots. The argument sync in tm_facets() can be used in this case to produce multiple maps with synchronised zoom and pan settings.\n\ntm_shape(sgpools_sf) +\n  tm_bubbles(col = \"OUTLET TYPE\", \n          size = \"Gp1Gp2 Winnings\",\n          border.col = \"black\",\n          border.lwd = 1) +\n  tm_facets(by= \"OUTLET TYPE\",\n            nrow = 1,\n            sync = TRUE)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\ntmap: Thematic Maps in R\ntmap\ntmap: get started!\ntmap: changes in version 2.0\ntmap: creating thematic maps in a flexible way (useR!2015)\nExploring and presenting maps with tmap (useR!2017)\n\n\n\n\n\nsf: Simple Features for R\nSimple Features for R: StandardizedSupport for Spatial Vector Data\nReading, Writing and Converting Simple Features\n\n\n\n\n\ndplyr\nTidy data\ntidyr: Easily Tidy Data with ‘spread()’ and ‘gather()’ Functions"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex08/Hands-on_Ex08_partb.html#learning-outcome",
    "href": "Hands-on_Ex/Hands-on_Ex08/Hands-on_Ex08_partb.html#learning-outcome",
    "title": "Hands-on Exercise 8: Part B",
    "section": "",
    "text": "By the end of this hands-on exercise, you will acquire the following skills by using appropriate R packages:\n\nTo import an aspatial data file into R.\nTo convert it into simple point feature data frame and at the same time, to assign an appropriate projection reference to the newly create simple point feature data frame.\nTo plot interactive proportional symbol maps."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex08/Hands-on_Ex08_partb.html#getting-started",
    "href": "Hands-on_Ex/Hands-on_Ex08/Hands-on_Ex08_partb.html#getting-started",
    "title": "Hands-on Exercise 8: Part B",
    "section": "",
    "text": "Before we get started, we need to ensure that tmap package of R and other related R packages have been installed and loaded into R.\n\npacman::p_load(sf, tmap, tidyverse)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex08/Hands-on_Ex08_partb.html#geospatial-data-wrangling",
    "href": "Hands-on_Ex/Hands-on_Ex08/Hands-on_Ex08_partb.html#geospatial-data-wrangling",
    "title": "Hands-on Exercise 8: Part B",
    "section": "",
    "text": "The data set use for this hands-on exercise is called SGPools_svy21. The data is in csv file format.\nFigure below shows the first 15 records of SGPools_svy21.csv. It consists of seven columns. The XCOORD and YCOORD columns are the x-coordinates and y-coordinates of SingPools outlets and branches. They are in Singapore SVY21 Projected Coordinates System.\n\n\n\nThe code chunk below uses read_csv() function of readr package to import SGPools_svy21.csv into R as a tibble data frame called sgpools.\n\nsgpools &lt;- read_csv(\"data/aspatial/SGPools_svy21.csv\")\n\nAfter importing the data file into R, it is important for us to examine if the data file has been imported correctly.\nThe code chunk below shows list() is used to do the job.\n\nlist(sgpools) \n\n[[1]]\n# A tibble: 306 × 7\n   NAME           ADDRESS POSTCODE XCOORD YCOORD `OUTLET TYPE` `Gp1Gp2 Winnings`\n   &lt;chr&gt;          &lt;chr&gt;      &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt; &lt;chr&gt;                     &lt;dbl&gt;\n 1 Livewire (Mar… 2 Bayf…    18972 30842. 29599. Branch                        5\n 2 Livewire (Res… 26 Sen…    98138 26704. 26526. Branch                       11\n 3 SportsBuzz (K… Lotus …   738078 20118. 44888. Branch                        0\n 4 SportsBuzz (P… 1 Sele…   188306 29777. 31382. Branch                       44\n 5 Prime Serango… Blk 54…   552542 32239. 39519. Branch                        0\n 6 Singapore Poo… 1A Woo…   731001 21012. 46987. Branch                        3\n 7 Singapore Poo… Blk 64…   370064 33990. 34356. Branch                       17\n 8 Singapore Poo… Blk 88…   370088 33847. 33976. Branch                       16\n 9 Singapore Poo… Blk 30…   540308 33910. 41275. Branch                       21\n10 Singapore Poo… Blk 20…   560202 29246. 38943. Branch                       25\n# ℹ 296 more rows\n\n\n\n\n\nThe code chunk below converts sgpools data frame into a simple feature data frame by using st_as_sf() of sf packages.\n\nsgpools_sf &lt;- st_as_sf(sgpools, \n                       coords = c(\"XCOORD\", \"YCOORD\"),\n                       crs= 3414)\n\nThings to learn from the arguments above:\n\nThe coords argument requires you to provide the column name of the x-coordinates first then followed by the column name of the y-coordinates.\nThe crs argument required you to provide the coordinates system in epsg format. EPSG: 3414 is Singapore SVY21 Projected Coordinate System. You can search for other country’s epsg code by refering to epsg.io.\n\nFigure below shows the data table of sgpools_sf. Notice that a new column called geometry has been added into the data frame.\n\nYou can display the basic information of the newly created sgpools_sf by using the code chunk below.\n\nlist(sgpools_sf)\n\n[[1]]\nSimple feature collection with 306 features and 5 fields\nGeometry type: POINT\nDimension:     XY\nBounding box:  xmin: 7844.194 ymin: 26525.7 xmax: 45176.57 ymax: 47987.13\nProjected CRS: SVY21 / Singapore TM\n# A tibble: 306 × 6\n   NAME                         ADDRESS POSTCODE `OUTLET TYPE` `Gp1Gp2 Winnings`\n * &lt;chr&gt;                        &lt;chr&gt;      &lt;dbl&gt; &lt;chr&gt;                     &lt;dbl&gt;\n 1 Livewire (Marina Bay Sands)  2 Bayf…    18972 Branch                        5\n 2 Livewire (Resorts World Sen… 26 Sen…    98138 Branch                       11\n 3 SportsBuzz (Kranji)          Lotus …   738078 Branch                        0\n 4 SportsBuzz (PoMo)            1 Sele…   188306 Branch                       44\n 5 Prime Serangoon North        Blk 54…   552542 Branch                        0\n 6 Singapore Pools Woodlands C… 1A Woo…   731001 Branch                        3\n 7 Singapore Pools 64 Circuit … Blk 64…   370064 Branch                       17\n 8 Singapore Pools 88 Circuit … Blk 88…   370088 Branch                       16\n 9 Singapore Pools Anchorvale … Blk 30…   540308 Branch                       21\n10 Singapore Pools Ang Mo Kio … Blk 20…   560202 Branch                       25\n# ℹ 296 more rows\n# ℹ 1 more variable: geometry &lt;POINT [m]&gt;\n\n\nThe output shows that sgpools_sf is in point feature class. It’s epsg ID is 3414. The bbox provides information of the extend of the geospatial data."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex08/Hands-on_Ex08_partb.html#drawing-proportional-symbol-map",
    "href": "Hands-on_Ex/Hands-on_Ex08/Hands-on_Ex08_partb.html#drawing-proportional-symbol-map",
    "title": "Hands-on Exercise 8: Part B",
    "section": "",
    "text": "To create an interactive proportional symbol map in R, the view mode of tmap will be used.\nThe code churn below will turn on the interactive mode of tmap.\n\ntmap_mode(\"view\")\n\n\n\nThe code chunks below are used to create an interactive point symbol map.\n\ntm_shape(sgpools_sf)+\ntm_bubbles(col = \"red\",\n           size = 1,\n           border.col = \"black\",\n           border.lwd = 1)\n\n\n\n\n\n\n\n\nTo draw a proportional symbol map, we need to assign a numerical variable to the size visual attribute. The code chunks below show that the variable Gp1Gp2Winnings is assigned to size visual attribute.\n\ntm_shape(sgpools_sf)+\ntm_bubbles(col = \"red\",\n           size = \"Gp1Gp2 Winnings\",\n           border.col = \"black\",\n           border.lwd = 1)\n\n\n\n\n\n\n\n\nThe proportional symbol map can be further improved by using the colour visual attribute. In the code chunks below, OUTLET_TYPE variable is used as the colour attribute variable.\n\ntm_shape(sgpools_sf)+\ntm_bubbles(col = \"OUTLET TYPE\", \n          size = \"Gp1Gp2 Winnings\",\n          border.col = \"black\",\n          border.lwd = 1)\n\n\n\n\n\n\n\n\nAn impressive and little-know feature of tmap’s view mode is that it also works with faceted plots. The argument sync in tm_facets() can be used in this case to produce multiple maps with synchronised zoom and pan settings.\n\ntm_shape(sgpools_sf) +\n  tm_bubbles(col = \"OUTLET TYPE\", \n          size = \"Gp1Gp2 Winnings\",\n          border.col = \"black\",\n          border.lwd = 1) +\n  tm_facets(by= \"OUTLET TYPE\",\n            nrow = 1,\n            sync = TRUE)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex08/Hands-on_Ex08_partb.html#reference",
    "href": "Hands-on_Ex/Hands-on_Ex08/Hands-on_Ex08_partb.html#reference",
    "title": "Hands-on Exercise 8: Part B",
    "section": "",
    "text": "tmap: Thematic Maps in R\ntmap\ntmap: get started!\ntmap: changes in version 2.0\ntmap: creating thematic maps in a flexible way (useR!2015)\nExploring and presenting maps with tmap (useR!2017)\n\n\n\n\n\nsf: Simple Features for R\nSimple Features for R: StandardizedSupport for Spatial Vector Data\nReading, Writing and Converting Simple Features\n\n\n\n\n\ndplyr\nTidy data\ntidyr: Easily Tidy Data with ‘spread()’ and ‘gather()’ Functions"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex07/Hands-on_Ex07.html",
    "href": "Hands-on_Ex/Hands-on_Ex07/Hands-on_Ex07.html",
    "title": "Hands-on Exercise 7",
    "section": "",
    "text": "By the end of this hands-on exercise we will be able create the followings data visualisation by using R packages:\n\nplotting a calender heatmap by using ggplot2 functions,\nplotting a cycle plot by using ggplot2 function,\nplotting a slopegraph\nplotting a horizon chart"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex07/Hands-on_Ex07.html#learning-outcome",
    "href": "Hands-on_Ex/Hands-on_Ex07/Hands-on_Ex07.html#learning-outcome",
    "title": "Hands-on Exercise 7",
    "section": "",
    "text": "By the end of this hands-on exercise we will be able create the followings data visualisation by using R packages:\n\nplotting a calender heatmap by using ggplot2 functions,\nplotting a cycle plot by using ggplot2 function,\nplotting a slopegraph\nplotting a horizon chart"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex07/Hands-on_Ex07.html#getting-started",
    "href": "Hands-on_Ex/Hands-on_Ex07/Hands-on_Ex07.html#getting-started",
    "title": "Hands-on Exercise 7",
    "section": "7.2 Getting Started",
    "text": "7.2 Getting Started"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex07/Hands-on_Ex07.html#do-it-yourself",
    "href": "Hands-on_Ex/Hands-on_Ex07/Hands-on_Ex07.html#do-it-yourself",
    "title": "Hands-on Exercise 7",
    "section": "7.3 Do It Yourself",
    "text": "7.3 Do It Yourself\nCode chunk to check, install and launch the following R packages: scales, viridis, lubridate, ggthemes, gridExtra, readxl, knitr, data.table and tidyverse.\n\npacman::p_load(scales, viridis, lubridate, ggthemes, gridExtra, readxl, knitr, data.table, CGPfunctions, ggHoriPlot, tidyverse)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex07/Hands-on_Ex07.html#plotting-calendar-heatmap",
    "href": "Hands-on_Ex/Hands-on_Ex07/Hands-on_Ex07.html#plotting-calendar-heatmap",
    "title": "Hands-on Exercise 7",
    "section": "7.4 Plotting Calendar Heatmap",
    "text": "7.4 Plotting Calendar Heatmap\nIn this section, you will learn how to plot a calender heatmap programmatically by using ggplot2 package.\nBy the end of this section, you will be able to:\n\n\nplot a calender heatmap by using ggplot2 functions and extension,\nto write function using R programming,\nto derive specific date and time related field by using base R and lubridate packages\nto perform data preparation task by using tidyr and dplyr packages.\n\n\n7.4.1 The Data\nFor the purpose of this hands-on exercise, eventlog.csv file will be used. This data file consists of 199,999 rows of time-series cyber attack records by country.\n\n\n7.4.2 Importing the data\nFirst, you will use the code chunk below to import eventlog.csv file into R environment and called the data frame as attacks.\n\nattacks &lt;- read_csv(\"data/eventlog.csv\")\n\n\n\n7.4.3 Examining the data structure\nIt is always a good practice to examine the imported data frame before further analysis is performed.\nFor example, kable() can be used to review the structure of the imported data frame.\n\nkable(head(attacks))\n\n\n\n\ntimestamp\nsource_country\ntz\n\n\n\n\n2015-03-12 15:59:16\nCN\nAsia/Shanghai\n\n\n2015-03-12 16:00:48\nFR\nEurope/Paris\n\n\n2015-03-12 16:02:26\nCN\nAsia/Shanghai\n\n\n2015-03-12 16:02:38\nUS\nAmerica/Chicago\n\n\n2015-03-12 16:03:22\nCN\nAsia/Shanghai\n\n\n2015-03-12 16:03:45\nCN\nAsia/Shanghai\n\n\n\n\n\nThere are three columns, namely timestamp, source_country and tz.\n\ntimestamp field stores date-time values in POSIXct format.\nsource_country field stores the source of the attack. It is in ISO 3166-1 alpha-2 country code.\ntz field stores time zone of the source IP address.\n\n\n\n7.4.4 Data Preparation\nStep 1: Deriving weekday and hour of day fields\nBefore we can plot the calender heatmap, two new fields namely wkday and hour need to be derived. In this step, we will write a function to perform the task.\n\nmake_hr_wkday &lt;- function(ts, sc, tz) {\n  real_times &lt;- ymd_hms(ts, \n                        tz = tz[1], \n                        quiet = TRUE)\n  dt &lt;- data.table(source_country = sc,\n                   wkday = weekdays(real_times),\n                   hour = hour(real_times))\n  return(dt)\n  }\n\n\n\n\n\n\n\nNote\n\n\n\n\nymd_hms() and hour() are from lubridate package, and\nweekdays() is a base R function.\n\n\n\nStep 2: Deriving the attacks tibble data frame\n\nwkday_levels &lt;- c('Saturday', 'Friday', \n                  'Thursday', 'Wednesday', \n                  'Tuesday', 'Monday', \n                  'Sunday')\n\nattacks &lt;- attacks %&gt;%\n  group_by(tz) %&gt;%\n  do(make_hr_wkday(.$timestamp, \n                   .$source_country, \n                   .$tz)) %&gt;% \n  ungroup() %&gt;% \n  mutate(wkday = factor(\n    wkday, levels = wkday_levels),\n    hour  = factor(\n      hour, levels = 0:23))\n\n\n\n\n\n\n\nNote\n\n\n\nBeside extracting the necessary data into attacks data frame, mutate() of dplyr package is used to convert wkday and hour fields into factor so they’ll be ordered when plotting\n\n\nTable below shows the tidy tibble table after processing.\n\nkable(head(attacks))\n\n\n\n\ntz\nsource_country\nwkday\nhour\n\n\n\n\nAfrica/Cairo\nBG\nSaturday\n20\n\n\nAfrica/Cairo\nTW\nSunday\n6\n\n\nAfrica/Cairo\nTW\nSunday\n8\n\n\nAfrica/Cairo\nCN\nSunday\n11\n\n\nAfrica/Cairo\nUS\nSunday\n15\n\n\nAfrica/Cairo\nCA\nMonday\n11\n\n\n\n\n\n\n\n7.4.5 Building the Calendar Heatmaps\n\ngrouped &lt;- attacks %&gt;% \n  count(wkday, hour) %&gt;% \n  ungroup() %&gt;%\n  na.omit()\n\nggplot(grouped, \n       aes(hour, \n           wkday, \n           fill = n)) + \ngeom_tile(color = \"white\", \n          size = 0.1) + \ntheme_tufte(base_family = \"Helvetica\") + \ncoord_equal() +\nscale_fill_gradient(name = \"# of attacks\",\n                    low = \"sky blue\", \n                    high = \"dark blue\") +\nlabs(x = NULL, \n     y = NULL, \n     title = \"Attacks by weekday and time of day\") +\ntheme(axis.ticks = element_blank(),\n      plot.title = element_text(hjust = 0.5),\n      legend.title = element_text(size = 8),\n      legend.text = element_text(size = 6) )\n\n\n\n\n\n\n\n\nThen we can simply group the count by hour and wkday and plot it, since we know that we have values for every combination there’s no need to further preprocess the data.\n\n\n\n\n\n\nThings to learn from code chunk\n\n\n\n\na tibble data table called grouped is derived by aggregating the attack by wkday and hour fields.\na new field called n is derived by using group_by() and count() functions.\nna.omit() is used to exclude missing value.\ngeom_tile() is used to plot tiles (grids) at each x and y position. color and size arguments are used to specify the border color and line size of the tiles.\ntheme_tufte() of ggthemes package is used to remove unnecessary chart junk. To learn which visual components of default ggplot2 have been excluded, you are encouraged to comment out this line to examine the default plot.\ncoord_equal() is used to ensure the plot will have an aspect ratio of 1:1.\nscale_fill_gradient() function is used to creates a two colour gradient (low-high).\n\n\n\n\n\n7.4.6 Building Multiple Calendar Heatmaps\nChallenge: Building multiple heatmaps for the top four countries with the highest number of attacks.\n\n\n7.4.7 Plotting Multiple Calendar Heatmaps\nStep 1: Deriving attack by country object\nIn order to identify the top 4 countries with the highest number of attacks, you are required to do the followings:\n\ncount the number of attacks by country,\ncalculate the percent of attackes by country, and\nsave the results in a tibble data frame.\n\n\nattacks_by_country &lt;- count(\n  attacks, source_country) %&gt;%\n  mutate(percent = percent(n/sum(n))) %&gt;%\n  arrange(desc(n))\n\nStep 2: Preparing the tidy data frame\nIn this step, you are required to extract the attack records of the top 4 countries from attacks data frame and save the data in a new tibble data frame (i.e. top4_attacks).\n\ntop4 &lt;- attacks_by_country$source_country[1:4]\ntop4_attacks &lt;- attacks %&gt;%\n  filter(source_country %in% top4) %&gt;%\n  count(source_country, wkday, hour) %&gt;%\n  ungroup() %&gt;%\n  mutate(source_country = factor(\n    source_country, levels = top4)) %&gt;%\n  na.omit()\n\n\n\n7.4.8 Plotting Multiple Calendar Heatmaps\nStep 3: Plotting the Multiple Calender Heatmap by using ggplot2 package.\n\nggplot(top4_attacks, \n       aes(hour, \n           wkday, \n           fill = n)) + \n  geom_tile(color = \"white\", \n          size = 0.1) + \n  theme_tufte(base_family = \"Helvetica\") + \n  coord_equal() +\n  scale_fill_gradient(name = \"# of attacks\",\n                    low = \"sky blue\", \n                    high = \"dark blue\") +\n  facet_wrap(~source_country, ncol = 2) +\n  labs(x = NULL, y = NULL, \n     title = \"Attacks on top 4 countries by weekday and time of day\") +\n  theme(axis.ticks = element_blank(),\n        axis.text.x = element_text(size = 7),\n        plot.title = element_text(hjust = 0.5),\n        legend.title = element_text(size = 8),\n        legend.text = element_text(size = 6) )"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex07/Hands-on_Ex07.html#plotting-cycle-plot",
    "href": "Hands-on_Ex/Hands-on_Ex07/Hands-on_Ex07.html#plotting-cycle-plot",
    "title": "Hands-on Exercise 7",
    "section": "7.5 Plotting Cycle Plot",
    "text": "7.5 Plotting Cycle Plot\nIn this section, you will learn how to plot a cycle plot showing the time-series patterns and trend of visitor arrivals from Vietnam programmatically by using ggplot2 functions.\n\n7.5.1 Step 1: Data Import\nFor the purpose of this hands-on exercise, arrivals_by_air.xlsx will be used.\nThe code chunk below imports arrivals_by_air.xlsx by using read_excel() of readxl package and save it as a tibble data frame called air.\n\nair &lt;- read_excel(\"data/arrivals_by_air.xlsx\")\n\n\n\n7.5.2 Step 2: Deriving month and year fields\nNext, two new fields called month and year are derived from Month-Year field.\n\nair$month &lt;- factor(month(air$`Month-Year`), \n                    levels=1:12, \n                    labels=month.abb, \n                    ordered=TRUE) \nair$year &lt;- year(ymd(air$`Month-Year`))\n\n\n\n7.5.3 Step 4: Extracting the target country\nNext, the code chunk below is use to extract data for the target country (i.e. Vietnam)\n\nVietnam &lt;- air %&gt;% \n  select(`Vietnam`, \n         month, \n         year) %&gt;%\n  filter(year &gt;= 2010)\n\n\n\n7.5.4 Step 5: Computing year average arrivals by month\nThe code chunk below uses group_by() and summarise() of dplyr to compute year average arrivals by month.\n\nhline.data &lt;- Vietnam %&gt;% \n  group_by(month) %&gt;%\n  summarise(avgvalue = mean(`Vietnam`))\n\n\n\n7.5.5 Step 6: Plotting the cycle plot\nThe code chunk below is used to plot the cycle plot.\n\nggplot() + \n  geom_line(data=Vietnam,\n            aes(x=year, \n                y=`Vietnam`, \n                group=month), \n            colour=\"black\") +\n  geom_hline(aes(yintercept=avgvalue), \n             data=hline.data, \n             linetype=6, \n             colour=\"red\", \n             size=0.5) + \n  facet_grid(~month) +\n  labs(axis.text.x = element_blank(),\n       title = \"Visitor arrivals from Vietnam by air, Jan 2010-Dec 2019\") +\n  xlab(\"\") +\n  ylab(\"No. of Visitors\") +\n  theme_tufte(base_family = \"Helvetica\")"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex07/Hands-on_Ex07.html#plotting-slopegraph",
    "href": "Hands-on_Ex/Hands-on_Ex07/Hands-on_Ex07.html#plotting-slopegraph",
    "title": "Hands-on Exercise 7",
    "section": "7.6 Plotting Slopegraph",
    "text": "7.6 Plotting Slopegraph\nIn this section you will learn how to plot a slopegraph by using R.\nBefore getting start, make sure that CGPfunctions has been installed and loaded onto R environment. Then, refer to Using newggslopegraph to learn more about the function. Lastly, read more about newggslopegraph() and its arguments by referring to this link.\n\n7.6.1 Step 1: Data Import\nImport the rice data set into R environment by using the code chunk below.\n\nrice &lt;- read_csv(\"data/rice.csv\")\n\n\n\n7.6.2 Step 2: Plotting the slopegraph\nNext, code chunk below will be used to plot a basic slopegraph as shown below.\n\nrice %&gt;% \n  mutate(Year = factor(Year)) %&gt;%\n  filter(Year %in% c(1961, 1980)) %&gt;%\n  newggslopegraph(Year, Yield, Country,\n                Title = \"Rice Yield of Top 11 Asian Counties\",\n                SubTitle = \"1961-1980\",\n                Caption = \"Prepared by: Sarthak Nagapurkar\")\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nThings to learn from code chunk above\n\n\n\nFor effective data visualisation design, factor() is used convert the value type of Year field from numeric to factor."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05.html",
    "href": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05.html",
    "title": "Hands-on Exercise 5",
    "section": "",
    "text": "In this hands-on exercise, we will learn how to visualise and analyse text data using R.\nBy the end of this hands-on exercise, we will be able to:\n\nunderstand tidytext framework for processing, analysing and visualising text data,\nwrite function for importing multiple files into R,\ncombine multiple files into a single data frame,\nclean and wrangle text data by using tidyverse approach,\nvisualise words with Word Cloud,\ncompute term frequency–inverse document frequency (TF-IDF) using tidytext method, and\nvisualising texts and terms relationship."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05.html#learning-outcome",
    "href": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05.html#learning-outcome",
    "title": "Hands-on Exercise 5",
    "section": "",
    "text": "In this hands-on exercise, we will learn how to visualise and analyse text data using R.\nBy the end of this hands-on exercise, we will be able to:\n\nunderstand tidytext framework for processing, analysing and visualising text data,\nwrite function for importing multiple files into R,\ncombine multiple files into a single data frame,\nclean and wrangle text data by using tidyverse approach,\nvisualise words with Word Cloud,\ncompute term frequency–inverse document frequency (TF-IDF) using tidytext method, and\nvisualising texts and terms relationship."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05.html#getting-started",
    "href": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05.html#getting-started",
    "title": "Hands-on Exercise 5",
    "section": "5.2 Getting Started",
    "text": "5.2 Getting Started\n\n5.2.1 Installing and launching R packages\nIn this hands-on exercise, the following R packages for handling, processing, wrangling, analysing and visualising text data will be used:\n\ntidytext, tidyverse (mainly readr, purrr, stringr, ggplot2)\nwidyr,\nwordcloud and ggwordcloud,\ntextplot (required igraph, tidygraph and ggraph, )\nDT,\nlubridate and hms.\n\n\npacman::p_load(tidytext, widyr, wordcloud, DT, ggwordcloud, textplot, lubridate, hms, tidyverse, tidygraph, ggraph, igraph)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05.html#importing-multiple-text-files-from-multiple-folders",
    "href": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05.html#importing-multiple-text-files-from-multiple-folders",
    "title": "Hands-on Exercise 5",
    "section": "5.3 Importing Multiple Text Files from Multiple Folders",
    "text": "5.3 Importing Multiple Text Files from Multiple Folders\n\n5.3.1 Creating a folder list\n\nnews20 &lt;- \"data/news20\"\n\n\n\n5.3.2 Define a function to read all files from a folder into a data frame\n\nread_folder &lt;- function(infolder) {\n  tibble(file = dir(infolder, \n                    full.names = TRUE)) %&gt;%\n    mutate(text = map(file, \n                      read_lines)) %&gt;%\n    transmute(id = basename(file), \n              text) %&gt;%\n    unnest(text)\n}"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05.html#importing-multiple-text-files-from-multiple-folders-1",
    "href": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05.html#importing-multiple-text-files-from-multiple-folders-1",
    "title": "Hands-on Exercise 5",
    "section": "5.4 Importing Multiple Text Files from Multiple Folders",
    "text": "5.4 Importing Multiple Text Files from Multiple Folders\n\n5.4.1 Reading in all the messages from the 20news folder\n\nraw_text &lt;- tibble(folder = \n                     dir(news20, \n                         full.names = TRUE)) %&gt;%\n  mutate(folder_out = map(folder, \n                          read_folder)) %&gt;%\n  unnest(cols = c(folder_out)) %&gt;%\n  transmute(newsgroup = basename(folder), \n            id, text)\nwrite_rds(raw_text, \"data/news20.rds\")\n\n\nnews20 &lt;- readRDS(\"data/news20.rds\")\n\n\n\n\n\n\n\nThings to learn from code chunk above:\n\n\n\n\nread_lines() of readr package is used to read up to n_max lines from a file.\nmap() of purrr package is used to transform their input by applying a function to each element of a list and returning an object of the same length as the input.\nunnest() of dplyr package is used to flatten a list-column of data frames back out into regular columns.\nmutate() of dplyr is used to add new variables and preserves existing ones;\ntransmute() of dplyr is used to add new variables and drops existing ones.\nread_rds() is used to save the extracted and combined data frame as rds file for future use."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05.html#initial-eda",
    "href": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05.html#initial-eda",
    "title": "Hands-on Exercise 5",
    "section": "5.5 Initial EDA",
    "text": "5.5 Initial EDA\n\nraw_text &lt;- news20\nraw_text %&gt;%\n  group_by(newsgroup) %&gt;%\n  summarize(messages = n_distinct(id)) %&gt;%\n  ggplot(aes(messages, newsgroup)) +\n  geom_col(fill = \"lightblue\") +\n  labs(y = NULL)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05.html#introducing-tidytext",
    "href": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05.html#introducing-tidytext",
    "title": "Hands-on Exercise 5",
    "section": "5.6 Introducing tidytext",
    "text": "5.6 Introducing tidytext\n\nUsing tidy data principles in processing, analysing and visualising text data.\nMuch of the infrastructure needed for text mining with tidy data frames already exists in packages like ‘dplyr’, ‘broom’, ‘tidyr’, and ‘ggplot2’.\n\nFigure below shows the workflow using tidytext approach for processing and visualising text data.\n\n\n5.6.1 Removing header and automated email signitures\nNotice that each message has some structure and extra text that we don’t want to include in our analysis. For example, every message has a header, containing field such as “from:” or “in_reply_to:” that describe the message. Some also have automated email signatures, which occur after a line like “–”.\n\ncleaned_text &lt;- raw_text %&gt;%\n  group_by(newsgroup, id) %&gt;%\n  filter(cumsum(text == \"\") &gt; 0,\n         cumsum(str_detect(\n           text, \"^--\")) == 0) %&gt;%\n  ungroup()\n\n\n\n5.6.2 Removing lines with nested text representing quotes from other users.\nIn this code chunk below, regular expressions are used to remove with nested text representing quotes from other users.\n\ncleaned_text &lt;- cleaned_text %&gt;%\n  filter(str_detect(text, \"^[^&gt;]+[A-Za-z\\\\d]\")\n         | text == \"\",\n         !str_detect(text, \n                     \"writes(:|\\\\.\\\\.\\\\.)$\"),\n         !str_detect(text, \n                     \"^In article &lt;\")\n  )\n\n\n\n5.6.3 Text Data Processing\nIn this code chunk below, unnest_tokens() of tidytext package is used to split the dataset into tokens, while stop_words() is used to remove stop-words.\n\nusenet_words &lt;- cleaned_text %&gt;%\n  unnest_tokens(word, text) %&gt;%\n  filter(str_detect(word, \"[a-z']$\"),\n         !word %in% stop_words$word)\n\nNow that we’ve removed the headers, signatures, and formatting, we can start exploring common words. For starters, we could find the most common words in the entire dataset, or within particular newsgroups.\n\nusenet_words %&gt;%\n  count(word, sort = TRUE)\n\n# A tibble: 5,542 × 2\n   word           n\n   &lt;chr&gt;      &lt;int&gt;\n 1 people        57\n 2 time          50\n 3 jesus         47\n 4 god           44\n 5 message       40\n 6 br            27\n 7 bible         23\n 8 drive         23\n 9 homosexual    23\n10 read          22\n# ℹ 5,532 more rows\n\n\nInstead of counting individual word, you can also count words within by newsgroup by using the code chunk below.\n\nwords_by_newsgroup &lt;- usenet_words %&gt;%\n  count(newsgroup, word, sort = TRUE) %&gt;%\n  ungroup()\n\n\n\n5.6.4 Visualising Words in newsgroups\nIn this code chunk below, wordcloud() of wordcloud package is used to plot a static wordcloud.\n\nwordcloud(words_by_newsgroup$word,\n          words_by_newsgroup$n,\n          max.words = 300)\n\n\n\n\n\n\n\n\n\n\n5.6.5 Visualising Words in newsgroups\nThe wordcloud below is plotted by using ggwordcloud package.\n\nset.seed(1234)\n\nwords_by_newsgroup &lt;- words_by_newsgroup %&gt;% filter(n &gt; 0)\nggplot(words_by_newsgroup,aes(label = word,\n           size = n)) +\n  geom_text_wordcloud() +\n  theme_minimal() +\n  facet_wrap(~ newsgroup)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05.html#basic-concept-of-tf-idf",
    "href": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05.html#basic-concept-of-tf-idf",
    "title": "Hands-on Exercise 5",
    "section": "5.7 Basic Concept of TF-IDF",
    "text": "5.7 Basic Concept of TF-IDF\n\ntf–idf, short for term frequency–inverse document frequency, is a numerical statistic that is intended to reflect how important a word is to a document in a collection of corpus.\n\n\n\n5.7.1 Computing tf-idf within newsgroups\nThe code chunk below uses bind_tf_idf() of tidytext to compute and bind the term frequency, inverse document frequency and ti-idf of a tidy text dataset to the dataset.\n\ntf_idf &lt;- words_by_newsgroup %&gt;%\n  bind_tf_idf(word, newsgroup, n) %&gt;%\n  arrange(desc(tf_idf))\n\n\n\n5.7.2 Visualising tf-idf as interactive table\n\nDT::datatable(tf_idf, filter = 'top') %&gt;% \n  formatRound(columns = c('tf', 'idf', \n                          'tf_idf'), \n              digits = 3) %&gt;%\n  formatStyle(0, \n              target = 'row', \n              lineHeight='25%')\n\n\n\n\n\n\n\n5.7.3 Visualising tf-idf within newsgroups\n\ntf_idf %&gt;%\n  filter(str_detect(newsgroup, \"^sci\\\\.\")) %&gt;%\n  group_by(newsgroup) %&gt;%\n  slice_max(tf_idf, \n            n = 12) %&gt;%\n  ungroup() %&gt;%\n  mutate(word = reorder(word, \n                        tf_idf)) %&gt;%\n  ggplot(aes(tf_idf, \n             word, \n             fill = newsgroup)) +\n  geom_col(show.legend = FALSE) +\n  facet_wrap(~ newsgroup, \n             scales = \"free\") +\n  labs(x = \"tf-idf\", \n       y = NULL)\n\n\n\n\n\n\n\n\n\n\n5.7.5 Counting and correlating pairs of words with the widyr package\n\nTo count the number of times that two words appear within the same document, or to see how correlated they are.\nMost operations for finding pairwise counts or correlations need to turn the data into a wide matrix first.\nwidyr package first ‘casts’ a tidy dataset into a wide matrix, performs an operation such as a correlation on it, then re-tidies the result.\n\n\n\nnewsgroup_cors &lt;- words_by_newsgroup %&gt;%\n  pairwise_cor(newsgroup, \n               word, \n               n, \n               sort = TRUE)\n\n\n\n5.7.6 Visualising correlation as a network\nNow, we can visualise the relationship between newgroups in network graph as shown below.\n\nset.seed(2017)\n\nnewsgroup_cors %&gt;%\n  filter(correlation &gt; .025) %&gt;%\n  graph_from_data_frame() %&gt;%\n  ggraph(layout = \"fr\") +\n  geom_edge_link(aes(alpha = correlation, \n                     width = correlation)) +\n  geom_node_point(size = 6, \n                  color = \"lightblue\") +\n  geom_node_text(aes(label = name),\n                 color = \"red\",\n                 repel = TRUE) +\n  theme_void()\n\n\n\n\n\n\n\n\n\n\n5.7.7 Bigram\nIn this code chunk below, a bigram data frame is created by using unnest_tokens() of tidytext.\n\nbigrams &lt;- cleaned_text %&gt;%\n  unnest_tokens(bigram, \n                text, \n                token = \"ngrams\", \n                n = 2)\nbigrams\n\n# A tibble: 28,824 × 3\n   newsgroup   id    bigram    \n   &lt;chr&gt;       &lt;chr&gt; &lt;chr&gt;     \n 1 alt.atheism 54256 &lt;NA&gt;      \n 2 alt.atheism 54256 &lt;NA&gt;      \n 3 alt.atheism 54256 as i      \n 4 alt.atheism 54256 i don't   \n 5 alt.atheism 54256 don't know\n 6 alt.atheism 54256 know this \n 7 alt.atheism 54256 this book \n 8 alt.atheism 54256 book i    \n 9 alt.atheism 54256 i will    \n10 alt.atheism 54256 will use  \n# ℹ 28,814 more rows\n\n\n\n\n5.7.8 Counting bigrams\nThe code chunk is used to count and sort the bigram data frame ascendingly.\n\nbigrams_count &lt;- bigrams %&gt;%\n  filter(bigram != 'NA') %&gt;%\n  count(bigram, sort = TRUE)\nbigrams_count\n\n# A tibble: 19,885 × 2\n   bigram       n\n   &lt;chr&gt;    &lt;int&gt;\n 1 of the     169\n 2 in the     113\n 3 to the      74\n 4 to be       59\n 5 for the     52\n 6 i have      48\n 7 that the    47\n 8 if you      40\n 9 on the      39\n10 it is       38\n# ℹ 19,875 more rows\n\n\n\n\n5.7.9 Cleaning bigram\nThe code chunk below is used to seperate the bigram into two words.\n\nbigrams_separated &lt;- bigrams %&gt;%\n  filter(bigram != 'NA') %&gt;%\n  separate(bigram, c(\"word1\", \"word2\"), \n           sep = \" \")\n\nbigrams_filtered &lt;- bigrams_separated %&gt;%\n  filter(!word1 %in% stop_words$word) %&gt;%\n  filter(!word2 %in% stop_words$word)\nbigrams_filtered\n\n# A tibble: 4,604 × 4\n   newsgroup   id    word1        word2        \n   &lt;chr&gt;       &lt;chr&gt; &lt;chr&gt;        &lt;chr&gt;        \n 1 alt.atheism 54256 defines      god          \n 2 alt.atheism 54256 term         preclues     \n 3 alt.atheism 54256 science      ideas        \n 4 alt.atheism 54256 ideas        drawn        \n 5 alt.atheism 54256 supernatural precludes    \n 6 alt.atheism 54256 scientific   assertions   \n 7 alt.atheism 54256 religious    dogma        \n 8 alt.atheism 54256 religion     involves     \n 9 alt.atheism 54256 involves     circumventing\n10 alt.atheism 54256 gain         absolute     \n# ℹ 4,594 more rows\n\n\n\n\n5.7.10 Counting the bigram again\n\nbigram_counts &lt;- bigrams_filtered %&gt;% \n  count(word1, word2, sort = TRUE)\nbigram_counts\n\n# A tibble: 4,135 × 3\n   word1   word2     n\n   &lt;chr&gt;   &lt;chr&gt; &lt;int&gt;\n 1 1       2        12\n 2 1       3        12\n 3 static  void     10\n 4 time    pad      10\n 5 1       4         8\n 6 infield fly       7\n 7 mat     28        6\n 8 vv      vv        6\n 9 1       5         5\n10 cock    crow      5\n# ℹ 4,125 more rows\n\n\n\n\n5.7.11 Create a network graph from bigram data frame\nIn the code chunk below, a network graph is created by using graph_from_data_frame() of igraph package.\n\nbigram_graph &lt;- bigram_counts %&gt;%\n  filter(n &gt; 3) %&gt;%\n  graph_from_data_frame()\nbigram_graph\n\nIGRAPH 1649bbf DN-- 40 24 -- \n+ attr: name (v/c), n (e/n)\n+ edges from 1649bbf (vertex names):\n [1] 1          -&gt;2           1          -&gt;3           static     -&gt;void       \n [4] time       -&gt;pad         1          -&gt;4           infield    -&gt;fly        \n [7] mat        -&gt;28          vv         -&gt;vv          1          -&gt;5          \n[10] cock       -&gt;crow        noticeshell-&gt;widget      27         -&gt;1993       \n[13] 3          -&gt;4           child      -&gt;molestation cock       -&gt;crew       \n[16] gun        -&gt;violence    heat       -&gt;sink        homosexual -&gt;male       \n[19] homosexual -&gt;women       include    -&gt;xol         mary       -&gt;magdalene  \n[22] read       -&gt;write       rev        -&gt;20          tt         -&gt;ee         \n\n\n\n\n5.7.12 Visualizing a network of bigrams with ggraph\nIn this code chunk below, ggraph package is used to plot the bigram.\n\nset.seed(1234)\n\nggraph(bigram_graph, layout = \"fr\") +\n  geom_edge_link() +\n  geom_node_point() +\n  geom_node_text(aes(label = name), \n                 vjust = 1, \n                 hjust = 1)\n\n\n\n\n\n\n\n\n\n\n5.7.13 Revised version\n\nset.seed(1234)\n\na &lt;- grid::arrow(type = \"closed\", \n                 length = unit(.15,\n                               \"inches\"))\n\nggraph(bigram_graph, \n       layout = \"fr\") +\n  geom_edge_link(aes(edge_alpha = n), \n                 show.legend = FALSE,\n                 arrow = a, \n                 end_cap = circle(.07,\n                                  'inches')) +\n  geom_node_point(color = \"lightblue\", \n                  size = 5) +\n  geom_node_text(aes(label = name), \n                 vjust = 1, \n                 hjust = 1) +\n  theme_void()"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05.html#references",
    "href": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05.html#references",
    "title": "Hands-on Exercise 5",
    "section": "5.8 References",
    "text": "5.8 References\n\n5.8.0.1 widyr\n\nReference guide\n\nwidyr: Widen, process, and re-tidy a dataset\nUnited Nations Voting Correlations"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04_partb.html",
    "href": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04_partb.html",
    "title": "Hands-on Exercise 4: Part B",
    "section": "",
    "text": "Visualising uncertainty is relatively new in statistical graphics. In this chapter, you will gain hands-on experience on creating statistical graphics for visualising uncertainty. By the end of this chapter you will be able:\n\nto plot statistics error bars by using ggplot2,\nto plot interactive error bars by combining ggplot2, plotly and DT,\nto create advanced by using ggdist, and\nto create hypothetical outcome plots (HOPs) by using ungeviz package."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04_partb.html#learning-outcome",
    "href": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04_partb.html#learning-outcome",
    "title": "Hands-on Exercise 4: Part B",
    "section": "",
    "text": "Visualising uncertainty is relatively new in statistical graphics. In this chapter, you will gain hands-on experience on creating statistical graphics for visualising uncertainty. By the end of this chapter you will be able:\n\nto plot statistics error bars by using ggplot2,\nto plot interactive error bars by combining ggplot2, plotly and DT,\nto create advanced by using ggdist, and\nto create hypothetical outcome plots (HOPs) by using ungeviz package."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04_partb.html#getting-started",
    "href": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04_partb.html#getting-started",
    "title": "Hands-on Exercise 4: Part B",
    "section": "5.2 Getting Started",
    "text": "5.2 Getting Started\n\n5.2.1 Installing and loading the packages\nFor the purpose of this exercise, the following R packages will be used, they are:\n\ntidyverse, a family of R packages for data science process,\nplotly for creating interactive plot,\ngganimate for creating animation plot,\nDT for displaying interactive html table,\ncrosstalk for for implementing cross-widget interactions (currently, linked brushing and filtering), and\nggdist for visualising distribution and uncertainty.\n\n\ndevtools::install_github(\"wilkelab/ungeviz\")\n\n\npacman::p_load(ungeviz, plotly, crosstalk, DT, ggdist, ggridges,\n               colorspace, gganimate, tidyverse)\n\n\n\n5.2.2 Data import\nFor the purpose of this exercise, Exam_data.csv will be used.\n\nexam &lt;- read_csv(\"data/Exam_data.csv\")"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04_partb.html#visualizing-the-uncertainty-of-point-estimates-ggplot2-methods",
    "href": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04_partb.html#visualizing-the-uncertainty-of-point-estimates-ggplot2-methods",
    "title": "Hands-on Exercise 4: Part B",
    "section": "5.3 Visualizing the uncertainty of point estimates: ggplot2 methods",
    "text": "5.3 Visualizing the uncertainty of point estimates: ggplot2 methods\nIn this section, you will learn how to plot error bars of maths scores by race by using data provided in exam tibble data frame.\nFirstly, code chunk below will be used to derive the necessary summary statistics.\n\nmy_sum &lt;- exam %&gt;%\n  group_by(RACE) %&gt;%\n  summarise(\n    n=dplyr::n(),\n    mean=mean(MATHS),\n    sd=sd(MATHS)\n  ) %&gt;%\n  mutate(se=sd/sqrt(n - 1))\n\n\n\n\n\n\n\nThings to learn from code chunk above\n\n\n\n\ngroup_by() of dplyr package is used to group the observation by RACE,\nsummarise() is used to compute the count of observations, mean, standard deviation\nmutate() is used to derive standard error of Maths by RACE, and\nthe output is save as a tibble data table called my_sum.\n\n\n\nNext, the code chunk below will be used to display my_sum tibble data frame in an html table format.\n\nThe codeThe table\n\n\n\nknitr::kable(head(my_sum), format = 'html')\n\n\n\n\n\n\n\n\n\nRACE\nn\nmean\nsd\nse\n\n\n\n\nChinese\n193\n76.50777\n15.69040\n1.132357\n\n\nIndian\n12\n60.66667\n23.35237\n7.041005\n\n\nMalay\n108\n57.44444\n21.13478\n2.043177\n\n\nOthers\n9\n69.66667\n10.72381\n3.791438\n\n\n\n\n\n\n\n\n\n\n\n\n5.3.1 Plotting standard error bars of point estimates\nNow we are ready to plot the standard error bars of mean maths score by race as shown below.\n\nThe plotThe code\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nggplot(my_sum) +\n  geom_errorbar(\n    aes(x = RACE,\n        ymin = mean - se,\n        ymax = mean + se),\n    width = 0.2,\n    colour = \"black\",\n    alpha = 0.9,\n    size = 0.5) +\n  geom_point(\n    aes(x = RACE,\n        y = mean),\n    stat = \"identity\",\n    color = \"red\",\n    size = 1.5,\n    alpha = 1) +\n  ggtitle(\"Standard error of mean Maths scores by rac\")\n\n\n\n\n\n\n\n\n\n\nThings to learn from code chunk above\n\n\n\n\nThe error bars are computed by using the formula mean+/-se.\nFor geom_point(), it is important to indicate stat=“identity”.\n\n\n\n\n\n5.3.2 Plotting confidence interval of point estimates\nInstead of plotting the standard error bar of point estimates, we can also plot the confidence intervals of mean maths score by race.\n\nThe plotThe code\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nggplot(my_sum) +\n  geom_errorbar(\n    aes(x=reorder(RACE, -mean), \n        ymin=mean-1.96*se, \n        ymax=mean+1.96*se), \n    width=0.2, \n    colour=\"black\", \n    alpha=0.9, \n    size=0.5) +\n  geom_point(aes\n           (x=RACE, \n            y=mean), \n           stat=\"identity\", \n           color=\"red\",\n           size = 1.5,\n           alpha=1) +\n  labs(x = \"Maths score\",\n       title = \"95% confidence interval of mean maths score by race\")\n\n\n\n\n\n\n\n\n\n\nTip\n\n\n\nThings to learn from the code chunk above\n\nThe confidence intervals are computed by using the formula mean+/-1.96*se.\nThe error bars is sorted by using the average maths scores.\nlabs() argument of ggplot2 is used to change the x-axis label.\n\n\n\n\n\n5.3.3 Visualizing the uncertainty of point estimates with interactive error bars\nIn this section, you will learn how to plot interactive error bars for the 99% confidence interval of mean maths score by race as shown in the figure below.\n\nThe plotThe code\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nshared_df = SharedData$new(my_sum)\n\nbscols(widths = c(4,8),\n       ggplotly((ggplot(shared_df) +\n                   geom_errorbar(aes(\n                     x=reorder(RACE, -mean),\n                     ymin=mean-2.58*se, \n                     ymax=mean+2.58*se), \n                     width=0.2, \n                     colour=\"black\", \n                     alpha=0.9, \n                     size=0.5) +\n                   geom_point(aes(\n                     x=RACE, \n                     y=mean, \n                     text = paste(\"Race:\", `RACE`, \n                                  \"&lt;br&gt;N:\", `n`,\n                                  \"&lt;br&gt;Avg. Scores:\", round(mean, digits = 2),\n                                  \"&lt;br&gt;95% CI:[\", \n                                  round((mean-2.58*se), digits = 2), \",\",\n                                  round((mean+2.58*se), digits = 2),\"]\")),\n                     stat=\"identity\", \n                     color=\"red\", \n                     size = 1.5, \n                     alpha=1) + \n                   xlab(\"Race\") + \n                   ylab(\"Average Scores\") + \n                   theme_minimal() + \n                   theme(axis.text.x = element_text(\n                     angle = 45, vjust = 0.5, hjust=1)) +\n                   ggtitle(\"99% Confidence interval of average /&lt;br&gt;maths scores by race\")), \n                tooltip = \"text\"), \n       DT::datatable(shared_df, \n                     rownames = FALSE, \n                     class=\"compact\", \n                     width=\"100%\", \n                     options = list(pageLength = 10,\n                                    scrollX=T), \n                     colnames = c(\"No. of pupils\", \n                                  \"Avg Scores\",\n                                  \"Std Dev\",\n                                  \"Std Error\")) %&gt;%\n         formatRound(columns=c('mean', 'sd', 'se'),\n                     digits=2))"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04_partb.html#visualising-uncertainty-ggdist-package",
    "href": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04_partb.html#visualising-uncertainty-ggdist-package",
    "title": "Hands-on Exercise 4: Part B",
    "section": "5.4 Visualising Uncertainty: ggdist package",
    "text": "5.4 Visualising Uncertainty: ggdist package\n\nggdist is an R package that provides a flexible set of ggplot2 geoms and stats designed especially for visualising distributions and uncertainty.\nIt is designed for both frequentist and Bayesian uncertainty visualization, taking the view that uncertainty visualization can be unified through the perspective of distribution visualization:\n\nfor frequentist models, one visualises confidence distributions or bootstrap distributions (see vignette(“freq-uncertainty-vis”));\nfor Bayesian models, one visualises probability distributions (see the tidybayes package, which builds on top of ggdist).\n\n\n\n5.4.1 Visualizing the uncertainty of point estimates: ggdist methods\nIn the code chunk below, stat_pointinterval() of ggdist is used to build a visual for displaying distribution of maths scores by race.\n\nexam %&gt;%\n  ggplot(aes(x = RACE,\n             y = MATHS)) +\n  stat_pointinterval() +\n  labs(\n    title = \"Visualising confidence intervals of mean math score\",\n    subtitle = \"Mean Point + Multiple-interval plot\"\n  )\n\n\n\n\n\n\n\n\nFor example, in the code chunk below the following arguments are used:\n\n.width = 0.95\n.point = median\n.interval = qi\n\n\nexam %&gt;%\n  ggplot(aes(x = RACE, y = MATHS)) +\n  stat_pointinterval(.width = 0.95,\n  .point = median,\n  .interval = qi) +\n  labs(\n    title = \"Visualising confidence intervals of median math score\",\n    subtitle = \"Median Point + Multiple-interval plot\")\n\n\n\n\n\n\n\n\n\n\n5.4.2 Visualizing the uncertainty of point estimates: ggdist methods\nShowing 95% and 99% Confidence Intervals\n\nexam %&gt;%\n  ggplot(aes(x = RACE, \n             y = MATHS)) +\n  stat_pointinterval(\n    .width = c(0.95, 0.99),\n    show.legend = FALSE) +   \n  labs(\n    title = \"Visualising confidence intervals of mean math score\",\n    subtitle = \"Mean Point + Multiple-interval plot\")\n\n\n\n\n\n\n\n\n\n\n5.4.3 Visualizing the uncertainty of point estimates: ggdist methods\nIn the code chunk below, stat_gradientinterval() of ggdist is used to build a visual for displaying distribution of maths scores by race.\n\nexam %&gt;%\n  ggplot(aes(x = RACE, \n             y = MATHS)) +\n  stat_gradientinterval(   \n    fill = \"skyblue\",      \n    show.legend = TRUE     \n  ) +                        \n  labs(\n    title = \"Visualising confidence intervals of mean math score\",\n    subtitle = \"Gradient + interval plot\")"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04_partb.html#visualising-uncertainty-with-hypothetical-outcome-plots-hops",
    "href": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04_partb.html#visualising-uncertainty-with-hypothetical-outcome-plots-hops",
    "title": "Hands-on Exercise 4: Part B",
    "section": "5.5 Visualising Uncertainty with Hypothetical Outcome Plots (HOPs)",
    "text": "5.5 Visualising Uncertainty with Hypothetical Outcome Plots (HOPs)\n\nggplot(data = exam, \n       (aes(x = factor(RACE), y = MATHS))) +\n  geom_point(position = position_jitter(\n    height = 0.3, width = 0.05), \n    size = 0.4, color = \"#0072B2\", alpha = 1/2) +\n  geom_hpline(data = sampler(25, group = RACE), height = 0.6, color = \"#D55E00\") +\n  theme_bw() + \n  # `.draw` is a generated column indicating the sample draw\n  transition_states(.draw, 1, 3)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03_partb.html",
    "href": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03_partb.html",
    "title": "Hands-on Exercise 3: Part B",
    "section": "",
    "text": "In this hands-on exercise, we will learn how to create animated data visualisation by using gganimate and plotly r packages. At the same time, we will also (i) reshape data by using tidyr package, and (ii) process, wrangle and transform data by using dplyr package.\n\n\nWhen creating animations, the plot does not actually move. Instead, many individual plots are built and then stitched together as movie frames, just like an old-school flip book or cartoon. Each frame is a different plot when conveying motion, which is built using some relevant subset of the aggregate data. The subset drives the flow of the animation when stitched back together.\n\n\n\n\nBefore we dive into the steps for creating an animated statistical graph, it’s important to understand some of the key concepts and terminology related to this type of visualization.\n\nFrame: In an animated line graph, each frame represents a different point in time or a different category. When the frame changes, the data points on the graph are updated to reflect the new data.\nAnimation Attributes: The animation attributes are the settings that control how the animation behaves. For example, you can specify the duration of each frame, the easing function used to transition between frames, and whether to start the animation from the current frame or from the beginning."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03_partb.html#overview",
    "href": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03_partb.html#overview",
    "title": "Hands-on Exercise 3: Part B",
    "section": "",
    "text": "In this hands-on exercise, we will learn how to create animated data visualisation by using gganimate and plotly r packages. At the same time, we will also (i) reshape data by using tidyr package, and (ii) process, wrangle and transform data by using dplyr package.\n\n\nWhen creating animations, the plot does not actually move. Instead, many individual plots are built and then stitched together as movie frames, just like an old-school flip book or cartoon. Each frame is a different plot when conveying motion, which is built using some relevant subset of the aggregate data. The subset drives the flow of the animation when stitched back together.\n\n\n\n\nBefore we dive into the steps for creating an animated statistical graph, it’s important to understand some of the key concepts and terminology related to this type of visualization.\n\nFrame: In an animated line graph, each frame represents a different point in time or a different category. When the frame changes, the data points on the graph are updated to reflect the new data.\nAnimation Attributes: The animation attributes are the settings that control how the animation behaves. For example, you can specify the duration of each frame, the easing function used to transition between frames, and whether to start the animation from the current frame or from the beginning."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03_partb.html#getting-started",
    "href": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03_partb.html#getting-started",
    "title": "Hands-on Exercise 3: Part B",
    "section": "4.2 Getting Started",
    "text": "4.2 Getting Started\n\n4.2.1 Loading the R packages\n\npacman::p_load(readxl, gifski, gapminder,\n               plotly, gganimate, tidyverse)\n\n\n\n4.2.2 Importing the data\nIn this hands-on exercise, the Data worksheet from GlobalPopulation Excel workbook will be used.\nThe code below imports Data worksheet from GlobalPopulation Excel workbook by using appropriate R package from tidyverse family.\n\ncol &lt;- c(\"Country\", \"Continent\")\nglobalPop &lt;- read_xls(\"data/GlobalPopulation.xls\",\n                      sheet=\"Data\") %&gt;%\n  mutate(across(col, as.factor)) %&gt;%\n  mutate(Year = as.integer(Year))"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03_partb.html#animated-data-visualisation-gganimate-methods",
    "href": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03_partb.html#animated-data-visualisation-gganimate-methods",
    "title": "Hands-on Exercise 3: Part B",
    "section": "4.3 Animated Data Visualisation: gganimate methods",
    "text": "4.3 Animated Data Visualisation: gganimate methods\ngganimate extends the grammar of graphics as implemented by ggplot2 to include the description of animation. It does this by providing a range of new grammar classes that can be added to the plot object in order to customise how it should change with time.\n\ntransition_*() defines how the data should be spread out and how it relates to itself across time.\nview_*() defines how the positional scales should change along the animation.\nshadow_*() defines how data from other points in time should be presented in the given point in time.\nenter_*()/exit_*() defines how new data should appear and how old data should disappear during the course of the animation.\nease_aes() defines how different aesthetics should be eased during transitions.\n\n\n4.3.1 Building a static population bubble plot\nIn the code chunk below, the basic ggplot2 functions are used to create a static bubble plot.\n\nggplot(globalPop,\n       aes(x = Old, y = Young, \n                      size = Population, \n                      colour = Country)) +\n  geom_point(alpha = 0.7, \n             show.legend = FALSE) +\n  scale_colour_manual(values = country_colors) +\n  scale_size(range = c(2, 12)) +\n  labs(title = 'Year: {frame_time}', \n       x = '% Aged', \n       y = '% Young') \n\n\n\n\n\n\n\n\n\n\n4.3.2 Building the animated bubble plot\nIn the code chunk below,\n\ntransition_time() of gganimate is used to create transition through distinct states in time (i.e. Year).\nease_aes() is used to control easing of aesthetics. The default is linear. Other methods are: quadratic, cubic, quartic, quintic, sine, circular, exponential, elastic, back, and bounce.\n\n\nggplot(globalPop,\n       aes(x = Old, y = Young,\n           size = Population, colour = Country)) +\n  geom_point(alpha = 0.7, show.legend = FALSE) +\n  scale_colour_manual(values= country_colors) +\n  scale_size(range = c(2,12)) +\n  labs(title = 'Year:{frame_time}',\n       x = '% Aged',\n       y = '% Young') +\n  transition_time(Year) +\n  ease_aes('linear')"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03_partb.html#animated-data-visualisation-plotly",
    "href": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03_partb.html#animated-data-visualisation-plotly",
    "title": "Hands-on Exercise 3: Part B",
    "section": "4.4 Animated Data Visualisation: plotly",
    "text": "4.4 Animated Data Visualisation: plotly\nIn Plotly R package, both ggplotly() and plot_ly() support key frame animations through the frame argument/aesthetic. They also support an ids argument/aesthetic to ensure smooth transitions between objects with the same id (which helps facilitate object constancy).\n\n4.4.1 Building an animated bubble plot: ggplotly() method\nIn this sub-section, you will learn how to create an animated bubble plot by using ggplotly() method.\n\nThe plotThe code\n\n\n\n\n\n\n\n\n\n\n\ngg &lt;- ggplot(globalPop,\n             aes(x = Old, y = Young,\n                 size = Population,\n                 colour = Country)) +\n  geom_point(aes(size = Population,\n                 frame = Year),\n             alpha = 0.7,\n             show.legend = FALSE) +\n  scale_colour_manual(values = country_colors) +\n  scale_size(range = c(2,12)) +\n  labs(x = '% Aged', \n       y = '% Young')\nggplotly(gg)\n\n\n\n\nNotice that although show.legend = FALSE argument was used, the legend still appears on the plot. To overcome this problem, theme(legend.position='none') should be used as shown in the plot and code chunk below.\n\nThe plotThe code\n\n\n\n\n\n\n\n\n\n\n\ngg &lt;- ggplot(globalPop, \n       aes(x = Old, \n           y = Young, \n           size = Population, \n           colour = Country)) +\n  geom_point(aes(size = Population,\n                 frame = Year),\n             alpha = 0.7) +\n  scale_colour_manual(values = country_colors) +\n  scale_size(range = c(2, 12)) +\n  labs(x = '% Aged', \n       y = '% Young') + \n  theme(legend.position='none')\n\nggplotly(gg)\n\n\n\n\n\n\n4.4.2 Building an animated bubble plot: plot_ly() method\nIn this sub-section, you will learn how to create an animated bubble plot by using plot_ly() method.\n\nThe plotThe code\n\n\n\n\n\n\n\n\n\n\n\nbp &lt;- globalPop %&gt;%\n  plot_ly(x = ~Old,\n          y = ~Young,\n          size = ~Population,\n          color = ~Continent,\n          sizes = c(2,100),\n          frame = ~Year,\n          text = ~Country,\n          hoverinfo = \"text\",\n          type = 'scatter',\n          mode = 'markers') %&gt;%\n          layout(show.legend = FALSE)\nbp"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03_partb.html#reference",
    "href": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03_partb.html#reference",
    "title": "Hands-on Exercise 3: Part B",
    "section": "4.5 Reference",
    "text": "4.5 Reference\n\nGetting Started\nBuilding an animation step-by-step with gganimate.\nCreating a composite gif with multiple gganimate panels"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02.html",
    "href": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02.html",
    "title": "Hands-on Exercise 2",
    "section": "",
    "text": "pacman::p_load(ggrepel, patchwork, ggthemes, hrbrthemes, tidyverse)\n\n\n\n\nThe code chunk below imports exam_data.csv into R environment by using read_csv() function of readr package. readr is one of the tidyverse package.\n\nexam_data &lt;- read_csv(\"data/Exam_data.csv\")\n\nThere are a total of seven attributes in the exam_data tibble data frame. Four of them are categorical data type and the other three are in continuous data type.\n\nThe categorical attributes are: ID, CLASS, GENDER and RACE.\nThe continuous attributes are: MATHS, ENGLISH and SCIENCE."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02.html#installing-and-loading-the-required-libraries",
    "href": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02.html#installing-and-loading-the-required-libraries",
    "title": "Hands-on Exercise 2",
    "section": "",
    "text": "pacman::p_load(ggrepel, patchwork, ggthemes, hrbrthemes, tidyverse)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02.html#importing-the-data",
    "href": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02.html#importing-the-data",
    "title": "Hands-on Exercise 2",
    "section": "",
    "text": "The code chunk below imports exam_data.csv into R environment by using read_csv() function of readr package. readr is one of the tidyverse package.\n\nexam_data &lt;- read_csv(\"data/Exam_data.csv\")\n\nThere are a total of seven attributes in the exam_data tibble data frame. Four of them are categorical data type and the other three are in continuous data type.\n\nThe categorical attributes are: ID, CLASS, GENDER and RACE.\nThe continuous attributes are: MATHS, ENGLISH and SCIENCE."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02.html#working-with-ggrepel",
    "href": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02.html#working-with-ggrepel",
    "title": "Hands-on Exercise 2",
    "section": "Working with ggrepel",
    "text": "Working with ggrepel\nWe simply replace geom_text() by geom_text_repel() and geom_label() by geom_label_repel\n\nThe plotThe code\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nggplot(data = exam_data,\n       aes(x = MATHS,\n           y = ENGLISH)) +\n  geom_point() +\n  geom_smooth(method=lm,\n              size=0.5) +\n  geom_label_repel(aes(label = ID),\n             fontface=\"bold\") + \n  coord_cartesian(xlim = c(0,100),\n                  ylim = c(0,100)) + \n  ggtitle(\"English scores versus Maths scores for Primary 3\")"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02.html#working-with-ggtheme-package",
    "href": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02.html#working-with-ggtheme-package",
    "title": "Hands-on Exercise 2",
    "section": "Working with ggtheme package",
    "text": "Working with ggtheme package\n\nThe plotThe code\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nggplot(data = exam_data,\n       aes(x = MATHS)) + \n  geom_histogram(bins = 20,\n                 boundary = 100,\n                 color = \"grey25\",\n                 fill = \"grey90\") + \n  ggtitle(\"Distribution of Maths scores\") +\n  theme_economist()"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02.html#working-with-hrbthemes-package",
    "href": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02.html#working-with-hrbthemes-package",
    "title": "Hands-on Exercise 2",
    "section": "Working with hrbthemes package",
    "text": "Working with hrbthemes package\n\nThe plotThe code\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nggplot(data = exam_data,\n       aes(x = MATHS)) + \n  geom_histogram(bins = 20,\n                 boundary = 100,\n                 color = \"grey25\",\n                 fill = \"grey90\") + \n  ggtitle(\"Distribution of Maths scores\") +\n  theme_ipsum()\n\n\n\n\nThe second goal centers around productivity for a production workflow. In fact, this “production workflow” is the context for where the elements of hrbrthemes should be used.\n\nThe plotThe code\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nggplot(data = exam_data,\n       aes(x = MATHS)) + \n  geom_histogram(bins = 20,\n                 boundary = 100,\n                 color = \"grey25\",\n                 fill = \"grey90\") + \n  ggtitle(\"Distribution of Maths scores\") +\n  theme_ipsum(axis_title_size = 18,\n              base_size = 15,\n              grid = \"Y\")"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02.html#creating-composite-graphics-pathwork-methods",
    "href": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02.html#creating-composite-graphics-pathwork-methods",
    "title": "Hands-on Exercise 2",
    "section": "Creating Composite Graphics: pathwork methods",
    "text": "Creating Composite Graphics: pathwork methods\nIn this section, I am going to shared with you an ggplot2 extension called patchwork which is specially designed for combining separate ggplot2 graphs into a single figure.\nPatchwork package has a very simple syntax where we can create layouts super easily. Here’s the general syntax that combines:\n\nTwo-Column Layout using the Plus Sign +.\nParenthesis () to create a subplot group.\nTwo-Row Layout using the Division Sign /"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02.html#combining-two-ggplot2-graphs",
    "href": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02.html#combining-two-ggplot2-graphs",
    "title": "Hands-on Exercise 2",
    "section": "Combining two ggplot2 graphs",
    "text": "Combining two ggplot2 graphs\nFigure in the tabset below shows a composite of two histograms created using patchwork. Note how simple the syntax used to create the plot!\n\nThe plotThe code\n\n\n\n\n\n\n\n\n\n\n\n\n\n\np1 + p2"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02.html#combining-three-ggplot2-graphs",
    "href": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02.html#combining-three-ggplot2-graphs",
    "title": "Hands-on Exercise 2",
    "section": "Combining three ggplot2 graphs",
    "text": "Combining three ggplot2 graphs\nWe can plot more complex composite by using appropriate operators. For example, the composite figure below is plotted by using:\n\n“/” operator to stack two ggplot2 graphs,\n“|” operator to place the plots beside each other,\n“()” operator the define the sequence of the plotting.\n\n\nThe plotThe code\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n(p1 / p2) | p3"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02.html#creating-a-composite-figure-with-tag",
    "href": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02.html#creating-a-composite-figure-with-tag",
    "title": "Hands-on Exercise 2",
    "section": "Creating a composite figure with tag",
    "text": "Creating a composite figure with tag\nIn order to identify subplots in text, patchwork also provides auto-tagging capabilities as shown in the figure below.\n\nThe plotThe code\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n((p1 / p2) | p3) +\n  plot_annotation(tag_levels = 'I')\n\n\n\n\n\nCreating figure with insert\nBeside providing functions to place plots next to each other based on the provided layout. With inset_element() of patchwork, we can place one or several plots or graphic elements freely on top or below another plot.\n\nThe plotThe code\n\n\n\n\n\n\n\n\n\n\n\n\n\n\np3 + inset_element(p2,\n                   left = 0.02,\n                   bottom = 0.7,\n                   right = 0.5,\n                   top = 1)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02.html#creating-a-composite-figure-by-using-patchwork-and-ggtheme",
    "href": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02.html#creating-a-composite-figure-by-using-patchwork-and-ggtheme",
    "title": "Hands-on Exercise 2",
    "section": "Creating a composite figure by using patchwork and ggtheme",
    "text": "Creating a composite figure by using patchwork and ggtheme\nFigure below is created by combining patchwork and theme_economist() of ggthemes package discussed earlier.\n\nThe plotThe code\n\n\n\n\n\n\n\n\n\n\n\n\n\n\npatchwork &lt;- (p1 / p2) | p3\npatchwork & theme_economist()"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02.html#reference",
    "href": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02.html#reference",
    "title": "Hands-on Exercise 2",
    "section": "Reference",
    "text": "Reference\n\nPatchwork R package goes nerd viral\nggrepel\nggthemes\nhrbrthemes\nggplot tips: Arranging plots\nggplot2 Theme Elements Demonstration\nggplot2 Theme Elements Reference Sheet"
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "About this site\n\n1 + 1\n\n[1] 2"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html",
    "href": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html",
    "title": "Hands-on Exercise 1",
    "section": "",
    "text": "pacman::p_load(tidyverse)\n\n\n\n\n\nexam_data &lt;- read_csv(\"data/Exam_data.csv\")\n\nRows: 322 Columns: 7\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (4): ID, CLASS, GENDER, RACE\ndbl (3): ENGLISH, MATHS, SCIENCE\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#installing-and-loading-r-packages",
    "href": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#installing-and-loading-r-packages",
    "title": "Hands-on Exercise 1",
    "section": "",
    "text": "pacman::p_load(tidyverse)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#importing-the-data",
    "href": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#importing-the-data",
    "title": "Hands-on Exercise 1",
    "section": "",
    "text": "exam_data &lt;- read_csv(\"data/Exam_data.csv\")\n\nRows: 322 Columns: 7\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (4): ID, CLASS, GENDER, RACE\ndbl (3): ENGLISH, MATHS, SCIENCE\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#r-graphics-vs-ggplot",
    "href": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#r-graphics-vs-ggplot",
    "title": "Hands-on Exercise 1",
    "section": "R graphics vs ggplot",
    "text": "R graphics vs ggplot\nFirst, let us compare how R Graphics, the core graphical functions of Base R and ggplot plot a simple histogram.\n\nR graphicsggplot2\n\n\n\nhist(exam_data$MATHS)\n\n\n\n\n\n\n\n\n\n\n\nggplot(data = exam_data,\n       aes(x = MATHS)) +\n  geom_histogram(bins = 10,\n                 boundary = 100,\n                 colour = \"black\",\n                 fill = \"grey\") +\n  ggtitle(\"Distribution of Maths scores\")\n\n\n\n\n\n\n\n\n\n\n\nAs you can see that the code chunk is relatively simple if R Graphics is used."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#plotting-a-bar-chart",
    "href": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#plotting-a-bar-chart",
    "title": "Hands-on Exercise 1",
    "section": "Plotting a Bar chart",
    "text": "Plotting a Bar chart\n\nggplot(data=exam_data, \n       aes(x=RACE)) +\n  geom_bar()"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#plotting-a-dot-plot",
    "href": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#plotting-a-dot-plot",
    "title": "Hands-on Exercise 1",
    "section": "Plotting a Dot plot",
    "text": "Plotting a Dot plot\nIn a dot plot, the width of a dot corresponds to the bin width (or maximum width, depending on the binning algorithm), and dots are stacked, with each dot representing one observation.\n\nggplot(data=exam_data, \n       aes(x = MATHS)) +\n  geom_dotplot(dotsize = 0.5)\n\nBin width defaults to 1/30 of the range of the data. Pick better value with\n`binwidth`.\n\n\n\n\n\n\n\n\n\nThe scale_y_continuous() is used to turn off the y-axis, and binwidth argument is used to change the binwidth to 2.5.\n\nggplot(data=exam_data, \n       aes(x = MATHS)) +\n  geom_dotplot(binwidth=2.5,         \n               dotsize = 0.5) +      \n  scale_y_continuous(NULL,           \n                     breaks = NULL)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#plotting-a-histogram",
    "href": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#plotting-a-histogram",
    "title": "Hands-on Exercise 1",
    "section": "Plotting a histogram",
    "text": "Plotting a histogram\nPlot a histogram for Maths scores\n\nggplot(data=exam_data, \n       aes(x = MATHS)) +\n  geom_histogram()       \n\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n\n\n\n\n\n\n\n\n\nModify the geometric object by changing the geom() object\n\nggplot(data=exam_data, \n       aes(x= MATHS)) +\n  geom_histogram(bins=20,            \n                 color=\"black\",      \n                 fill=\"light blue\")  \n\n\n\n\n\n\n\n\nModify the geometric object by changing the aes() object\n\nggplot(data=exam_data, \n       aes(x= MATHS, \n           fill = GENDER)) +\n  geom_histogram(bins=20, \n                 color=\"grey30\")"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#plotting-the-kernel-estimate-density-plot",
    "href": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#plotting-the-kernel-estimate-density-plot",
    "title": "Hands-on Exercise 1",
    "section": "Plotting the kernel estimate density plot",
    "text": "Plotting the kernel estimate density plot\nThe code below plots the distribution of Maths scores in a kernel density estimate plot.\n\nggplot(data=exam_data, \n       aes(x = MATHS)) +\n  geom_density()           \n\n\n\n\n\n\n\n\nThe code chunk below plots two kernel density lines by using colour or fill arguments of aes()\n\nggplot(data=exam_data,\n       aes(x = MATHS,colour=GENDER)) +\n  geom_density()"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#plotting-a-boxplot",
    "href": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#plotting-a-boxplot",
    "title": "Hands-on Exercise 1",
    "section": "Plotting a Boxplot",
    "text": "Plotting a Boxplot\n\nggplot(data=exam_data,\n       aes(y= MATHS,x = GENDER)) +\n  geom_boxplot()\n\n\n\n\n\n\n\n\nThe code chunk below plots the distribution of Maths scores by gender in notched plot instead of boxplot.\n\nggplot(data=exam_data,\n       aes(y = MATHS,x = GENDER)) +\n  geom_boxplot(notch=TRUE)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#plotting-a-violin-plot",
    "href": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#plotting-a-violin-plot",
    "title": "Hands-on Exercise 1",
    "section": "Plotting a Violin Plot",
    "text": "Plotting a Violin Plot\nThe code below plot the distribution of Maths score by gender in violin plot.\n\nggplot(data=exam_data,\n       aes(y=MATHS, x=GENDER)) + \n  geom_violin()"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#plotting-a-scatter-plot",
    "href": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#plotting-a-scatter-plot",
    "title": "Hands-on Exercise 1",
    "section": "Plotting a Scatter Plot",
    "text": "Plotting a Scatter Plot\nThe code chunk below plots a scatterplot showing the Maths and English grades of pupils.\n\nggplot(data=exam_data,\n       aes(x=MATHS, y=ENGLISH)) +\n  geom_point()"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#combining-geom-objects-boxplots-and-scatter-plots",
    "href": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#combining-geom-objects-boxplots-and-scatter-plots",
    "title": "Hands-on Exercise 1",
    "section": "Combining geom objects: Boxplots and Scatter plots",
    "text": "Combining geom objects: Boxplots and Scatter plots\nThe code chunk below plots the data points on the boxplots by using both geom_boxplot() and geom_point().\n\nggplot(data=exam_data,\n       aes(y=MATHS, x=GENDER)) +\n  geom_point(position=\"jitter\", size=0.5) + \n  geom_boxplot()"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#working-with-stat---the-stat_summary-method",
    "href": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#working-with-stat---the-stat_summary-method",
    "title": "Hands-on Exercise 1",
    "section": "Working with stat - the stat_summary() method",
    "text": "Working with stat - the stat_summary() method\nThe code chunk below adds mean values by using stat_summary() function and overriding the default geom.\n\nggplot(data=exam_data,\n       aes(y=MATHS, x=GENDER)) +\n  geom_boxplot() +\n  stat_summary(geom= \"point\",\n               fun= \"mean\",\n               colour= \"red\",\n               size= 4)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#working-with-stat---the-geom-method",
    "href": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#working-with-stat---the-geom-method",
    "title": "Hands-on Exercise 1",
    "section": "Working with stat - the geom() method",
    "text": "Working with stat - the geom() method\nThe code chunk below adding mean values by using geom_() function and overriding the default stat.\n\nggplot(data=exam_data,\n       aes(y=MATHS, x=GENDER)) +\n  geom_boxplot() + \n  geom_point(stat=\"summary\",\n             fun= \"mean\",\n             colour= \"red\",\n             size= 4)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#adding-a-best-fit-curve-on-a-scatter-plot",
    "href": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#adding-a-best-fit-curve-on-a-scatter-plot",
    "title": "Hands-on Exercise 1",
    "section": "Adding a best fit curve on a scatter plot",
    "text": "Adding a best fit curve on a scatter plot\nThe scatterplot below shows the relationship of Maths and English grades of pupils. The interpretability of this graph can be improved by adding a best fit curve.In the code chunk below, geom_smooth() is used to plot a best fit curve on the scatterplot.\n\nggplot(data=exam_data,\n       aes(y= ENGLISH, x= MATHS)) +\n  geom_point() +\n  geom_smooth(linewidth=0.5)\n\n`geom_smooth()` using method = 'loess' and formula = 'y ~ x'\n\n\n\n\n\n\n\n\n\nThe default smoothing method is loess. The default smoothing method can be overridden as shown below.\n\nggplot(data= exam_data,\n       aes(y= ENGLISH, x= MATHS)) +\n  geom_point() +\n  geom_smooth(method= lm,\n              linewidth= 0.5)\n\n`geom_smooth()` using formula = 'y ~ x'"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#working-with-facet_wrap",
    "href": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#working-with-facet_wrap",
    "title": "Hands-on Exercise 1",
    "section": "Working with facet_wrap()",
    "text": "Working with facet_wrap()\nfacet_wrap wraps a 1d sequence of panels into 2d. This is generally a better use of screen space than facet_grid because most displays are roughly rectangular. The code chunk below plots a trellis plot using facet-wrap().\n\nggplot(data = exam_data,\n       aes(x = MATHS)) +\n  geom_histogram(bins = 25) +\n  facet_wrap(~ CLASS)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#working-with-facet_grid",
    "href": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#working-with-facet_grid",
    "title": "Hands-on Exercise 1",
    "section": "Working with facet_grid()",
    "text": "Working with facet_grid()\nfacet_grid() forms a matrix of panels defined by row and column facetting variables. It is most useful when you have two discrete variables, and all combinations of the variables exist in the data. The code chunk below plots a trellis plot using facet_grid().\n\nggplot(data = exam_data,\n       aes(x = MATHS)) + \n  geom_histogram(bins = 25) + \n  facet_grid(~ CLASS)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#changing-the-x-and-y-axis-range",
    "href": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#changing-the-x-and-y-axis-range",
    "title": "Hands-on Exercise 1",
    "section": "Changing the x and y-axis range",
    "text": "Changing the x and y-axis range\nThe scatter plot below is slightly misleading because the y-axis and x-axis range are not equal.\n\nggplot(data = exam_data,\n       aes(x = MATHS, y = ENGLISH)) +\n  geom_point() +\n  geom_smooth(method = lm, linewidth=0.5)\n\n`geom_smooth()` using formula = 'y ~ x'\n\n\n\n\n\n\n\n\n\nThe code chunk below fixed both the y-axis and x-axis range from 0-100.\n\nggplot(data = exam_data,\n       aes(x = MATHS, y = ENGLISH)) +\n  geom_point() +\n  geom_smooth(method = lm, linewidth=0.5) +\n  coord_cartesian(xlim = c(0, 100),\n                  ylim = c(0, 100))\n\n`geom_smooth()` using formula = 'y ~ x'"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03_parta.html",
    "href": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03_parta.html",
    "title": "Hands-on Exercise 3: Part A",
    "section": "",
    "text": "In this hands-on exercise, you will learn how to create interactive data visualisation by using functions provided by ggiraph and plotlyr packages."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03_parta.html#learning-outcome",
    "href": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03_parta.html#learning-outcome",
    "title": "Hands-on Exercise 3: Part A",
    "section": "",
    "text": "In this hands-on exercise, you will learn how to create interactive data visualisation by using functions provided by ggiraph and plotlyr packages."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03_parta.html#getting-started",
    "href": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03_parta.html#getting-started",
    "title": "Hands-on Exercise 3: Part A",
    "section": "3.2 Getting Started",
    "text": "3.2 Getting Started\nFirst, write a code chunk to check, install and launch the following R packages:\n\npacman::p_load(ggiraph, plotly, patchwork, DT, tidyverse)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03_parta.html#importing-data",
    "href": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03_parta.html#importing-data",
    "title": "Hands-on Exercise 3: Part A",
    "section": "3.3 Importing Data",
    "text": "3.3 Importing Data\nIn this section, Exam_data.csv provided will be used. Using read_csv() of readr package, import Exam_data.csv into R.\nThe code chunk below read_csv() of readr package is used to import Exam_data.csv data file into R and save it as an tibble data frame called exam_data.\n\nexam_data &lt;- read_csv(\"data/Exam_data.csv\")"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03_parta.html#interactive-data-visualisation---ggiraph-methods",
    "href": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03_parta.html#interactive-data-visualisation---ggiraph-methods",
    "title": "Hands-on Exercise 3: Part A",
    "section": "3.4 Interactive Data Visualisation - ggiraph methods",
    "text": "3.4 Interactive Data Visualisation - ggiraph methods\nggiraph is an htmlwidget and a ggplot2 extension. It allows ggplot graphics to be interactive.\nInteractive is made with ggplot geometries that can understand three arguments:\n\nTooltip: a column of data-sets that contain tooltips to be displayed when the mouse is over elements.\nOnclick: a column of data-sets that contain a JavaScript function to be executed when elements are clicked.\nData_id: a column of data-sets that contain an id to be associated with elements.\n\nIf it used within a shiny application, elements associated with an id (data_id) can be selected and manipulated on client and server sides. Refer to this article for more detail explanation.\n\n3.4.1 Tooltip effect with tooltip aesthetic\nBelow shows a typical code chunk to plot an interactive statistical graph by using ggiraph package. Notice that the code chunk consists of two parts. First, an ggplot object will be created. Next, girafe() of ggiraph will be used to create an interactive svg object.\n\np &lt;- ggplot(data = exam_data,\n            aes(x = MATHS)) +\n  geom_dotplot_interactive(\n    aes(tooltip = ID),\n    stackgroups = TRUE,\n    binwidth = 1,\n    method = \"histodot\") +\n  scale_y_continuous(NULL, breaks= NULL)\ngirafe(\n  ggobj = p,\n  width_svg = 6,\n  height_svg = 6*0.618\n)\n\nNotice that two steps are involved. First, an interactive version of ggplot2 geom (i.e. geom_dotplot_interactive()) will be used to create the basic graph. Then, girafe() will be used to generate an svg object to be displayed on an html page."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03_parta.html#interactivity",
    "href": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03_parta.html#interactivity",
    "title": "Hands-on Exercise 3: Part A",
    "section": "3.5 Interactivity",
    "text": "3.5 Interactivity\nBy hovering the mouse pointer on an data point of interest, the student’s ID will be displayed.\n\n\n\n\n\n\n\n3.5.1 Displaying multiple information on tooltip\nThe content of the tooltip can be customised by including a list object as shown in the code chunk below.\n\nexam_data$tooltip &lt;- c(paste0(     \n  \"Name = \", exam_data$ID,         \n  \"\\n Class = \", exam_data$CLASS))\np &lt;- ggplot(data=exam_data,\n            aes(x=MATHS)) +\n  geom_dotplot_interactive(\n    aes(tooltip = exam_data$tooltip),\n    stackgroups = TRUE,\n    binwidth = 1,\n    method = \"histodot\"\n  ) + \n  scale_y_continuous(NULL, breaks = NULL)\ngirafe(\n  ggobj = p,\n  width_svg = 8,\n  height_svg = 8*0.618 \n)\n\nThe first three lines of codes in the code chunk create a new field called tooltip. At the same time, it populates text in ID and CLASS fields into the newly created field. Next, this newly created field is used as tooltip field as shown in the code of line 7."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03_parta.html#interactivity-1",
    "href": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03_parta.html#interactivity-1",
    "title": "Hands-on Exercise 3: Part A",
    "section": "3.6 Interactivity",
    "text": "3.6 Interactivity\nBy hovering the mouse pointer on an data point of interest, the student’s ID and Class will be displayed.\n\n\n\n\n\n\n\n3.6.1 Customising Tooltip style\nCode chunk below uses opts_tooltip() of ggiraph to customize tooltip rendering by add css declarations.\n\ntooltip_css &lt;- \"background-color:white;font-style:bold;\n color:black;\"\nexam_data$tooltip &lt;- c(paste0(     \n  \"Name = \", exam_data$ID,         \n  \"\\n Class = \", exam_data$CLASS))\np &lt;- ggplot(data=exam_data,\n            aes(x=MATHS)) +\n  geom_dotplot_interactive(\n    aes(tooltip = exam_data$tooltip),\n    stackgroups = TRUE,\n    binwidth = 1,\n    method = \"histodot\"\n  ) + \n  scale_y_continuous(NULL, breaks = NULL)\ngirafe(\n  ggobj = p,\n  width_svg = 8,\n  height_svg = 8*0.618,\n  options = list(\n      opts_tooltip(\n        css = tooltip_css))\n)\n\nNotice that the background colour of the tooltip is black and the font colour is white and bold.\n\n\n\n\n\n\n\n\n3.6.2 Displaying statistics on tooltip\nCode chunk below shows an advanced way to customise tooltip. In this example, a function is used to compute 90% confident interval of the mean. The derived statistics are then displayed in the tooltip.\n\ntooltip &lt;- function(y, ymax, accuracy = 0.01) {\n  mean &lt;- scales::number(y, accuracy = accuracy)\n  sem &lt;- scales::number(ymax - y, accuracy = accuracy)\n  paste(\"Mean maths scores:\", mean, \"+/-\", sem)\n}\n\ngg_point &lt;- ggplot(data = exam_data,\n                   aes(x = RACE)) +\n  stat_summary(aes(y = MATHS,\n                   tooltip = after_stat(tooltip(y, ymax))),\n               fun.data = \"mean_se\",\n               geom = GeomInteractiveCol,\n               fill = \"light blue\") +\n  stat_summary(aes(y = MATHS),\n               fun.data = mean_se,\n               geom = \"errorbar\", width = 0.2, size = 0.2)\ngirafe(ggobj = gg_point,\n       width_svg = 8,\n       height_svg = 8*0.618)\n\n\n\n\n\n\n\n\n\n3.6.3 Hover effect with data_id aesthetic\nCode chunk below shows the second interactive feature of ggiraph, namely data_id.\n\np &lt;- ggplot(data=exam_data, \n       aes(x = MATHS)) +\n  geom_dotplot_interactive(           \n    aes(data_id = CLASS),             \n    stackgroups = TRUE,               \n    binwidth = 1,                        \n    method = \"histodot\") +               \n  scale_y_continuous(NULL,               \n                     breaks = NULL)\ngirafe(                                  \n  ggobj = p,                             \n  width_svg = 6,                         \n  height_svg = 6*0.618                      \n)\n\nInteractivity: Elements associated with a data_id (i.e CLASS) will be highlighted upon mouse over.\n\n\n\n\n\n\n\n\n3.6.4 Styling hover effect\nIn the code chunk below, css codes are used to change the highlighting effect.\n\np &lt;- ggplot(data=exam_data, \n       aes(x = MATHS)) +\n  geom_dotplot_interactive(              \n    aes(data_id = CLASS),              \n    stackgroups = TRUE,                  \n    binwidth = 1,                        \n    method = \"histodot\") +               \n  scale_y_continuous(NULL,               \n                     breaks = NULL)\ngirafe(                                  \n  ggobj = p,                             \n  width_svg = 6,                         \n  height_svg = 6*0.618,\n  options = list(                        \n    opts_hover(css = \"fill: #202020;\"),  \n    opts_hover_inv(css = \"opacity:0.2;\") \n  )                                        \n)                                        \n\nInteractivity: Elements associated with a data_id (i.e CLASS) will be highlighted upon mouse over.\n\n\n\n\n\n\n\n\n3.6.5 Combining tooltip and hover effect\nThere are time that we want to combine tooltip and hover effect on the interactive statistical graph as shown in the code chunk below.\n\np &lt;- ggplot(data=exam_data, \n       aes(x = MATHS)) +\n  geom_dotplot_interactive(              \n    aes(tooltip = CLASS, \n        data_id = CLASS),              \n    stackgroups = TRUE,                  \n    binwidth = 1,                        \n    method = \"histodot\") +               \n  scale_y_continuous(NULL,               \n                     breaks = NULL)\ngirafe(                                  \n  ggobj = p,                             \n  width_svg = 6,                         \n  height_svg = 6*0.618,\n  options = list(                        \n    opts_hover(css = \"fill: #202020;\"),  \n    opts_hover_inv(css = \"opacity:0.2;\") \n  )                                        \n)                                        \n\nInteractivity: Elements associated with a data_id (i.e CLASS) will be highlighted upon mouse over. At the same time, the tooltip will show the CLASS.\n\n\n\n\n\n\n\n\n3.6.6 Click effect with onclick\nonclick argument of ggiraph provides hotlink interactivity on the web.\nThe code chunk below shown an example of onclick.\n\nexam_data$onclick &lt;- sprintf(\"window.open(\\\"%s%s\\\")\",\n\"https://www.moe.gov.sg/schoolfinder?journey=Primary%20school\",\nas.character(exam_data$ID))\n\np &lt;- ggplot(data=exam_data,\n            aes(x = MATHS)) +\n  geom_dotplot_interactive(aes(onclick = onclick),\n    stackgroups = TRUE,                  \n    binwidth = 1,                        \n    method = \"histodot\") +               \n  scale_y_continuous(NULL,               \n                     breaks = NULL)\ngirafe(                                  \n  ggobj = p,                             \n  width_svg = 6,                         \n  height_svg = 6*0.618) \n\nInteractivity: Web document link with a data object will be displayed on the web browser upon mouse click.\n\n\n\n\n\n\n\n\n3.6.7 Coordinated Multiple Views with ggiraph\nCoordinated multiple views methods has been implemented in the data visualisation below.\n\n\n\n\n\n\nNotice that when a data point of one of the dotplot is selected, the corresponding data point ID on the second data visualisation will be highlighted too. Below is the code chunk for the same.\n\np1 &lt;- ggplot(data=exam_data, \n       aes(x = MATHS)) +\n  geom_dotplot_interactive(              \n    aes(data_id = ID),              \n    stackgroups = TRUE,                  \n    binwidth = 1,                        \n    method = \"histodot\") +  \n  coord_cartesian(xlim=c(0,100)) + \n  scale_y_continuous(NULL,               \n                     breaks = NULL)\n\np2 &lt;- ggplot(data=exam_data, \n       aes(x = ENGLISH)) +\n  geom_dotplot_interactive(              \n    aes(data_id = ID),              \n    stackgroups = TRUE,                  \n    binwidth = 1,                        \n    method = \"histodot\") + \n  coord_cartesian(xlim=c(0,100)) + \n  scale_y_continuous(NULL,               \n                     breaks = NULL)\n\ngirafe(code = print(p1 + p2), \n       width_svg = 6,\n       height_svg = 3,\n       options = list(\n         opts_hover(css = \"fill: #202020;\"),\n         opts_hover_inv(css = \"opacity:0.2;\")\n         )\n       ) \n\nThe data_id aesthetic is critical to link observations between plots and the tooltip aesthetic is optional but nice to have when mouse over a point."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03_parta.html#interactive-data-visualisation---plotly-methods",
    "href": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03_parta.html#interactive-data-visualisation---plotly-methods",
    "title": "Hands-on Exercise 3: Part A",
    "section": "3.7 Interactive Data Visualisation - plotly methods",
    "text": "3.7 Interactive Data Visualisation - plotly methods\nThere are two ways to create interactive graph by using plotly, they are:\n\nby using plot_ly(), and\nby using ggplotly()\n\n\n3.7.1 Creating an interactive scatter plot: plot_ly() method\nThe tabset below shows an example a basic interactive plot created by using plot_ly().\n\nThe plotThe code\n\n\n\n\n\n\n\n\n\n\n\nplot_ly(data = exam_data,\n        x = ~MATHS,\n        y = ~ENGLISH)\n\n\n\n\n\n\n3.7.2 Working with visual variable: plot_ly() method\nIn the code chunk below, color argument is mapped to a qualitative visual variable (i.e. RACE).\n\nThe plotThe code\n\n\n\n\n\n\n\n\n\n\n\nplot_ly(data = exam_data,\n        x = ~MATHS,\n        y = ~ENGLISH,\n        color = ~RACE)\n\n\n\n\n\n\n3.7.3 Creating an interactive scatter plot: ggplotly() method\nThe code chunk below plots an interactive scatter plot by using ggplotly().\n\nThe plotThe code\n\n\n\n\n\n\n\n\n\n\n\np &lt;- ggplot(data=exam_data, \n            aes(x = MATHS,\n                y = ENGLISH)) +\n  geom_point(size=1) +\n  coord_cartesian(xlim=c(0,100),\n                  ylim=c(0,100))\nggplotly(p)\n\n\n\n\n\n\n3.7.4 Coordinated Multiple Views with plotly\nThe creation of a coordinated linked plot by using plotly involves three steps:\n\nhighlight_key() of plotly package is used as shared data.\ntwo scatterplots will be created by using ggplot2 functions.\nlastly, subplot() of plotly package is used to place them next to each other side-by-side.\n\n\nThe plotThe code\n\n\n\n\n\n\n\n\n\n\n\nd &lt;- highlight_key(exam_data)\np1 &lt;- ggplot(data=d, \n            aes(x = MATHS,\n                y = ENGLISH)) +\n  geom_point(size=1) +\n  coord_cartesian(xlim=c(0,100),\n                  ylim=c(0,100))\n\np2 &lt;- ggplot(data=d, \n            aes(x = MATHS,\n                y = SCIENCE)) +\n  geom_point(size=1) +\n  coord_cartesian(xlim=c(0,100),\n                  ylim=c(0,100))\nsubplot(ggplotly(p1),\n        ggplotly(p2))"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03_parta.html#interactive-data-visualisation---crosstalk-methods",
    "href": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03_parta.html#interactive-data-visualisation---crosstalk-methods",
    "title": "Hands-on Exercise 3: Part A",
    "section": "3.8 Interactive Data Visualisation - crosstalk methods!",
    "text": "3.8 Interactive Data Visualisation - crosstalk methods!\nCrosstalk is an add-on to the htmlwidgets package. It extends htmlwidgets with a set of classes, functions, and conventions for implementing cross-widget interactions (currently, linked brushing and filtering).\n\n3.8.1 Interactive Data Table: DT package\n\nA wrapper of the JavaScript Library DataTables\nData objects in R can be rendered as HTML tables using the JavaScript library ‘DataTables’ (typically via R Markdown or Shiny).\n\nDT::datatable(exam_data, class=\"compact\")\n\n\n\n\n\n\n\n\n3.8.2 Linked brushing: crosstalk method\n\nThe plotThe code\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nd &lt;- highlight_key(exam_data) \np &lt;- ggplot(d, \n            aes(ENGLISH, \n                MATHS)) + \n  geom_point(size=1) +\n  coord_cartesian(xlim=c(0,100),\n                  ylim=c(0,100))\n\ngg &lt;- highlight(ggplotly(p),        \n                \"plotly_selected\")  \n\ncrosstalk::bscols(gg,               \n                  DT::datatable(d), \n                  widths = 5) \n\n\n\n\nThings to learn from the code chunk:\n\nhighlight() is a function of plotly package. It sets a variety of options for brushing (i.e., highlighting) multiple plots. These options are primarily designed for linking multiple plotly graphs, and may not behave as expected when linking plotly to another htmlwidget package via crosstalk. In some cases, other htmlwidgets will respect these options, such as persistent selection in leaflet.\nbscols() is a helper function of crosstalk package. It makes it easy to put HTML elements side by side. It can be called directly from the console but is especially designed to work in an R Markdown document"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03_parta.html#reference",
    "href": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03_parta.html#reference",
    "title": "Hands-on Exercise 3: Part A",
    "section": "3.9 Reference",
    "text": "3.9 Reference\n\n3.9.1 ggiraph\nThis link provides online version of the reference guide and several useful articles. Use this link to download the pdf version of the reference guide.\n\nHow to Plot With Ggiraph\nInteractive map of France with ggiraph\nCustom interactive sunbursts with ggplot in R\nThis link provides code example on how ggiraph is used to interactive graphs for Swiss Olympians - the solo specialists.\n\n\n\n3.9.2 plotly for R\n\nGetting Started with Plotly in R\nA collection of plotly R graphs are available via this link.\nCarson Sievert (2020) Interactive web-based data visualization with R, plotly, and shiny, Chapman and Hall/CRC is the best resource to learn plotly for R. The online version is available via this link\nPlotly R Figure Reference provides a comprehensive discussion of each visual representations.\nPlotly R Library Fundamentals is a good place to learn the fundamental features of Plotly’s R API.\nGetting Started\nVisit this link for a very interesting implementation of gganimate by your senior.\nBuilding an animation step-by-step with gganimate.\nCreating a composite gif with multiple gganimate panels"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04_parta.html",
    "href": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04_parta.html",
    "title": "Hands-on Exercise 4: Part A",
    "section": "",
    "text": "In this hands-on exercise, we will gain hands-on experience on using:\n\nggstatsplot package to create visual graphics with rich statistical information,\nperformance package to visualise model diagnostics, and\nparameters package to visualise model parameters"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04_parta.html#learning-outcome",
    "href": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04_parta.html#learning-outcome",
    "title": "Hands-on Exercise 4: Part A",
    "section": "",
    "text": "In this hands-on exercise, we will gain hands-on experience on using:\n\nggstatsplot package to create visual graphics with rich statistical information,\nperformance package to visualise model diagnostics, and\nparameters package to visualise model parameters"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04_parta.html#visual-statistical-analysis-with-ggstatsplot",
    "href": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04_parta.html#visual-statistical-analysis-with-ggstatsplot",
    "title": "Hands-on Exercise 4: Part A",
    "section": "4.2 Visual Statistical Analysis with ggstatsplot",
    "text": "4.2 Visual Statistical Analysis with ggstatsplot\nggstatsplot  is an extension of ggplot2 package for creating graphics with details from statistical tests included in the information-rich plots themselves."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04_parta.html#getting-started",
    "href": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04_parta.html#getting-started",
    "title": "Hands-on Exercise 4: Part A",
    "section": "4.3 Getting Started",
    "text": "4.3 Getting Started\n\n4.3.1 Installing and launching R packages\nIn this exercise, ggstatsplot and tidyverse will be used.\n\npacman::p_load(ggstatsplot, tidyverse)\n\n\n\n4.3.2 Importing data\n\nexam &lt;- read_csv(\"data/Exam_data.csv\")\n\n\n\n4.3.3 One-sample test: gghistostats() method\n\nset.seed(1234)\n\ngghistostats(\n  data = exam,\n  x = ENGLISH,\n  type = \"bayes\",\n  test.value = 60,\n  xlab = \"English Scores\"\n)\n\n\n\n\n\n\n\n\n\n\n4.3.4 Unpacking the Bayes Factor\n\nA Bayes factor is the ratio of the likelihood of one particular hypothesis to the likelihood of another. It can be interpreted as a measure of the strength of evidence in favor of one theory among two competing theories.\nThat’s because the Bayes factor gives us a way to evaluate the data in favor of a null hypothesis, and to use external information to do so. It tells us what the weight of the evidence is in favor of a given hypothesis.\nWhen we are comparing two hypotheses, H1 (the alternate hypothesis) and H0 (the null hypothesis), the Bayes Factor is often written as B10. It can be defined mathematically as\nThe Schwarz criterion is one of the easiest ways to calculate rough approximation of the Bayes Factor.\n\n\n\n4.3.5 How to interpret Bayes Factor\nA Bayes Factor can be any positive number. One of the most common interpretations is this one—first proposed by Harold Jeffereys (1961) and slightly modified by Lee and Wagenmakers in 2013:\n\n\n4.3.6 Two-sample mean test: ggbetweenstats()\nIn the code chunk below, ggbetweenstats() is used to build a visual for two-sample mean test of Maths scores by gender.\n\nggbetweenstats(\n  data = exam,\n  x = GENDER, \n  y = MATHS,\n  type = \"np\",\n  messages = FALSE\n)\n\n\n\n\n\n\n\n\nDefault information: - statistical details - Bayes Factor - sample sizes - distribution summary\n\n\n4.3.7 Oneway ANOVA Test: ggbetweenstats() method\nIn the code chunk below, ggbetweenstats() is used to build a visual for One-way ANOVA test on English score by race.\n\nggbetweenstats(\n  data = exam,\n  x = RACE,\n  y = ENGLISH,\n  type = \"p\",\n  mean.ci = TRUE, \n  pairwise.comparisons = TRUE, \n  pairwise.display = \"s\",\n  p.adjust.method = \"fdr\",\n  messages = FALSE\n)\n\n\n\n\n\n\n\n\n\n“ns” → only non-significant\n“s” → only significant\n“all” → everything\n\n\n\n4.3.8 Significant Test of Correlation: ggscatterstats()\nIn the code chunk below, ggscatterstats() is used to build a visual for Significant Test of Correlation between Maths scores and English scores.\n\nggscatterstats(\n  data = exam,\n  x = MATHS,\n  y = ENGLISH,\n  marginal = FALSE\n)\n\n\n\n\n\n\n\n\n\n\n4.3.9 Significant Test of Association (Depedence) : ggbarstats() methods\nIn the code chunk below, the Maths scores is binned into a 4-class variable by using cut().\n\nexam1 &lt;- exam %&gt;%\n  mutate(MATHS_bins = \n           cut(MATHS,\n               breaks= c(0,60,75,85,100)))\n\nIn this code chunk below ggbarstats() is used to build a visual for Significant Test of Association\n\nggbarstats(exam1,\n           x = MATHS_bins,\n           y = GENDER)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04_parta.html#visualising-models",
    "href": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04_parta.html#visualising-models",
    "title": "Hands-on Exercise 4: Part A",
    "section": "4.4 Visualising Models",
    "text": "4.4 Visualising Models\nIn this section, you will learn how to visualise model diagnostic and model parameters by using parameters package.\n\nToyota Corolla case study will be used. The purpose of study is to build a model to discover factors affecting prices of used-cars by taking into consideration a set of explanatory variables."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04_parta.html#getting-started-1",
    "href": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04_parta.html#getting-started-1",
    "title": "Hands-on Exercise 4: Part A",
    "section": "4.5 Getting Started",
    "text": "4.5 Getting Started"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04_parta.html#installing-and-loading-the-required-libraries",
    "href": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04_parta.html#installing-and-loading-the-required-libraries",
    "title": "Hands-on Exercise 4: Part A",
    "section": "4.6 Installing and loading the required libraries",
    "text": "4.6 Installing and loading the required libraries\n\npacman::p_load(readxl, performance, parameters, see)\n\n\n4.6.1 Importing Excel file: readxl methods\nIn the code chunk below, read_xls() of readxl package is used to import the data worksheet of ToyotaCorolla.xls workbook into R.\n\ncar_resale &lt;- read_xls(\"data/ToyotaCorolla.xls\", \n                       \"data\")\ncar_resale\n\n# A tibble: 1,436 × 38\n      Id Model    Price Age_08_04 Mfg_Month Mfg_Year     KM Quarterly_Tax Weight\n   &lt;dbl&gt; &lt;chr&gt;    &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;    &lt;dbl&gt;  &lt;dbl&gt;         &lt;dbl&gt;  &lt;dbl&gt;\n 1    81 TOYOTA … 18950        25         8     2002  20019           100   1180\n 2     1 TOYOTA … 13500        23        10     2002  46986           210   1165\n 3     2 TOYOTA … 13750        23        10     2002  72937           210   1165\n 4     3  TOYOTA… 13950        24         9     2002  41711           210   1165\n 5     4 TOYOTA … 14950        26         7     2002  48000           210   1165\n 6     5 TOYOTA … 13750        30         3     2002  38500           210   1170\n 7     6 TOYOTA … 12950        32         1     2002  61000           210   1170\n 8     7  TOYOTA… 16900        27         6     2002  94612           210   1245\n 9     8 TOYOTA … 18600        30         3     2002  75889           210   1245\n10    44 TOYOTA … 16950        27         6     2002 110404           234   1255\n# ℹ 1,426 more rows\n# ℹ 29 more variables: Guarantee_Period &lt;dbl&gt;, HP_Bin &lt;chr&gt;, CC_bin &lt;chr&gt;,\n#   Doors &lt;dbl&gt;, Gears &lt;dbl&gt;, Cylinders &lt;dbl&gt;, Fuel_Type &lt;chr&gt;, Color &lt;chr&gt;,\n#   Met_Color &lt;dbl&gt;, Automatic &lt;dbl&gt;, Mfr_Guarantee &lt;dbl&gt;,\n#   BOVAG_Guarantee &lt;dbl&gt;, ABS &lt;dbl&gt;, Airbag_1 &lt;dbl&gt;, Airbag_2 &lt;dbl&gt;,\n#   Airco &lt;dbl&gt;, Automatic_airco &lt;dbl&gt;, Boardcomputer &lt;dbl&gt;, CD_Player &lt;dbl&gt;,\n#   Central_Lock &lt;dbl&gt;, Powered_Windows &lt;dbl&gt;, Power_Steering &lt;dbl&gt;, …\n\n\n\n\n4.6.2 Multiple Regression Model using lm()\nThe code chunk below is used to calibrate a multiple linear regression model by using lm() of Base Stats of R.\n\nmodel &lt;- lm(Price ~ Age_08_04 + Mfg_Year + KM + \n              Weight + Guarantee_Period, data = car_resale)\nmodel\n\n\nCall:\nlm(formula = Price ~ Age_08_04 + Mfg_Year + KM + Weight + Guarantee_Period, \n    data = car_resale)\n\nCoefficients:\n     (Intercept)         Age_08_04          Mfg_Year                KM  \n      -2.637e+06        -1.409e+01         1.315e+03        -2.323e-02  \n          Weight  Guarantee_Period  \n       1.903e+01         2.770e+01  \n\n\n\n\n4.6.3 Model Diagnostic: checking for multicolinearity:\nIn the code chunk, check_collinearity() of performance package.\n\ncheck_c &lt;- check_collinearity(model)\nplot(check_c)\n\n\n\n\n\n\n\n\n\n\n4.6.4 Model Diagnostic: checking normality assumption\nIn the code chunk, check_normality() of performance package.\n\nmodel1 &lt;- lm(Price ~ Age_08_04 + KM + \n              Weight + Guarantee_Period, data = car_resale)\n\n\ncheck_n &lt;- check_normality(model1)\nplot(check_n)\n\n\n\n\n\n\n\n\n\n\n4.6.5 Model Diagnostic: Check model for homogeneity of variances\nIn the code chunk, check_heteroscedasticity() of performance package.\n\ncheck_h &lt;- check_heteroscedasticity(model1)\nplot(check_h)\n\n\n\n\n\n\n\n\n\n\n4.6.6 Model Diagnostic: Complete check\nWe can also perform the complete by using check_model().\n\ncheck_model(model1)\n\n\n\n\n\n\n\n\n\n\n4.6.7 Visualising Regression Parameters: see methods\nIn the code below, plot() of see package and parameters() of parameters package is used to visualise the parameters of a regression model.\n\nplot(parameters(model1))\n\n\n\n\n\n\n\n\n\n\n4.6.8 Visualising Regression Parameters: ggcoefstats() methods\nIn the code below, ggcoefstats() of ggstatsplot package to visualise the parameters of a regression model.\n\nggcoefstats(model1, \n            output = \"plot\")"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04_partc.html",
    "href": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04_partc.html",
    "title": "Hands-on Exercise 4: Part C",
    "section": "",
    "text": "Funnel plot is a specially designed data visualisation for conducting unbiased comparison between outlets, stores or business entities. By the end of this hands-on exercise, you will gain hands-on experience on:\n\nplotting funnel plots by using funnelPlotR package,\nplotting static funnel plot by using ggplot2 package, and\nplotting interactive funnel plot by using both plotly R and ggplot2 packages."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04_partc.html#overview",
    "href": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04_partc.html#overview",
    "title": "Hands-on Exercise 4: Part C",
    "section": "",
    "text": "Funnel plot is a specially designed data visualisation for conducting unbiased comparison between outlets, stores or business entities. By the end of this hands-on exercise, you will gain hands-on experience on:\n\nplotting funnel plots by using funnelPlotR package,\nplotting static funnel plot by using ggplot2 package, and\nplotting interactive funnel plot by using both plotly R and ggplot2 packages."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04_partc.html#installing-and-launching-r-packages",
    "href": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04_partc.html#installing-and-launching-r-packages",
    "title": "Hands-on Exercise 4: Part C",
    "section": "6.2 Installing and Launching R Packages",
    "text": "6.2 Installing and Launching R Packages\n\npacman::p_load(tidyverse, FunnelPlotR, plotly, knitr)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04_partc.html#importing-data",
    "href": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04_partc.html#importing-data",
    "title": "Hands-on Exercise 4: Part C",
    "section": "6.3 Importing Data",
    "text": "6.3 Importing Data\nIn this section, COVID-19_DKI_Jakarta will be used. The data was downloaded from Open Data Covid-19 Provinsi DKI Jakarta portal. For this hands-on exercise, we are going to compare the cumulative COVID-19 cases and death by sub-district (i.e. kelurahan) as at 31st July 2021, DKI Jakarta.\nThe code chunk below imports the data into R and save it into a tibble data frame object called covid19.\n\ncovid19 &lt;- read_csv(\"data/COVID-19_DKI_Jakarta.csv\") %&gt;%\n  mutate_if(is.character, as.factor)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04_partc.html#funnelplotr-methods",
    "href": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04_partc.html#funnelplotr-methods",
    "title": "Hands-on Exercise 4: Part C",
    "section": "6.4 FunnelPlotR methods",
    "text": "6.4 FunnelPlotR methods\nFunnelPlotR package uses ggplot to generate funnel plots. It requires a numerator (events of interest), denominator (population to be considered) and group. The key arguments selected for customisation are:\n\nlimit: plot limits (95 or 99).\nlabel_outliers: to label outliers (true or false).\nPoisson_limits: to add Poisson limits to the plot.\nOD_adjust: to add overdispersed limits to the plot.\nxrange and yrange: to specify the range to display for axes, acts like a zoom function.\nOther aesthetic components such as graph title, axis labels etc.\n\n\nfunnel_plot(\n  numerator = Positive,\n  denominator = Death,\n  group = `Sub-district`,\n  .data = covid19\n)\n\n\n\n\n\n\n\n\nA funnel plot object with 267 points of which 0 are outliers. \nPlot is adjusted for overdispersion. \n\n\n\n6.4.2 FunnelPlotR methods: Makeover 1\nThe code chunk below plots a funnel plot.\n\nfunnel_plot(\n  numerator = Death,\n  denominator = Positive,\n  group = `Sub-district`,\n  data_type = \"PR\",     \n  xrange = c(0, 6500),  \n  yrange = c(0, 0.05),\n  .data = covid19\n)\n\n\n\n\n\n\n\n\nA funnel plot object with 267 points of which 7 are outliers. \nPlot is adjusted for overdispersion. \n\n\n\n\n6.4.3 FunnelPlotR methods: Makeover 2\nThe code chunk below plots a funnel plot.\n\nfunnel_plot(\n  numerator = Death,\n  denominator = Positive,\n  group = `Sub-district`,\n  data_type = \"PR\",\n  .data = covid19,\n  xrange = c(0, 6500),  \n  yrange = c(0, 0.05),\n  label = NA,\n  title = \"Cumulative COVID-19 Fatality Rate by Cumulative Total Number of COVID-19 Positive Cases\", #&lt;&lt;           \n  x_label = \"Cumulative COVID-19 Positive Cases\", #&lt;&lt;\n  y_label = \"Cumulative Fatality Rate\"  #&lt;&lt;\n)\n\n\n\n\n\n\n\n\nA funnel plot object with 267 points of which 7 are outliers. \nPlot is adjusted for overdispersion. \n\n\n\n\n\n\n\n\nThings to learn from the code chunk above.\n\n\n\n\nlabel = NA argument is to removed the default label outliers feature.\ntitle argument is used to add plot title.\nx_label and y_label arguments are used to add/edit x-axis and y-axis titles"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04_partc.html#funnel-plot-for-fair-visual-comparison-ggplot2-methods",
    "href": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04_partc.html#funnel-plot-for-fair-visual-comparison-ggplot2-methods",
    "title": "Hands-on Exercise 4: Part C",
    "section": "6.5 Funnel Plot for Fair Visual Comparison: ggplot2 methods",
    "text": "6.5 Funnel Plot for Fair Visual Comparison: ggplot2 methods\nIn this section, you will gain hands-on experience on building funnel plots step-by-step by using ggplot2. It aims to enhance you working experience of ggplot2 to customise speciallised data visualisation like funnel plot.\n\n6.5.1 Computing the basic derived fields\nTo plot the funnel plot from scratch, we need to derive cumulative death rate and standard error of cumulative death rate.\n\ndf &lt;- covid19 %&gt;%\n  mutate(rate = Death / Positive) %&gt;%\n  mutate(rate.se = sqrt((rate*(1-rate)) / (Positive))) %&gt;%\n  filter(rate &gt; 0)\n\nNext, the fit.mean is computed by using the code chunk below.\n\nfit.mean &lt;- weighted.mean(df$rate, 1/df$rate.se^2)\n\n\n\n6.5.2 Calculate lower and upper limits for 95% and 99.9% CI\nThe code chunk below is used to compute the lower and upper limits for 95% confidence interval.\n\nnumber.seq &lt;- seq(1, max(df$Positive), 1)\nnumber.ll95 &lt;- fit.mean - 1.96 * sqrt((fit.mean*(1-fit.mean)) / (number.seq)) \nnumber.ul95 &lt;- fit.mean + 1.96 * sqrt((fit.mean*(1-fit.mean)) / (number.seq)) \nnumber.ll999 &lt;- fit.mean - 3.29 * sqrt((fit.mean*(1-fit.mean)) / (number.seq)) \nnumber.ul999 &lt;- fit.mean + 3.29 * sqrt((fit.mean*(1-fit.mean)) / (number.seq)) \ndfCI &lt;- data.frame(number.ll95, number.ul95, number.ll999, \n                   number.ul999, number.seq, fit.mean)\n\n\n\n6.5.3 Plotting a static funnel plot\nIn the code chunk below, ggplot2 functions are used to plot a static funnel plot.\n\np &lt;- ggplot(df, aes(x = Positive, y = rate)) +\n  geom_point(aes(label=`Sub-district`), \n             alpha=0.4) +\n  geom_line(data = dfCI, \n            aes(x = number.seq, \n                y = number.ll95), \n            size = 0.4, \n            colour = \"grey40\", \n            linetype = \"dashed\") +\n  geom_line(data = dfCI, \n            aes(x = number.seq, \n                y = number.ul95), \n            size = 0.4, \n            colour = \"grey40\", \n            linetype = \"dashed\") +\n  geom_line(data = dfCI, \n            aes(x = number.seq, \n                y = number.ll999), \n            size = 0.4, \n            colour = \"grey40\") +\n  geom_line(data = dfCI, \n            aes(x = number.seq, \n                y = number.ul999), \n            size = 0.4, \n            colour = \"grey40\") +\n  geom_hline(data = dfCI, \n             aes(yintercept = fit.mean), \n             size = 0.4, \n             colour = \"grey40\") +\n  coord_cartesian(ylim=c(0,0.05)) +\n  annotate(\"text\", x = 1, y = -0.13, label = \"95%\", size = 3, colour = \"grey40\") + \n  annotate(\"text\", x = 4.5, y = -0.18, label = \"99%\", size = 3, colour = \"grey40\") + \n  ggtitle(\"Cumulative Fatality Rate by Cumulative Number of COVID-19 Cases\") +\n  xlab(\"Cumulative Number of COVID-19 Cases\") + \n  ylab(\"Cumulative Fatality Rate\") +\n  theme_light() +\n  theme(plot.title = element_text(size=12),\n        legend.position = c(0.91,0.85), \n        legend.title = element_text(size=7),\n        legend.text = element_text(size=7),\n        legend.background = element_rect(colour = \"grey60\", linetype = \"dotted\"),\n        legend.key.height = unit(0.3, \"cm\"))\np\n\n\n\n\n\n\n\n\n\n\n6.5.4 Interactive Funnel Plot: plotly + ggplot2\nThe funnel plot created using ggplot2 functions can be made interactive with ggplotly() of plotly r package.\n\nfp_ggplotly &lt;- ggplotly(p,\n  tooltip = c(\"label\", \n              \"x\", \n              \"y\"))\nfp_ggplotly"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04_partc.html#references",
    "href": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04_partc.html#references",
    "title": "Hands-on Exercise 4: Part C",
    "section": "6.6 References",
    "text": "6.6 References\n\nfunnelPlotR package.\nFunnel Plots for Indirectly-standardised ratios.\nChanging funnel plot options\nggplot2 package."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex06.html",
    "href": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex06.html",
    "title": "Hands-on Exercise 6",
    "section": "",
    "text": "In this hands-on exercise, we will learn how to model, analyse and visualise network data using R.\nBy the end of this hands-on exercise, we will be able to:\n\ncreate graph object data frames, manipulate them using appropriate functions of dplyr, lubridate, and tidygraph,\nbuild network graph visualisation using appropriate functions of ggraph,\ncompute network geometrics using tidygraph,\nbuild advanced graph visualisation by incorporating the network geometrics, and\nbuild interactive network visualisation using visNetwork package."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex06.html#overview",
    "href": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex06.html#overview",
    "title": "Hands-on Exercise 6",
    "section": "",
    "text": "In this hands-on exercise, we will learn how to model, analyse and visualise network data using R.\nBy the end of this hands-on exercise, we will be able to:\n\ncreate graph object data frames, manipulate them using appropriate functions of dplyr, lubridate, and tidygraph,\nbuild network graph visualisation using appropriate functions of ggraph,\ncompute network geometrics using tidygraph,\nbuild advanced graph visualisation by incorporating the network geometrics, and\nbuild interactive network visualisation using visNetwork package."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex06.html#getting-started",
    "href": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex06.html#getting-started",
    "title": "Hands-on Exercise 6",
    "section": "6.2 Getting Started",
    "text": "6.2 Getting Started\n\n6.2.1 Installing and launching R packages\nIn this hands-on exercise, four network data modelling and visualisation packages will be installed and launched. They are igraph, tidygraph, ggraph and visNetwork. Beside these four packages, tidyverse and lubridate, an R package specially designed to handle and wrangling time data will be installed and launched too.\n\npacman::p_load(igraph, tidygraph, ggraph, visNetwork, lubridate, clock,\n               tidyverse, graphlayouts)\n\n\n\n6.3.1 The edges data\n\nGAStech-email_edges.csv which consists of two weeks of 9063 emails correspondances between 55 employees.\n\n\n\n6.3.2 The nodes data\n\nGAStech_email_nodes.csv which consist of the names, department and title of the 55 employees.\n\n\n\n6.3.3 Importing network data from files\nIn this step, you will import GAStech_email_node.csv and GAStech_email_edges-v2.csv into RStudio environment by using read_csv() of readr package.\n\nGAStech_nodes &lt;- read_csv(\"data/GAStech_email_node.csv\")\nGAStech_edges &lt;- read_csv(\"data/GAStech_email_edge-v2.csv\")\n\n\n\n6.3.4 Reviewing the imported data\nNext, we will examine the structure of the data frame using glimpse() of dplyr.\n\nglimpse(GAStech_edges)\n\nRows: 9,063\nColumns: 8\n$ source      &lt;dbl&gt; 43, 43, 44, 44, 44, 44, 44, 44, 44, 44, 44, 44, 26, 26, 26…\n$ target      &lt;dbl&gt; 41, 40, 51, 52, 53, 45, 44, 46, 48, 49, 47, 54, 27, 28, 29…\n$ SentDate    &lt;chr&gt; \"6/1/2014\", \"6/1/2014\", \"6/1/2014\", \"6/1/2014\", \"6/1/2014\"…\n$ SentTime    &lt;time&gt; 08:39:00, 08:39:00, 08:58:00, 08:58:00, 08:58:00, 08:58:0…\n$ Subject     &lt;chr&gt; \"GT-SeismicProcessorPro Bug Report\", \"GT-SeismicProcessorP…\n$ MainSubject &lt;chr&gt; \"Work related\", \"Work related\", \"Work related\", \"Work rela…\n$ sourceLabel &lt;chr&gt; \"Sven.Flecha\", \"Sven.Flecha\", \"Kanon.Herrero\", \"Kanon.Herr…\n$ targetLabel &lt;chr&gt; \"Isak.Baza\", \"Lucas.Alcazar\", \"Felix.Resumir\", \"Hideki.Coc…\n\n\n\n\n6.3.5 Wrangling time\nThe code chunk below will be used to perform the changes.\n\nGAStech_edges &lt;- GAStech_edges %&gt;%\n  mutate(SendDate = dmy(SentDate)) %&gt;%\n  mutate(WeekDay = wday(SentDate,\n                        label = TRUE,\n                        abbr = FALSE))\n\n\n\n\n\n\n\nThings to learn from code chunk above:\n\n\n\n\nboth dmy() and wday() are functions of lubridate package. lubridate is an R package that makes it easier to work with dates and times.\ndmy() transforms the SentDate to Date data type.\nwday() returns the day of the week as a decimal number or an ordered factor if label is TRUE. The argument abbr is FALSE keep the daya spells in full, i.e. Monday. The function will create a new column in the data.frame i.e. Weekday and the output of wday() will save in this newly created field.\nthe values in the Weekday field are in ordinal scale.\n\n\n\n\n\n6.3.6 Reviewing the revised date fields\nTable below shows the data structure of the reformatted GAStech_edges data frame.\n\nglimpse(GAStech_edges)\n\nRows: 9,063\nColumns: 10\n$ source      &lt;dbl&gt; 43, 43, 44, 44, 44, 44, 44, 44, 44, 44, 44, 44, 26, 26, 26…\n$ target      &lt;dbl&gt; 41, 40, 51, 52, 53, 45, 44, 46, 48, 49, 47, 54, 27, 28, 29…\n$ SentDate    &lt;chr&gt; \"6/1/2014\", \"6/1/2014\", \"6/1/2014\", \"6/1/2014\", \"6/1/2014\"…\n$ SentTime    &lt;time&gt; 08:39:00, 08:39:00, 08:58:00, 08:58:00, 08:58:00, 08:58:0…\n$ Subject     &lt;chr&gt; \"GT-SeismicProcessorPro Bug Report\", \"GT-SeismicProcessorP…\n$ MainSubject &lt;chr&gt; \"Work related\", \"Work related\", \"Work related\", \"Work rela…\n$ sourceLabel &lt;chr&gt; \"Sven.Flecha\", \"Sven.Flecha\", \"Kanon.Herrero\", \"Kanon.Herr…\n$ targetLabel &lt;chr&gt; \"Isak.Baza\", \"Lucas.Alcazar\", \"Felix.Resumir\", \"Hideki.Coc…\n$ SendDate    &lt;date&gt; 2014-01-06, 2014-01-06, 2014-01-06, 2014-01-06, 2014-01-0…\n$ WeekDay     &lt;ord&gt; Friday, Friday, Friday, Friday, Friday, Friday, Friday, Fr…\n\n\n\n\n6.3.7 Wrangling attributes\nA close examination of GAStech_edges data.frame reveals that it consists of individual e-mail flow records. This is not very useful for visualisation.\nIn view of this, we will aggregate the individual by date, senders, receivers, main subject and day of the week.\n\nGAStech_edges_aggregated &lt;- GAStech_edges %&gt;%\n  filter(MainSubject == \"Work related\") %&gt;%\n  group_by(source, target, WeekDay) %&gt;%\n  summarise(Weight = n()) %&gt;%\n  filter(source!=target) %&gt;%\n  filter(Weight &gt; 1) %&gt;%\n  ungroup()\n\n\n\n\n\n\n\nThings to learn from code chunk:\n\n\n\n\nfour functions from dplyr package are used. They are: filter(), group(), summarise(), and ungroup().\nThe output data.frame is called GAStech_edges_aggregated.\nA new field called Weight has been added in GAStech_edges_aggregated.\n\n\n\n\n\n6.3.8 Reviewing the revised edges file\n\nglimpse(GAStech_edges_aggregated) \n\nRows: 1,372\nColumns: 4\n$ source  &lt;dbl&gt; 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,…\n$ target  &lt;dbl&gt; 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 4, 4, 4, 4, 4, 5, 5, 5, 5, 5, 6,…\n$ WeekDay &lt;ord&gt; Sunday, Monday, Tuesday, Wednesday, Friday, Sunday, Monday, Tu…\n$ Weight  &lt;int&gt; 5, 2, 3, 4, 6, 5, 2, 3, 4, 6, 5, 2, 3, 4, 6, 5, 2, 3, 4, 6, 5,…"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex06.html#creating-network-objects-using-tidygraph",
    "href": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex06.html#creating-network-objects-using-tidygraph",
    "title": "Hands-on Exercise 6",
    "section": "6.4 Creating network objects using tidygraph",
    "text": "6.4 Creating network objects using tidygraph\nIn this section, you will learn how to create a graph data model by using tidygraph package. It provides a tidy API for graph/network manipulation. While network data itself is not tidy, it can be envisioned as two tidy tables, one for node data and one for edge data. tidygraph provides a way to switch between the two tables and provides dplyr verbs for manipulating them. Furthermore it provides access to a lot of graph algorithms with return values that facilitate their use in a tidy workflow.\n\n6.4.1 The tbl_graph object\nTwo functions of tidygraph package can be used to create network objects, they are:\n\ntbl_graph() creates a tbl_graph network object from nodes and edges data.\nas_tbl_graph() converts network data and objects to a tbl_graph network. Below are network data and objects supported by as_tbl_graph()\n\na node data.frame and an edge data.frame,\ndata.frame, list, matrix from base,\nigraph from igraph,\nnetwork from network,\ndendrogram and hclust from stats,\nNode from data.tree,\nphylo and evonet from ape, and\ngraphNEL, graphAM, graphBAM from graph (in Bioconductor)\n\n6.4.2 The dplyr verbs in tidygraph\nactivate() verb from tidygraph serves as a switch between tibbles for nodes and edges. All dplyr verbs applied to tbl_graph object are applied to the active tibble.\n\n\n\n6.4.3 Using tbl_graph() to build tidygraph data model.\nIn this section, you will use tbl_graph() of tinygraph package to build an tidygraph’s network graph data.frame.\nBefore typing the codes, you are recommended to review to reference guide of tbl_graph()\n\nGAStech_graph &lt;- tbl_graph(nodes = GAStech_nodes,\n                           edges = GAStech_edges_aggregated,\n                           directed = TRUE)\n\n\n\n6.4.4 Reviewing the output tidygraph’s graph object\n\nGAStech_graph\n\n# A tbl_graph: 54 nodes and 1372 edges\n#\n# A directed multigraph with 1 component\n#\n# Node Data: 54 × 4 (active)\n      id label               Department     Title                               \n   &lt;dbl&gt; &lt;chr&gt;               &lt;chr&gt;          &lt;chr&gt;                               \n 1     1 Mat.Bramar          Administration Assistant to CEO                    \n 2     2 Anda.Ribera         Administration Assistant to CFO                    \n 3     3 Rachel.Pantanal     Administration Assistant to CIO                    \n 4     4 Linda.Lagos         Administration Assistant to COO                    \n 5     5 Ruscella.Mies.Haber Administration Assistant to Engineering Group Mana…\n 6     6 Carla.Forluniau     Administration Assistant to IT Group Manager       \n 7     7 Cornelia.Lais       Administration Assistant to Security Group Manager \n 8    44 Kanon.Herrero       Security       Badging Office                      \n 9    45 Varja.Lagos         Security       Badging Office                      \n10    46 Stenig.Fusil        Security       Building Control                    \n# ℹ 44 more rows\n#\n# Edge Data: 1,372 × 4\n   from    to WeekDay Weight\n  &lt;int&gt; &lt;int&gt; &lt;ord&gt;    &lt;int&gt;\n1     1     2 Sunday       5\n2     1     2 Monday       2\n3     1     2 Tuesday      3\n# ℹ 1,369 more rows\n\n\n\n\n6.4.6 Changing the active object\nThe nodes tibble data frame is activated by default, but you can change which tibble data frame is active with the activate() function. Thus, if we wanted to rearrange the rows in the edges tibble to list those with the highest “weight” first, we could use activate() and then arrange().\nFor example,\n\nGAStech_graph %&gt;%\n  activate(edges) %&gt;%\n  arrange(desc(Weight))\n\n# A tbl_graph: 54 nodes and 1372 edges\n#\n# A directed multigraph with 1 component\n#\n# Edge Data: 1,372 × 4 (active)\n    from    to WeekDay   Weight\n   &lt;int&gt; &lt;int&gt; &lt;ord&gt;      &lt;int&gt;\n 1    40    41 Saturday      13\n 2    41    43 Monday        11\n 3    35    31 Tuesday       10\n 4    40    41 Monday        10\n 5    40    43 Monday        10\n 6    36    32 Sunday         9\n 7    40    43 Saturday       9\n 8    41    40 Monday         9\n 9    19    15 Wednesday      8\n10    35    38 Tuesday        8\n# ℹ 1,362 more rows\n#\n# Node Data: 54 × 4\n     id label           Department     Title           \n  &lt;dbl&gt; &lt;chr&gt;           &lt;chr&gt;          &lt;chr&gt;           \n1     1 Mat.Bramar      Administration Assistant to CEO\n2     2 Anda.Ribera     Administration Assistant to CFO\n3     3 Rachel.Pantanal Administration Assistant to CIO\n# ℹ 51 more rows"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex06.html#plotting-static-network-graphs-with-ggraph-package",
    "href": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex06.html#plotting-static-network-graphs-with-ggraph-package",
    "title": "Hands-on Exercise 6",
    "section": "6.5 Plotting Static Network Graphs with ggraph package",
    "text": "6.5 Plotting Static Network Graphs with ggraph package\nggraph is an extension of ggplot2, making it easier to carry over basic ggplot skills to the design of network graphs.\nAs in all network graph, there are three main aspects to a ggraph’s network graph, they are:\n\nnodes,\nedges and\nlayouts.\n\nFor a comprehensive discussion of each of this aspect of graph, please refer to their respective vignettes provided.\n\n6.5.1 Plotting a basic network graph\nThe code chunk below uses ggraph(), geom-edge_link() and geom_node_point() to plot a network graph by using GAStech_graph. Before your get started, it is advisable to read their respective reference guide at least once.\n\nggraph(GAStech_graph) +\n  geom_edge_link() +\n  geom_node_point()\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nThings to learn from code chunk:\n\n\n\n\nThe basic plotting function is ggraph(), which takes the data to be used for the graph and the type of layout desired. Both of the arguments for ggraph() are built around igraph. Therefore, ggraph() can use either an igraph object or a tbl_graph object.\n\n\n\n\n\n6.5.2 Changing the default network graph theme\nIn this section, you will use theme_graph() to remove the x and y axes. Before your get started, it is advisable to read it’s reference guide at least once.\n\ng &lt;- ggraph(GAStech_graph) +\n  geom_edge_link() +\n  geom_node_point()\ng + theme_graph()\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nThings to learn from code chunk:\n\n\n\n\nggraph introduces a special ggplot theme that provides better defaults for network graphs than the normal ggplot defaults. theme_graph(), besides removing axes, grids, and border, changes the font to Arial Narrow (this can be overridden).\nThe ggraph theme can be set for a series of plots with the set_graph_style() command run before the graphs are plotted or by using theme_graph() in the individual plots.\n\n\n\n\n\n6.5.3 Changing the coloring of the plot\nFurthermore, theme_graph() makes it easy to change the coloring of the plot.\n\ng &lt;- ggraph(GAStech_graph) + \n  geom_edge_link(aes(colour = 'grey50')) +\n  geom_node_point(aes(colour = 'grey40'))\n\ng + theme_graph(background = 'grey10',\n                text_colour = 'white')\n\n\n\n\n\n\n\n\n\n\n6.5.4 Working with ggraph’s layouts\nggraph support many layout for standard used, they are: star, circle, nicely (default), dh, gem, graphopt, grid, mds, spahere, randomly, fr, kk, drl and lgl. Figures below and on the right show layouts supported by ggraph().\n\n\n\n6.5.5 Fruchterman and Reingold layout\nThe code chunks below will be used to plot the network graph using Fruchterman and Reingold layout.\n\ng &lt;- ggraph(GAStech_graph, layout=\"fr\") +\n  geom_edge_link(aes()) +\n  geom_node_point(aes()) \n  \ng + theme_graph()\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nThing to learn from the code chunk above:\n\n\n\n\nlayout argument is used to define the layout to be used.\n\n\n\n\n\n6.5.6 Modifying network nodes\nIn this section, you will colour each node by referring to their respective departments.\n\ng &lt;- ggraph(GAStech_graph, layout=\"nicely\") +\n  geom_edge_link(aes()) +\n  geom_node_point(aes(colour = Department, size = 3))\n\ng + theme_graph()\n\n\n\n\n\n\n\n\nThings to learn from the code chunks above:\n\ngeom_node_point is equivalent in functionality to geo_point of ggplot2. It allows for simple plotting of nodes in different shapes, colours and sizes. In the codes chnuks above colour and size are used.\n\n\n\n6.5.7 Modifying edges\nIn the code chunk below, the thickness of the edges will be mapped with the Weight variable.\n\ng &lt;- ggraph(GAStech_graph, layout=\"nicely\") +\n  geom_edge_link(aes(width=Weight),\n                 alpha = 0.2) +\n  scale_edge_width(range = c(0.1, 5)) +\n  geom_node_point(aes(colour = Department,\n                      size = 3))\ng + theme_graph()\n\n\n\n\n\n\n\n\nThings to learn from the code chunks above:\n\ngeom_edge_link draws edges in the simplest way - as straight lines between the start and end nodes. But, it can do more that that. In the example above, argument width is used to map the width of the line in proportional to the Weight attribute and argument alpha is used to introduce opacity on the line."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex06.html#creating-facet-graphs",
    "href": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex06.html#creating-facet-graphs",
    "title": "Hands-on Exercise 6",
    "section": "6.6 Creating facet graphs",
    "text": "6.6 Creating facet graphs\nAnother very useful feature of ggraph is faceting. In visualising network data, this technique can be used to reduce edge over-plotting in a very meaning way by spreading nodes and edges out based on their attributes. In this section, you will learn how to use faceting technique to visualise network data.\nThere are three functions in ggraph to implement faceting, they are:\n\nfacet_nodes() whereby edges are only draw in a panel if both terminal nodes are present here,\nfacet_edges() whereby nodes are always drawn in al panels even if the node data contains an attribute named the same as the one used for the edge facetting, and\nfacet_graph() faceting on two variables simultaneously.\n\n\n6.6.1 Working with facet_edges()\nIn the code chunk below, facet_edges() is used. Before getting started, it is advisable for you to read it’s reference guide at least once.\n\nset_graph_style()\n\ng &lt;- ggraph(GAStech_graph, layout=\"nicely\") +\n  geom_edge_link(aes(width = Weight),\n                 alpha = 0.2) +\n  scale_edge_width(range = c(0.1,5)) +\n  geom_node_point(aes(colour = Department),\n                  size = 2)\n  \ng + facet_edges(~ WeekDay)\n\n\n\n\n\n\n\n\n\n\n6.6.2 Working with facet_edges()\nThe code chunk below uses theme() to change the position of the legend.\n\nset_graph_style()\n\ng &lt;- ggraph(GAStech_graph, \n            layout = \"nicely\") + \n  geom_edge_link(aes(width=Weight), \n                 alpha=0.2) +\n  scale_edge_width(range = c(0.1, 5)) +\n  geom_node_point(aes(colour = Department), \n                  size = 2) +\n  theme(legend.position = 'bottom')\n  \ng + facet_edges(~ WeekDay)\n\n\n\n\n\n\n\n\n\n\n6.6.3 A framed facet graph\nThe code chunk below adds frame to each graph.\n\nset_graph_style() \n\ng &lt;- ggraph(GAStech_graph, \n            layout = \"nicely\") + \n  geom_edge_link(aes(width=Weight), \n                 alpha=0.2) +\n  scale_edge_width(range = c(0.1, 5)) +\n  geom_node_point(aes(colour = Department), \n                  size = 2)\n  \ng + facet_edges(~WeekDay) +\n  th_foreground(foreground = \"grey80\",  \n                border = TRUE) +\n  theme(legend.position = 'bottom')\n\n\n\n\n\n\n\n\n\n\n6.6.4 Working with facet_nodes()\nIn the code chunkc below, facet_nodes() is used. Before getting started, it is advisable for you to read it’s reference guide at least once.\n\nset_graph_style()\n\ng &lt;- ggraph(GAStech_graph, layout=\"nicely\") +\n  geom_edge_link(aes(width = Weight),\n                 alpha = 0.2) +\n  scale_edge_width(range = c(0.1,5)) +\n  geom_node_point(aes(colour = Department),\n                  size = 2)\n\ng + facet_nodes(~ Department) + \n  th_foreground(foreground = \"grey80\",  \n                border = TRUE) +\n  theme(legend.position = \"bottom\")"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex06.html#network-metrics-analysis",
    "href": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex06.html#network-metrics-analysis",
    "title": "Hands-on Exercise 6",
    "section": "6.7 Network Metrics Analysis",
    "text": "6.7 Network Metrics Analysis\n\n6.7.1 Computing centrality indices\nCentrality measures are a collection of statistical indices use to describe the relative important of the actors are to a network. There are four well-known centrality measures, namely: degree, betweenness, closeness and eigenvector. It is beyond the scope of this hands-on exercise to cover the principles and mathematics of these measure here.\n\ng &lt;- GAStech_graph %&gt;%\n  mutate(betweenness_centrality = centrality_betweenness()) %&gt;%\n  ggraph(layout = \"fr\") +\n  geom_edge_link(aes(width = Weight),\n                 alpha = 0.2) +\n  scale_edge_width(range = c(0.1, 5)) +\n  geom_node_point(aes(colour = Department,\n                      size = betweenness_centrality))\ng + theme_graph()\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nThings to learn from the code chunk above:\n\n\n\n\nmutate() of dplyr is used to perform the computation.\nthe algorithm used, on the other hand, is the centrality_betweenness() of tidygraph.\n\n\n\n\n\n6.7.2 Visualising network metrics\nIt is important to note that from ggraph v2.0 onward tidygraph algorithms such as centrality measures can be accessed directly in ggraph calls. This means that it is no longer necessary to precompute and store derived node and edge centrality measures on the graph in order to use them in a plot.\n\ng &lt;- ggraph(GAStech_graph, layout=\"fr\") +\n  geom_edge_link(aes(width = Weight), alpha = 0.2) +\n  scale_edge_width(range = c(0.1,5)) +\n  geom_node_point(aes(colour = Department,\n                      size = centrality_betweenness()))\ng + theme_graph()\n\n\n\n\n\n\n\n\n\n\n6.7.3 Visualising Community\ntidygraph package inherits many of the community detection algorithms imbedded into igraph and makes them available to us, including Edge-betweenness (group_edge_betweenness), Leading eigenvector (group_leading_eigen), Fast-greedy (group_fast_greedy), Louvain (group_louvain), Walktrap (group_walktrap), Label propagation (group_label_prop), InfoMAP (group_infomap), Spinglass (group_spinglass), and Optimal (group_optimal). Some community algorithms are designed to take into account direction or weight, while others ignore it. Use this link to find out more about community detection functions provided by tidygraph,\nIn the code chunk below group_edge_betweenness() is used.\n\ng &lt;- GAStech_graph %&gt;%\n  mutate(community = as.factor(group_edge_betweenness(weights = Weight, directed = TRUE))) %&gt;%\n  ggraph(layout = \"fr\") +\n  geom_edge_link(aes(width = Weight),\n                 alpha = 0.2) +\n  scale_edge_width(range = c(0.1,5)) +\n  geom_node_point(aes(colour = community))\n\ng + theme_graph()"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex06.html#building-interactive-network-graph-with-visnetwork",
    "href": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex06.html#building-interactive-network-graph-with-visnetwork",
    "title": "Hands-on Exercise 6",
    "section": "6.8 Building Interactive Network Graph with visNetwork",
    "text": "6.8 Building Interactive Network Graph with visNetwork\n\nvisNetwork() is a R package for network visualization, using vis.js javascript library.\nvisNetwork() function uses a nodes list and edges list to create an interactive graph.\n\nThe nodes list must include an “id” column, and the edge list must have “from” and “to” columns.\nThe function also plots the labels for the nodes, using the names of the actors from the “label” column in the node list.\n\nThe resulting graph is fun to play around with.\n\nYou can move the nodes and the graph will use an algorithm to keep the nodes properly spaced.\nYou can also zoom in and out on the plot and move it around to re-center it.\n\n\n\n6.8.1 Data preparation\nBefore we can plot the interactive network graph, we need to prepare the data model by using the code chunk below.\n\nGAStech_edges_aggregated &lt;- GAStech_edges %&gt;%\n  left_join(GAStech_nodes, by=c(\"sourceLabel\" = \"label\")) %&gt;%\n  rename(from = id) %&gt;%\n  left_join(GAStech_nodes, by=c(\"targetLabel\" = \"label\")) %&gt;%\n  rename(to = id) %&gt;%\n  filter(MainSubject == \"Work related\") %&gt;%\n  group_by(from, to) %&gt;%\n    summarise(weight = n()) %&gt;%\n  filter(from!=to) %&gt;%\n  filter(weight &gt; 1) %&gt;%\n  ungroup()\n\n\n\n6.8.2 Plotting the first interactive network graph\nThe code chunk below will be used to plot an interactive network graph by using the data prepared.\n\nvisNetwork(GAStech_nodes, GAStech_edges_aggregated)\n\n\n\n\n\n\n\n6.8.3 Working with layout\nIn the code chunk below, Fruchterman and Reingold layout is used.\n\nvisNetwork(GAStech_nodes, GAStech_edges_aggregated) %&gt;%\n  visIgraphLayout(layout = \"layout_with_fr\")\n\n\n\n\n\n\n\n6.8.4 Working with visual attributes - Nodes\nvisNetwork() looks for a field called “group” in the nodes object and colour the nodes according to the values of the group field.\nThe code chunk below rename Department field to group.\n\nGAStech_nodes &lt;- GAStech_nodes %&gt;%\n  rename(group = Department)\n\nWhen we rerun the code chunk below, visNetwork shades the nodes by assigning unique colour to each category in the group field.\n\nvisNetwork(GAStech_nodes,\n           GAStech_edges_aggregated) %&gt;%\n  visIgraphLayout(layout = \"layout_with_fr\") %&gt;%\n  visLegend() %&gt;%\n  visLayout(randomSeed = 123)\n\n\n\n\n\n\n\n6.8.5 Working with visual attributes - Edges\nIn the code run below visEdges() is used to symbolise the edges.\n- The argument arrows is used to define where to place the arrow.\n- The smooth argument is used to plot the edges using a smooth curve.\n\nvisNetwork(GAStech_nodes,\n           GAStech_edges_aggregated) %&gt;%\n  visIgraphLayout(layout = \"layout_with_fr\") %&gt;%\n  visEdges(arrows = \"to\",\n           smooth = list(enabled = TRUE,\n                         type = \"curvedCW\")) %&gt;%\n  visLegend() %&gt;%\n  visLayout(randomSeed = 123)\n\n\n\n\n\n\n\n6.8.6 Interactivity\nIn the code chunk below, visOptions() is used to incorporate interactivity features in the data visualisation.\n\nThe argument highlightNearest highlights nearest when clicking a node.\nThe argument nodesIdSelection adds an id node selection creating an HTML select element.\n\n\nvisNetwork(GAStech_nodes,\n           GAStech_edges_aggregated) %&gt;%\n  visIgraphLayout(layout = \"layout_with_fr\") %&gt;%\n  visOptions(highlightNearest = TRUE,\n             nodesIdSelection = TRUE) %&gt;%\n  visLegend() %&gt;%\n  visLayout(randomSeed = 123)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex08/Hands-on_Ex08_parta.html",
    "href": "Hands-on_Ex/Hands-on_Ex08/Hands-on_Ex08_parta.html",
    "title": "Hands-on Exercise 8: Part A",
    "section": "",
    "text": "Choropleth mapping involves the symbolisation of enumeration units, such as countries, provinces, states, counties or census units, using area patterns or graduated colors. For example, a social scientist may need to use a choropleth map to portray the spatial distribution of aged population of Singapore by Master Plan 2014 Subzone Boundary.\nIn this chapter, you will learn how to plot functional and truthful choropleth maps by using an R package called tmap package."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex08/Hands-on_Ex08_parta.html#overview",
    "href": "Hands-on_Ex/Hands-on_Ex08/Hands-on_Ex08_parta.html#overview",
    "title": "Hands-on Exercise 8: Part A",
    "section": "",
    "text": "Choropleth mapping involves the symbolisation of enumeration units, such as countries, provinces, states, counties or census units, using area patterns or graduated colors. For example, a social scientist may need to use a choropleth map to portray the spatial distribution of aged population of Singapore by Master Plan 2014 Subzone Boundary.\nIn this chapter, you will learn how to plot functional and truthful choropleth maps by using an R package called tmap package."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex08/Hands-on_Ex08_parta.html#getting-started",
    "href": "Hands-on_Ex/Hands-on_Ex08/Hands-on_Ex08_parta.html#getting-started",
    "title": "Hands-on Exercise 8: Part A",
    "section": "8.2 Getting Started",
    "text": "8.2 Getting Started\nIn this hands-on exercise, the key R package use is tmap package in R. Beside tmap package, four other R packages will be used. They are:\n\nreadr for importing delimited text file,\ntidyr for tidying data,\ndplyr for wrangling data and\nsf for handling geospatial data.\n\nAmong the four packages, readr, tidyr and dplyr are part of tidyverse package.\nThe code chunk below will be used to install and load these packages in RStudio.\n\npacman::p_load(sf, tmap, tidyverse)\n\n\n8.3.1 The Data\nTwo data set will be used to create the choropleth map. They are:\n\nMaster Plan 2014 Subzone Boundary (Web) (i.e. MP14_SUBZONE_WEB_PL) in ESRI shapefile format. It can be downloaded at data.gov.sg This is a geospatial data. It consists of the geographical boundary of Singapore at the planning subzone level. The data is based on URA Master Plan 2014.\nSingapore Residents by Planning Area / Subzone, Age Group, Sex and Type of Dwelling, June 2011-2020 in csv format (i.e. respopagesextod2011to2020.csv). This is an aspatial data fie. It can be downloaded at Department of Statistics, Singapore Although it does not contain any coordinates values, but it’s PA and SZ fields can be used as unique identifiers to geocode to MP14_SUBZONE_WEB_PL shapefile.\n\n\n\n8.3.2 Importing Geospatial Data into R\nThe code chunk below uses the st_read() function of sf package to import MP14_SUBZONE_WEB_PL shapefile into R as a simple feature data frame called mpsz.\n\nmpsz &lt;- st_read(dsn = \"data/geospatial\", \n                layer = \"MP14_SUBZONE_WEB_PL\")\n\nReading layer `MP14_SUBZONE_WEB_PL' from data source \n  `C:\\sarthakjn1\\ISSS608-VAA\\Hands-on_Ex\\Hands-on_Ex08\\data\\geospatial' \n  using driver `ESRI Shapefile'\nSimple feature collection with 323 features and 15 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 2667.538 ymin: 15748.72 xmax: 56396.44 ymax: 50256.33\nProjected CRS: SVY21\n\n\n\nmpsz\n\nSimple feature collection with 323 features and 15 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 2667.538 ymin: 15748.72 xmax: 56396.44 ymax: 50256.33\nProjected CRS: SVY21\nFirst 10 features:\n   OBJECTID SUBZONE_NO       SUBZONE_N SUBZONE_C CA_IND      PLN_AREA_N\n1         1          1    MARINA SOUTH    MSSZ01      Y    MARINA SOUTH\n2         2          1    PEARL'S HILL    OTSZ01      Y          OUTRAM\n3         3          3       BOAT QUAY    SRSZ03      Y SINGAPORE RIVER\n4         4          8  HENDERSON HILL    BMSZ08      N     BUKIT MERAH\n5         5          3         REDHILL    BMSZ03      N     BUKIT MERAH\n6         6          7  ALEXANDRA HILL    BMSZ07      N     BUKIT MERAH\n7         7          9   BUKIT HO SWEE    BMSZ09      N     BUKIT MERAH\n8         8          2     CLARKE QUAY    SRSZ02      Y SINGAPORE RIVER\n9         9         13 PASIR PANJANG 1    QTSZ13      N      QUEENSTOWN\n10       10          7       QUEENSWAY    QTSZ07      N      QUEENSTOWN\n   PLN_AREA_C       REGION_N REGION_C          INC_CRC FMEL_UPD_D   X_ADDR\n1          MS CENTRAL REGION       CR 5ED7EB253F99252E 2014-12-05 31595.84\n2          OT CENTRAL REGION       CR 8C7149B9EB32EEFC 2014-12-05 28679.06\n3          SR CENTRAL REGION       CR C35FEFF02B13E0E5 2014-12-05 29654.96\n4          BM CENTRAL REGION       CR 3775D82C5DDBEFBD 2014-12-05 26782.83\n5          BM CENTRAL REGION       CR 85D9ABEF0A40678F 2014-12-05 26201.96\n6          BM CENTRAL REGION       CR 9D286521EF5E3B59 2014-12-05 25358.82\n7          BM CENTRAL REGION       CR 7839A8577144EFE2 2014-12-05 27680.06\n8          SR CENTRAL REGION       CR 48661DC0FBA09F7A 2014-12-05 29253.21\n9          QT CENTRAL REGION       CR 1F721290C421BFAB 2014-12-05 22077.34\n10         QT CENTRAL REGION       CR 3580D2AFFBEE914C 2014-12-05 24168.31\n     Y_ADDR SHAPE_Leng SHAPE_Area                       geometry\n1  29220.19   5267.381  1630379.3 MULTIPOLYGON (((31495.56 30...\n2  29782.05   3506.107   559816.2 MULTIPOLYGON (((29092.28 30...\n3  29974.66   1740.926   160807.5 MULTIPOLYGON (((29932.33 29...\n4  29933.77   3313.625   595428.9 MULTIPOLYGON (((27131.28 30...\n5  30005.70   2825.594   387429.4 MULTIPOLYGON (((26451.03 30...\n6  29991.38   4428.913  1030378.8 MULTIPOLYGON (((25899.7 297...\n7  30230.86   3275.312   551732.0 MULTIPOLYGON (((27746.95 30...\n8  30222.86   2208.619   290184.7 MULTIPOLYGON (((29351.26 29...\n9  29893.78   6571.323  1084792.3 MULTIPOLYGON (((20996.49 30...\n10 30104.18   3454.239   631644.3 MULTIPOLYGON (((24472.11 29...\n\n\n\n\n8.3.3 Importing Attribute Data into R\nNext, we will import respopagsex2011to2020.csv file into RStudio and save the file into an R dataframe called popagsex.\nThe task will be performed by using read_csv() function of readr package as shown in the code chunk below.\n\npopdata &lt;- read_csv(\"data/aspatial/respopagesextod2011to2020.csv\")\n\n\n\n8.3.4 Data Preparation\nBefore a thematic map can be prepared, you are required to prepare a data table with year 2020 values. The data table should include the variables PA, SZ, YOUNG, ECONOMY ACTIVE, AGED, TOTAL, DEPENDENCY.\n\nYOUNG: age group 0 to 4 until age groyup 20 to 24,\nECONOMY ACTIVE: age group 25-29 until age group 60-64,\nAGED: age group 65 and above,\nTOTAL: all age group, and\nDEPENDENCY: the ratio between young and aged against economy active group\n\n\n8.3.4.1 Data wrangling\nThe following data wrangling and transformation functions will be used:\n\npivot_wider() of tidyr package, and\nmutate(), filter(), group_by() and select() of dplyr package\n\n\npopdata2020 &lt;- popdata %&gt;%\n  filter(Time == 2020) %&gt;%\n  group_by(PA, SZ, AG) %&gt;%\n  summarise(`POP` = sum(`Pop`)) %&gt;%\n  ungroup() %&gt;%\n  pivot_wider(names_from=AG, \n              values_from=POP) %&gt;%\n  mutate(YOUNG = rowSums(.[3:6])\n         +rowSums(.[12])) %&gt;%\nmutate(`ECONOMY ACTIVE` = rowSums(.[7:11])+\nrowSums(.[13:15]))%&gt;%\nmutate(`AGED`=rowSums(.[16:8])) %&gt;%\nmutate(`TOTAL`=rowSums(.[3:8])) %&gt;%  \nmutate(`DEPENDENCY` = (`YOUNG` + `AGED`)\n/`ECONOMY ACTIVE`) %&gt;%\n  select(`PA`, `SZ`, `YOUNG`, \n       `ECONOMY ACTIVE`, `AGED`, \n       `TOTAL`, `DEPENDENCY`)\n\n\n\n8.3.4.2 Joining the attribute data and geospatial data\nBefore we can perform the georelational join, one extra step is required to convert the values in PA and SZ fields to uppercase. This is because the values of PA and SZ fields are made up of upper- and lowercase. On the other, hand the SUBZONE_N and PLN_AREA_N are in uppercase.\n\npopdata2020 &lt;- popdata2020 %&gt;%\n  mutate_at(.vars = vars(PA, SZ), \n          .funs = list(toupper)) %&gt;%\n  filter(`ECONOMY ACTIVE` &gt; 0)\n\nNext, left_join() of dplyr is used to join the geographical data and attribute table using planning subzone name e.g. SUBZONE_N and SZ as the common identifier.\n\nmpsz_pop2020 &lt;- left_join(mpsz, popdata2020,\n                          by = c(\"SUBZONE_N\" = \"SZ\"))\n\n\nwrite_rds(mpsz_pop2020, \"data/rds/mpszpop2020.rds\")"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex08/Hands-on_Ex08_parta.html#choropleth-mapping-geospatial-data-using-tmap",
    "href": "Hands-on_Ex/Hands-on_Ex08/Hands-on_Ex08_parta.html#choropleth-mapping-geospatial-data-using-tmap",
    "title": "Hands-on Exercise 8: Part A",
    "section": "8.4 Choropleth Mapping Geospatial Data Using tmap",
    "text": "8.4 Choropleth Mapping Geospatial Data Using tmap\nTwo approaches can be used to prepare thematic map using tmap, they are:\n\nPlotting a thematic map quickly by using qtm().\nPlotting highly customisable thematic map by using tmap elements.\n\n\n8.4.1 Plotting a choropleth map quickly by using qtm()\nThe easiest and quickest to draw a choropleth map using tmap is using qtm(). It is concise and provides a good default visualisation in many cases.\nThe code chunk below will draw a cartographic standard choropleth map as shown below.\n\ntmap_mode(\"plot\")\nqtm(mpsz_pop2020,\n    fill = \"DEPENDENCY\")\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nThings to learn from code chunk above:\n\n\n\n\ntmap_mode() with “plot” option is used to produce a static map. For interactive mode, “view” option should be used.\nfill argument is used to map the attribute (i.e. DEPENDENCY)\n\n\n\n\n\n8.4.2 Creating a choropleth map by using tmap’s elements\nDespite its usefulness of drawing a choropleth map quickly and easily, the disadvantge of qtm() is that it makes aesthetics of individual layers harder to control. To draw a high quality cartographic choropleth map as shown in the figure below, tmap’s drawing elements should be used.\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\", \n          style = \"quantile\", \n          palette = \"Blues\",\n          title = \"Dependency ratio\") +\n  tm_layout(main.title = \"Distribution of Dependency Ratio by planning subzone\",\n            main.title.position = \"center\",\n            main.title.size = 1.2,\n            legend.height = 0.45, \n            legend.width = 0.35,\n            frame = TRUE) +\n  tm_borders(alpha = 0.5) +\n  tm_compass(type=\"8star\", size = 2) +\n  tm_scale_bar() +\n  tm_grid(alpha =0.2) +\n  tm_credits(\"Source: Planning Sub-zone boundary from Urban Redevelopment Authorithy (URA)\\n and Population data from Department of Statistics DOS\", \n             position = c(\"left\", \"bottom\"))\n\n\n\n\n\n\n\n\nIn the following sub-section, we will share with you tmap functions that used to plot these elements.\n\n8.4.2.1 Drawing a base map\nThe basic building block of tmap is tm_shape() followed by one or more layer elemments such as tm_fill() and tm_polygons().\nIn the code chunk below, tm_shape() is used to define the input data (i.e mpsz_pop2020) and tm_polygons() is used to draw the planning subzone polygons.\n\ntm_shape(mpsz_pop2020) +\n  tm_polygons()\n\n\n\n\n\n\n\n\n\n\n8.4.2.2 Drawing a choropleth map using tm_polygons()\nTo draw a choropleth map showing the geographical distribution of a selected variable by planning subzone, we just need to assign the target variable such as Dependency to tm_polygons().\n\ntm_shape(mpsz_pop2020)+\n  tm_polygons(\"DEPENDENCY\")\n\n\n\n\n\n\n\n\nThings to learn from tm_polygons():\n\nThe default interval binning used to draw the choropleth map is called “pretty”. A detailed discussion of the data classification methods supported by tmap will be provided in sub-section 4.3.\nThe default colour scheme used is YlOrRd of ColorBrewer. You will learn more about the color scheme in sub-section 4.4.\nBy default, Missing value will be shaded in grey.\n\n\n\n8.4.2.3 Drawing a choropleth map using tm_fill() and *tm_border()**\nActually, tm_polygons() is a wraper of tm_fill() and tm_border(). tm_fill() shades the polygons by using the default colour scheme and tm_borders() adds the borders of the shapefile onto the choropleth map.\nThe code chunk below draws a choropleth map by using tm_fill() alone.\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\")\n\n\n\n\n\n\n\n\nNotice that the planning subzones are shared according to the respective dependecy values\nTo add the boundary of the planning subzones, tm_borders will be used as shown in the code chunk below.\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\") +\n  tm_borders(lwd = 0.1,  alpha = 1)\n\n\n\n\n\n\n\n\nNotice that light-gray border lines have been added on the choropleth map.\nThe alpha argument is used to define transparency number between 0 (totally transparent) and 1 (not transparent). By default, the alpha value of the col is used (normally 1).\nBeside alpha argument, there are three other arguments for tm_borders(), they are:\n\ncol = border colour,\nlwd = border line width. The default is 1, and\nlty = border line type. The default is “solid”.\n\n\n\n\n8.4.3 Data classification methods of tmap\nMost choropleth maps employ some methods of data classification. The point of classification is to take a large number of observations and group them into data ranges or classes.\ntmap provides a total ten data classification methods, namely: fixed, sd, equal, pretty (default), quantile, kmeans, hclust, bclust, fisher, and jenks.\nTo define a data classification method, the style argument of tm_fill() or tm_polygons() will be used.\n\n8.4.3.1 Plotting choropleth maps with built-in classification methods\nThe code chunk below shows a quantile data classification that used 5 classes.\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\",\n          n = 5,\n          style = \"jenks\") +\n  tm_borders(alpha = 0.5)\n\n\n\n\n\n\n\n\nIn the code chunk below, equal data classification method is used.\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\",\n          n = 5,\n          style = \"equal\") +\n  tm_borders(alpha = 0.5)\n\n\n\n\n\n\n\n\nNotice that the distribution of quantile data classification method are more evenly distributed then equal data classification method.\n\n\n8.4.3.2 Plotting choropleth map with custome break\nFor all the built-in styles, the category breaks are computed internally. In order to override these defaults, the breakpoints can be set explicitly by means of the breaks argument to the tm_fill(). It is important to note that, in tmap the breaks include a minimum and maximum. As a result, in order to end up with n categories, n+1 elements must be specified in the breaks option (the values must be in increasing order).\nBefore we get started, it is always a good practice to get some descriptive statistics on the variable before setting the break points. Code chunk below will be used to compute and display the descriptive statistics of DEPENDENCY field.\n\nsummary(mpsz_pop2020$DEPENDENCY)\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max.    NA's \n 0.8333  1.5540  1.6138  1.6099  1.6603  3.0000      92 \n\n\nWith reference to the results above, we set break point at 0.60, 0.70, 0.80, and 0.90. In addition, we also need to include a minimum and maximum, which we set at 0 and 100. Our breaks vector is thus c(0, 0.60, 0.70, 0.80, 0.90, 1.00)\nNow, we will plot the choropleth map by using the code chunk below.\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\",\n          breaks = c(0, 0.60, 0.70, 0.80, 0.90, 1.00)) +\n  tm_borders(alpha = 0.5)\n\n\n\n\n\n\n\n\n\n\n\n8.4.4 Colour Scheme\ntmap supports colour ramps either defined by the user or a set of predefined colour ramps from the RColorBrewer package.\n\n8.4.4.1 Using ColourBrewer palette\nTo change the colour, we assign the preferred colour to palette argument of tm_fill() as shown in the code chunk below.\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\",\n          n = 6,\n          style = \"quantile\",\n          palette = \"Blues\") +\n  tm_borders(alpha = 0.5)\n\n\n\n\n\n\n\n\nNotice that the choropleth map is shaded in green.\nTo reverse the colour shading, add a “-” prefix.\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\",\n          style = \"quantile\",\n          palette = \"-Greens\") +\n  tm_borders(alpha = 0.5)\n\n\n\n\n\n\n\n\nNotice that the colour scheme has been reversed.\n\n\n\n8.4.5 Map Layouts\nMap layout refers to the combination of all map elements into a cohensive map. Map elements include among others the objects to be mapped, the title, the scale bar, the compass, margins and aspects ratios. Colour settings and data classification methods covered in the previous section relate to the palette and break-points are used to affect how the map looks.\n\n8.4.5.1 Map Legend\nIn tmap, several legend options are provided to change the placement, format and appearance of the legend.\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\", \n          style = \"jenks\", \n          palette = \"Blues\", \n          legend.hist = TRUE, \n          legend.is.portrait = TRUE,\n          legend.hist.z = 0.1) +\n  tm_layout(main.title = \"Distribution of Dependency Ratio by planning subzone \\n(Jenks classification)\",\n            main.title.position = \"center\",\n            main.title.size = 1,\n            legend.height = 0.45, \n            legend.width = 0.35,\n            legend.outside = FALSE,\n            legend.position = c(\"right\", \"bottom\"),\n            frame = FALSE) +\n  tm_borders(alpha = 0.5)\n\n\n\n\n\n\n\n\n\n\n8.4.5.2 Map style\ntmap allows a wide variety of layout settings to be changed. They can be called by using tmap_style().\nThe code chunk below shows the classic style is used.\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\", \n          style = \"quantile\", \n          palette = \"-Greens\") +\n  tm_borders(alpha = 0.5) +\n  tmap_style(\"classic\")\n\n\n\n\n\n\n\n\n\n\n8.4.5.3 Cartographic Furniture\nBeside map style, tmap also also provides arguments to draw other map furniture such as compass, scale bar and grid lines.\nIn the code chunk below, tm_compass(), tm_scale_bar() and tm_grid() are used to add compass, scale bar and grid lines onto the choropleth map.\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\", \n          style = \"quantile\", \n          palette = \"Blues\",\n          title = \"No. of persons\") +\n  tm_layout(main.title = \"Distribution of Dependency Ratio \\nby planning subzone\",\n            main.title.position = \"center\",\n            main.title.size = 1.2,\n            legend.height = 0.45, \n            legend.width = 0.35,\n            frame = TRUE) +\n  tm_borders(alpha = 0.5) +\n  tm_compass(type=\"8star\", size = 2) +\n  tm_scale_bar(width = 0.15) +\n  tm_grid(lwd = 0.1, alpha = 0.2) +\n  tm_credits(\"Source: Planning Sub-zone boundary from Urban Redevelopment Authorithy (URA)\\n and Population data from Department of Statistics DOS\", \n             position = c(\"left\", \"bottom\"))\n\n\n\n\n\n\n\n\nTo reset the default style, refer to the code chunk below.\n\ntmap_style(\"white\")\n\n\n\n\n8.4.6 Drawing Small Multiple Choropleth Maps\nSmall multiple maps, also referred to as facet maps, are composed of many maps arrange side-by-side, and sometimes stacked vertically. Small multiple maps enable the visualisation of how spatial relationships change with respect to another variable, such as time.\nIn tmap, small multiple maps can be plotted in three ways:\n\nby assigning multiple values to at least one of the asthetic arguments,\nby defining a group-by variable in tm_facets(), and\nby creating multiple stand-alone maps with tmap_arrange().\n\n\n8.4.6.1 By assigning multiple values to at least one of the aesthetic arguments\nIn this example, small multiple choropleth maps are created by defining ncols in tm_fill()\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(c(\"YOUNG\", \"AGED\"),\n          style = \"equal\", \n          palette = \"Blues\") +\n  tm_layout(legend.position = c(\"right\", \"bottom\")) +\n  tm_borders(alpha = 0.5) +\n  tmap_style(\"white\")\n\n\n\n\n\n\n\n\nIn this example, small multiple choropleth maps are created by assigning multiple values to at least one of the aesthetic arguments.\n\ntm_shape(mpsz_pop2020)+ \n  tm_polygons(c(\"DEPENDENCY\",\"AGED\"),\n          style = c(\"equal\", \"quantile\"), \n          palette = list(\"Blues\",\"Greens\")) +\n  tm_layout(legend.position = c(\"right\", \"bottom\"))\n\n\n\n\n\n\n\n\n\n\n8.4.6.2 By defining a group-by variable in tm_facets()\nIn this example, multiple small choropleth maps are created by using tm_facets().\n\ntm_shape(mpsz_pop2020) +\n  tm_fill(\"DEPENDENCY\",\n          style = \"quantile\",\n          palette = \"Blues\",\n          thres.poly = 0) + \n  tm_facets(by=\"REGION_N\", \n            free.coords=TRUE, \n            drop.shapes=FALSE) +\n  tm_layout(legend.show = FALSE,\n            title.position = c(\"center\", \"center\"), \n            title.size = 20) +\n  tm_borders(alpha = 0.5)\n\n\n\n\n\n\n\n\n\n\n8.4.6.3 By creating multiple stand-alone maps with tmap_arrange()\nIn this example, multiple small choropleth maps are created by creating multiple stand-alone maps with tmap_arrange().\n\nyoungmap &lt;- tm_shape(mpsz_pop2020)+ \n  tm_polygons(\"YOUNG\", \n              style = \"quantile\", \n              palette = \"Blues\")\n\nagedmap &lt;- tm_shape(mpsz_pop2020)+ \n  tm_polygons(\"AGED\", \n              style = \"quantile\", \n              palette = \"Blues\")\n\ntmap_arrange(youngmap, agedmap, asp=1, ncol=2)\n\n\n\n\n\n\n\n\n\n\n\n8.4.7 Mapping Spatial Object Meeting a Selection Criterion\nInstead of creating small multiple choropleth map, you can also use selection funtion to map spatial objects meeting the selection criterion.\n\ntm_shape(mpsz_pop2020[mpsz_pop2020$REGION_N==\"CENTRAL REGION\", ])+\n  tm_fill(\"DEPENDENCY\", \n          style = \"quantile\", \n          palette = \"Blues\", \n          legend.hist = TRUE, \n          legend.is.portrait = TRUE,\n          legend.hist.z = 0.1) +\n  tm_layout(legend.outside = TRUE,\n            legend.height = 0.45, \n            legend.width = 5.0,\n            legend.position = c(\"right\", \"bottom\"),\n            frame = FALSE) +\n  tm_borders(alpha = 0.5)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex08/Hands-on_Ex08_parta.html#reference",
    "href": "Hands-on_Ex/Hands-on_Ex08/Hands-on_Ex08_parta.html#reference",
    "title": "Hands-on Exercise 8: Part A",
    "section": "8.5 Reference",
    "text": "8.5 Reference\n\n8.5.1 All about tmap package\n\ntmap: Thematic Maps in R\ntmap\ntmap: get started!\ntmap: changes in version 2.0\ntmap: creating thematic maps in a flexible way (useR!2015)\nExploring and presenting maps with tmap (useR!2017)\n\n\n\n8.5.2 Geospatial data wrangling\n\nsf: Simple Features for R\nSimple Features for R: StandardizedSupport for Spatial Vector Data\nReading, Writing and Converting Simple Features\n\n\n\n8.5.3 Data wrangling\n\ndplyr\nTidy data\ntidyr: Easily Tidy Data with ‘spread()’ and ‘gather()’ Functions"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex08/Hands-on_Ex08_partc.html",
    "href": "Hands-on_Ex/Hands-on_Ex08/Hands-on_Ex08_partc.html",
    "title": "Hands-on Exercise 8: Part C",
    "section": "",
    "text": "In this in-class exercise, you will gain hands-on experience on using appropriate R methods to plot analytical maps.\n\n\n\nBy the end of this in-class exercise, you will be able to use appropriate functions of tmap and tidyverse to perform the following tasks:\n\nImporting geospatial data in rds format into R environment.\nCreating cartographic quality choropleth maps by using appropriate tmap functions.\nCreating rate map\nCreating percentile map\nCreating boxmap"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex08/Hands-on_Ex08_partc.html#overview",
    "href": "Hands-on_Ex/Hands-on_Ex08/Hands-on_Ex08_partc.html#overview",
    "title": "Hands-on Exercise 8: Part C",
    "section": "",
    "text": "In this in-class exercise, you will gain hands-on experience on using appropriate R methods to plot analytical maps.\n\n\n\nBy the end of this in-class exercise, you will be able to use appropriate functions of tmap and tidyverse to perform the following tasks:\n\nImporting geospatial data in rds format into R environment.\nCreating cartographic quality choropleth maps by using appropriate tmap functions.\nCreating rate map\nCreating percentile map\nCreating boxmap"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex08/Hands-on_Ex08_partc.html#getting-started",
    "href": "Hands-on_Ex/Hands-on_Ex08/Hands-on_Ex08_partc.html#getting-started",
    "title": "Hands-on Exercise 8: Part C",
    "section": "8.2 Getting Started",
    "text": "8.2 Getting Started\n\n8.2.1 Installing and loading packages\nInstalling and loading sf, tmap and tidyverse packages into R environment.\n\npacman::p_load(sf, tmap, tidyverse)\n\n\n\n8.2.2 Importing data\nFor the purpose of this hands-on exercise, a prepared data set called NGA_wp.rds will be used. The data set is a polygon feature data.frame providing information on water point of Nigeria at the LGA level. You can find the data set in the rds sub-direct of the hands-on data folder.\n\nNGA_wp &lt;- read_rds(\"data/rds/NGA_wp.rds\")"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex08/Hands-on_Ex08_partc.html#basic-choropleth-mapping",
    "href": "Hands-on_Ex/Hands-on_Ex08/Hands-on_Ex08_partc.html#basic-choropleth-mapping",
    "title": "Hands-on Exercise 8: Part C",
    "section": "8.3 Basic Choropleth Mapping",
    "text": "8.3 Basic Choropleth Mapping\n\n8.3.1 Visualising distribution of non-functional water point\n\np1 &lt;- tm_shape(NGA_wp) +\n  tm_fill(\"wp_functional\",\n          n = 10,\n          style = \"equal\",\n          palette = \"Blues\") +\n  tm_borders(lwd = 0.1,\n             alpha = 1) +\n  tm_layout(main.title = \"Distribution of functional water point by LGAs\",\n            legend.outside = FALSE)\n\n\np2 &lt;- tm_shape(NGA_wp) +\n  tm_fill(\"total_wp\",\n          n = 10,\n          style = \"equal\",\n          palette = \"Blues\") +\n  tm_borders(lwd = 0.1,\n             alpha = 1) +\n  tm_layout(main.title = \"Distribution of total  water point by LGAs\",\n            legend.outside = FALSE)\n\n\ntmap_arrange(p2, p1, nrow = 1)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex08/Hands-on_Ex08_partc.html#choropleth-map-for-rates",
    "href": "Hands-on_Ex/Hands-on_Ex08/Hands-on_Ex08_partc.html#choropleth-map-for-rates",
    "title": "Hands-on Exercise 8: Part C",
    "section": "8.4 Choropleth Map for Rates",
    "text": "8.4 Choropleth Map for Rates\nIn much of our readings we have now seen the importance to map rates rather than counts of things, and that is for the simple reason that water points are not equally distributed in space. That means that if we do not account for how many water points are somewhere, we end up mapping total water point size rather than our topic of interest.\n\n8.4.1 Deriving Proportion of Functional Water Points and Non-Functional Water Points\nWe will tabulate the proportion of functional water points and the proportion of non-functional water points in each LGA. In the following code chunk, mutate() from dplyr package is used to derive two fields, namely pct_functional and pct_nonfunctional.\n\nNGA_wp &lt;- NGA_wp %&gt;%\n  mutate(pct_functional = wp_functional/total_wp) %&gt;%\n  mutate(pct_nonfunctional = wp_nonfunctional/total_wp)\n\n\n\n8.4.2 Plotting map of rate\n\ntm_shape(NGA_wp) +\n  tm_fill(\"pct_functional\",\n          n = 10,\n          style = \"equal\",\n          palette = \"Blues\",\n          legend.hist = TRUE) +\n  tm_borders(lwd = 0.1,\n             alpha = 1) +\n  tm_layout(main.title = \"Rate map of functional water point by LGAs\",\n            legend.outside = TRUE)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex08/Hands-on_Ex08_partc.html#extreme-value-maps",
    "href": "Hands-on_Ex/Hands-on_Ex08/Hands-on_Ex08_partc.html#extreme-value-maps",
    "title": "Hands-on Exercise 8: Part C",
    "section": "8.5 Extreme Value Maps",
    "text": "8.5 Extreme Value Maps\nExtreme value maps are variations of common choropleth maps where the classification is designed to highlight extreme values at the lower and upper end of the scale, with the goal of identifying outliers. These maps were developed in the spirit of spatializing EDA, i.e., adding spatial features to commonly used approaches in non-spatial EDA (Anselin 1994).\n\n8.5.1 Percentile Map\nThe percentile map is a special type of quantile map with six specific categories: 0-1%,1-10%, 10-50%,50-90%,90-99%, and 99-100%. The corresponding breakpoints can be derived by means of the base R quantile command, passing an explicit vector of cumulative probabilities as c(0,.01,.1,.5,.9,.99,1). Note that the begin and endpoint need to be included.\n\n8.5.1.1 Data Preparation\nStep 1: Exclude records with NA by using the code chunk below.\n\nNGA_wp &lt;- NGA_wp %&gt;%\n  drop_na()\n\nStep 2: Creating customised classification and extracting values.\n\npercent &lt;- c(0,.01,.1,.5,.9,.99,1)\nvar &lt;- NGA_wp[\"pct_functional\"] %&gt;%\n  st_set_geometry(NULL)\nquantile(var[,1], percent)\n\n       0%        1%       10%       50%       90%       99%      100% \n0.0000000 0.0000000 0.2169811 0.4791667 0.8611111 1.0000000 1.0000000 \n\n\n\n\n8.5.1.2 Why writing functions?\nWriting a function has three big advantages over using copy-and-paste:\n\nYou can give a function an evocative name that makes your code easier to understand.\nAs requirements change, you only need to update code in one place, instead of many.\nYou eliminate the chance of making incidental mistakes when you copy and paste (i.e. updating a variable name in one place, but not in another).\n\nSource: Chapter 19: Functions of R for Data Science.\n\n\n8.5.1.3 Creating the get.var function\nFirstly, we will write an R function as shown below to extract a variable (i.e. wp_nonfunctional) as a vector out of an sf data.frame.\n\narguments:\n\nvname: variable name (as character, in quotes)\ndf: name of sf data frame\n\nreturns:\n\nv: vector with values (without a column name)\n\n\n\nget.var &lt;- function(vname,df) {\n  v &lt;- df[vname] %&gt;% \n    st_set_geometry(NULL)\n  v &lt;- unname(v[,1])\n  return(v)\n}\n\n\n\n8.5.1.4 A percentile mapping function\nNext, we will write a percentile mapping function by using the code chunk below.\n\npercentmap &lt;- function(vnam, df, legtitle=NA, mtitle=\"Percentile Map\"){\n  percent &lt;- c(0,.01,.1,.5,.9,.99,1)\n  var &lt;- get.var(vnam, df)\n  bperc &lt;- quantile(var, percent)\n  tm_shape(df) +\n  tm_polygons() +\n  tm_shape(df) +\n     tm_fill(vnam,\n             title=legtitle,\n             breaks=bperc,\n             palette=\"Blues\",\n          labels=c(\"&lt; 1%\", \"1% - 10%\", \"10% - 50%\", \"50% - 90%\", \"90% - 99%\", \"&gt; 99%\"))  +\n  tm_borders() +\n  tm_layout(main.title = mtitle, \n            title.position = c(\"right\",\"bottom\"))\n}\n\n\n\n8.5.1.5 Test drive the percentile mapping function\nTo run the function, type the code chunk as shown below.\n\npercentmap(\"total_wp\", NGA_wp)\n\n\n\n\n\n\n\n\nNote that this is just a bare bones implementation. Additional arguments such as the title, legend positioning just to name a few of them, could be passed to customise various features of the map.\n\n\n\n8.5.2 Box map\nIn essence, a box map is an augmented quartile map, with an additional lower and upper category. When there are lower outliers, then the starting point for the breaks is the minimum value, and the second break is the lower fence. In contrast, when there are no lower outliers, then the starting point for the breaks will be the lower fence, and the second break is the minimum value (there will be no observations that fall in the interval between the lower fence and the minimum value).\n\nggplot(data = NGA_wp,\n       aes(x = \"\",\n           y = wp_nonfunctional)) +\n  geom_boxplot()\n\n\n\n\n\n\n\n\n\nDisplaying summary statistics on a choropleth map by using the basic principles of boxplot.\nTo create a box map, a custom breaks specification will be used. However, there is a complication. The break points for the box map vary depending on whether lower or upper outliers are present.\n\n\n8.5.2.1 Creating the boxbreaks function\nThe code chunk below is an R function that creating break points for a box map.\n\narguments:\n\nv: vector with observations\nmult: multiplier for IQR (default 1.5)\n\nreturns:\n\nbb: vector with 7 break points compute quartile and fences\n\n\n\nboxbreaks &lt;- function(v,mult=1.5) {\n  qv &lt;- unname(quantile(v))\n  iqr &lt;- qv[4] - qv[2]\n  upfence &lt;- qv[4] + mult * iqr\n  lofence &lt;- qv[2] - mult * iqr\n  # initialize break points vector\n  bb &lt;- vector(mode=\"numeric\",length=7)\n  # logic for lower and upper fences\n  if (lofence &lt; qv[1]) {  # no lower outliers\n    bb[1] &lt;- lofence\n    bb[2] &lt;- floor(qv[1])\n  } else {\n    bb[2] &lt;- lofence\n    bb[1] &lt;- qv[1]\n  }\n  if (upfence &gt; qv[5]) { # no upper outliers\n    bb[7] &lt;- upfence\n    bb[6] &lt;- ceiling(qv[5])\n  } else {\n    bb[6] &lt;- upfence\n    bb[7] &lt;- qv[5]\n  }\n  bb[3:5] &lt;- qv[2:4]\n  return(bb)\n}\n\n\n\n8.5.2.2 Creating the get.var function\nThe code chunk below is an R function to extract a variable as a vector out of an sf data frame.\n\narguments:\n\nvname: variable name (as character, in quotes)\ndf: name of sf data frame\n\nreturns:\n\nv: vector with values (without a column name)\n\n\n\nget.var &lt;- function(vname,df) {\n  v &lt;- df[vname] %&gt;% st_set_geometry(NULL)\n  v &lt;- unname(v[,1])\n  return(v)\n}\n\n\n\n8.5.2.3 Test drive the newly created function\nLet’s test the newly created function\n\nvar &lt;- get.var(\"wp_nonfunctional\", NGA_wp) \nboxbreaks(var)\n\n[1] -56.5   0.0  14.0  34.0  61.0 131.5 278.0\n\n\n\n\n8.5.2.4 Boxmap function\nThe code chunk below is an R function to create a box map. - arguments: - vnam: variable name (as character, in quotes) - df: simple features polygon layer - legtitle: legend title - mtitle: map title - mult: multiplier for IQR - returns: - a tmap-element (plots a map)\n\nboxmap &lt;- function(vnam, df, \n                   legtitle=NA,\n                   mtitle=\"Box Map\",\n                   mult=1.5){\n  var &lt;- get.var(vnam,df)\n  bb &lt;- boxbreaks(var)\n  tm_shape(df) +\n    tm_polygons() +\n  tm_shape(df) +\n     tm_fill(vnam,title=legtitle,\n             breaks=bb,\n             palette=\"Blues\",\n          labels = c(\"lower outlier\", \n                     \"&lt; 25%\", \n                     \"25% - 50%\", \n                     \"50% - 75%\",\n                     \"&gt; 75%\", \n                     \"upper outlier\"))  +\n  tm_borders() +\n  tm_layout(main.title = mtitle, \n            title.position = c(\"left\",\n                               \"top\"))\n}\n\n\ntmap_mode(\"plot\")\nboxmap(\"wp_nonfunctional\", NGA_wp)"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex02/In-class_Ex02.html",
    "href": "In-class_Ex/In-class_Ex02/In-class_Ex02.html",
    "title": "In-class Exercise 2",
    "section": "",
    "text": "pacman::p_load(tidyverse, ggdist, ggridges, colorspace, ggthemes)"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex02/In-class_Ex02.html#loading-r-packages",
    "href": "In-class_Ex/In-class_Ex02/In-class_Ex02.html#loading-r-packages",
    "title": "In-class Exercise 2",
    "section": "",
    "text": "pacman::p_load(tidyverse, ggdist, ggridges, colorspace, ggthemes)"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex02/In-class_Ex02.html#reading-data",
    "href": "In-class_Ex/In-class_Ex02/In-class_Ex02.html#reading-data",
    "title": "In-class Exercise 2",
    "section": "Reading data",
    "text": "Reading data\n\nexam_data &lt;- read_csv(\"data/Exam_data.csv\")"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex02/In-class_Ex02.html#visualizing-distribution",
    "href": "In-class_Ex/In-class_Ex02/In-class_Ex02.html#visualizing-distribution",
    "title": "In-class Exercise 2",
    "section": "Visualizing Distribution",
    "text": "Visualizing Distribution\n\nggplot(exam_data,\n       aes(x = ENGLISH)) +\n  geom_density(\n    color = \"#1696d2\",\n    adjust = 0.65,\n    alpha = 0.6\n  )"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex02/In-class_Ex02.html#alternative-design",
    "href": "In-class_Ex/In-class_Ex02/In-class_Ex02.html#alternative-design",
    "title": "In-class Exercise 2",
    "section": "Alternative Design",
    "text": "Alternative Design\n\nmedian_eng &lt;- median(exam_data$ENGLISH)\nmean_eng &lt;- mean(exam_data$ENGLISH)\nstd_eng &lt;- sd(exam_data$ENGLISH)\nggplot(exam_data,\n       aes(x = ENGLISH)) +\n  geom_density(\n    color = \"#1696d2\",\n    adjust = 0.65,\n    alpha = 0.6) +\n  stat_function(\n    fun = dnorm,\n    args= list(mean = mean_eng,\n               sd = std_eng),\n    col = \"grey30\",\n    size = 0.8) +\n  geom_vline(\n    aes(xintercept = mean_eng),\n    colour = \"#4d5887\",\n    linewidth = 0.6,\n    linetype = \"dashed\") +\n  annotate(geom = \"text\",\n           x = mean_eng - 8,\n           y = 0.04,\n           label = paste0(\"Mean ENGLISH: \",\n                          round((mean_eng), 2)),\n           color = \"#4d5887\") +\n  geom_vline(\n    aes(xintercept = median_eng),\n    colour = \"#4d4677\",\n    linewidth = 0.6,\n    linetype = \"dashed\") +\n  annotate(geom = \"text\",\n           x = mean_eng + 8,\n           y = 0.04,\n           label = paste0(\"Median ENGLISH: \",\n                          round((median_eng), 2)),\n           color = \"#4d4677\")"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex05/In-class_Ex05.html",
    "href": "In-class_Ex/In-class_Ex05/In-class_Ex05.html",
    "title": "In-class Exercise 5",
    "section": "",
    "text": "pacman::p_load(tidyverse, readtext, quanteda, tidytext)\n\n\ntext_data &lt;- readtext(\"data/articles/*\")\n\n\nusenet_words &lt;- text_data %&gt;%\n  unnest_tokens(word, text) %&gt;%\n  filter(str_detect(word, \"[a-z']$\"), !word %in% stop_words$word)\n\n\nusenet_words %&gt;%\n  count(word, sort= TRUE)\n\nreadtext object consisting of 3261 documents and 0 docvars.\n# A data frame: 3,261 × 3\n  word             n text     \n  &lt;chr&gt;        &lt;int&gt; &lt;chr&gt;    \n1 fishing       2177 \"\\\"\\\"...\"\n2 sustainable   1525 \"\\\"\\\"...\"\n3 company       1036 \"\\\"\\\"...\"\n4 practices      838 \"\\\"\\\"...\"\n5 industry       715 \"\\\"\\\"...\"\n6 transactions   696 \"\\\"\\\"...\"\n# ℹ 3,255 more rows\n\n\n\ntext_data_splitted &lt;- text_data %&gt;%\n  separate_wider_delim(\"doc_id\",\n                       delim = \"__0__\",\n                       names = c(\"X\", \"Y\"),\n                       too_few = \"align_end\")"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex06/In-class_Ex06.html",
    "href": "In-class_Ex/In-class_Ex06/In-class_Ex06.html",
    "title": "In-class Exercise 6",
    "section": "",
    "text": "pacman::p_load(tidyverse, readtext, corporaexplorer, quanteda, stringi,\n               rvest, tidytext)"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex06/In-class_Ex06.html#reading-data",
    "href": "In-class_Ex/In-class_Ex06/In-class_Ex06.html#reading-data",
    "title": "In-class Exercise 6",
    "section": "Reading data",
    "text": "Reading data\n\nbible &lt;- readr::read_lines(\"http://www.gutenberg.org/cache/epub/10/pg10.txt\")\n\n\n# Collapsing into one string.\nbible &lt;- paste(bible, collapse = \"\\n\")\n\n# Identifying the beginning and end of the Bible / stripping PJ metadata\n # (technique borrowed from https://quanteda.io/articles/pkgdown/replication/digital-humanities.html).\nstart_v &lt;- stri_locate_first_fixed(bible, \"The First Book of Moses: Called Genesis\")[1]\nend_v &lt;- stri_locate_last_fixed(bible, \"Amen.\")[2]\nbible &lt;- stri_sub(bible, start_v, end_v)\n\n# In the file, every book in the bible is preceded by five newlines,\n  # which we use to split our string into a vector where each element is a book.\nbooks &lt;- stri_split_regex(bible, \"\\n{5}\") %&gt;%\n    unlist %&gt;%\n    .[-40]  # Removing the heading \"The New Testament of the King James Bible\",\n              # which also was preceded by five newlines.\n\n# Because of the structure of the text in the file:\n  # Replacing double or more newlines with two newlines, and a single newline with space.\nbooks &lt;- str_replace_all(books, \"\\n{2,}\", \"NEW_PARAGRAPH\") %&gt;%\n    str_replace_all(\"\\n\", \" \") %&gt;%\n    str_replace_all(\"NEW_PARAGRAPH\", \"\\n\\n\")\nbooks &lt;- books[3:68]  # The two first elements are not books\n\n# Identifying new chapters within each book and split the text into chapters.\n# (The first characters in chapter 2 will e.g. be 2:1)\nchapters &lt;- str_replace_all(books, \"(\\\\d+:1 )\", \"NEW_CHAPTER\\\\1\") %&gt;%\n    stri_split_regex(\"NEW_CHAPTER\")\n\n# Removing the chapter headings from the text (we want them as metadata).\nchapters &lt;- lapply(chapters, function(x) x[-1])\n\n\n# We are not quite happy with the long book titles in the King James Bible,\n  # so we retrieve shorter versions from esv.org which will take up less\n  # space in the corpus map plot.\nbook_titles &lt;- read_html(\"https://www.esv.org/resources/esv-global-study-bible/list-of-abbreviations\") %&gt;%\n  html_nodes(\"td:nth-child(1)\") %&gt;%\n  html_text() %&gt;%\n  .[13:78]  # Removing irrelevant elements after manual inspection.\n\n# We add a column indicating whether a book belongs to the Old or New Testament,\n#   knowing that they contain respectively 39 and 27 books.\ntestament &lt;- c(rep(\"Old\", 39), rep(\"New\", 27))\n\n\n# Data frame with one book as one row.\nbible_df &lt;- tibble::tibble(Text = chapters,\n                           Book = book_titles,\n                           Testament = testament)\n\n# We want each chapter to be one row, but keep the metadata (book and which testament).\nbible_df &lt;- tidyr::unnest(bible_df, Text)\n\n\n# As this is a corpus which is not organised by date,\n  # we set `date_based_corpus` to `FALSE`.\n# Because we want to organise our exploration around the books in the Bible,\n  # we pass `\"Book\"` to the `grouping_variable` argument.\n# We specify which metadata columns we want to be displayed in the\n  # \"Document information\" tab, using the `columns_doc_info` argument.\nKJB &lt;- prepare_data(dataset = bible_df,\n                    date_based_corpus = FALSE,\n                    grouping_variable = \"Book\",\n                    columns_doc_info = c(\"Testament\", \"Book\"))\n\n\nexplore(KJB)\n\nShiny applications not supported in static R Markdown documents"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "ISSS608-VAA",
    "section": "",
    "text": "Welcome to my learning journey of ISSS608 Visual Analytics and Applications"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex02/Take-home_Ex02.html",
    "href": "Take-home_Ex/Take-home_Ex02/Take-home_Ex02.html",
    "title": "Take-home Exercise 2",
    "section": "",
    "text": "This exercise aims to provide critique and improvements to visualizations created by peer in Take-home Exercise 1 using R. This will be done based on clarity and aesthetics. The original design will then be remade using data visualization design principles and best practices using ggplot2, its extensions, and tidyverse packages.\nThe original dataset consisted of transaction data of REALIS. A complete set of the private residential property transaction data of Singapore from 1st January 2023 to 31st March 2024 was used."
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex02/Take-home_Ex02.html#overview",
    "href": "Take-home_Ex/Take-home_Ex02/Take-home_Ex02.html#overview",
    "title": "Take-home Exercise 2",
    "section": "",
    "text": "This exercise aims to provide critique and improvements to visualizations created by peer in Take-home Exercise 1 using R. This will be done based on clarity and aesthetics. The original design will then be remade using data visualization design principles and best practices using ggplot2, its extensions, and tidyverse packages.\nThe original dataset consisted of transaction data of REALIS. A complete set of the private residential property transaction data of Singapore from 1st January 2023 to 31st March 2024 was used."
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex02/Take-home_Ex02.html#data-visualization-critique",
    "href": "Take-home_Ex/Take-home_Ex02/Take-home_Ex02.html#data-visualization-critique",
    "title": "Take-home Exercise 2",
    "section": "2. Data Visualization Critique",
    "text": "2. Data Visualization Critique\n\n2.1 Data Preparation\n\npacman::p_load(ggrepel, patchwork, ggthemes, ggridges, hrbrthemes, colorspace,ggdist, tidyr, tidyverse, htmltools, viridis)\n\n\nrealis_data_2023Q1 &lt;- read_csv(\"data/ResidentialTransaction20240308160536.csv\")\nrealis_data_2023Q1 &lt;- mutate(realis_data_2023Q1, Quarter='2023-Q1')\nrealis_data_2023Q2 &lt;- read_csv(\"data/ResidentialTransaction20240308160736.csv\")\nrealis_data_2023Q2 &lt;- mutate(realis_data_2023Q2, Quarter='2023-Q2')\nrealis_data_2023Q3 &lt;- read_csv(\"data/ResidentialTransaction20240308161009.csv\")\nrealis_data_2023Q3 &lt;- mutate(realis_data_2023Q3, Quarter='2023-Q3')\nrealis_data_2023Q4 &lt;- read_csv(\"data/ResidentialTransaction20240308161109.csv\")\nrealis_data_2023Q4 &lt;- mutate(realis_data_2023Q4, Quarter='2023-Q4')\nrealis_data_2024Q1 &lt;- read_csv(\"data/ResidentialTransaction20240414220633.csv\")\nrealis_data_2024Q1 &lt;- mutate(realis_data_2024Q1, Quarter='2024-Q1')\ndf &lt;- rbind(realis_data_2023Q1, realis_data_2023Q2, realis_data_2023Q3, realis_data_2023Q4, realis_data_2024Q1)\n\ndf &lt;- df %&gt;%\n  mutate_if(is.character, as.factor)\n\n\ndf$`Sale Date` = as.Date(df$`Sale Date`, format = \"%d %b %Y\")\n\n\n\n2.2 Original Design\n\ndf %&gt;%\n  filter(`Number of Units` &gt; 1) %&gt;%\n  arrange(desc(`Number of Units`)) \n\n# A tibble: 12 × 22\n   `Project Name`      `Transacted Price ($)` `Area (SQFT)` `Unit Price ($ PSF)`\n   &lt;fct&gt;                                &lt;dbl&gt;         &lt;dbl&gt;                &lt;dbl&gt;\n 1 MEYER PARK                       392180000       144883.                 2707\n 2 BAGNALL COURT                    115280000        68491.                 1683\n 3 KEW LODGE                         66800000        25177                  2653\n 4 KARTAR APARTMENTS                 18000000         6964.                 2585\n 5 MONDO MANSION BUIL…                6280000         5490.                 1144\n 6 N.A.                              10600000         6747.                 1571\n 7 N.A.                              61080008        32149.                 1900\n 8 N.A.                              32200000        14123.                 2280\n 9 N.A.                               6150000         4342.                 1416\n10 EAST VIEW GARDEN                   6100000         8338.                  732\n11 N.A.                               8000000         3659.                 2187\n12 CLAYMORE PLAZA                     7000000         4209.                 1663\n# ℹ 18 more variables: `Sale Date` &lt;date&gt;, Address &lt;fct&gt;, `Type of Sale` &lt;fct&gt;,\n#   `Type of Area` &lt;fct&gt;, `Area (SQM)` &lt;dbl&gt;, `Unit Price ($ PSM)` &lt;dbl&gt;,\n#   `Nett Price($)` &lt;fct&gt;, `Property Type` &lt;fct&gt;, `Number of Units` &lt;dbl&gt;,\n#   Tenure &lt;fct&gt;, `Completion Date` &lt;fct&gt;, `Purchaser Address Indicator` &lt;fct&gt;,\n#   `Postal Code` &lt;fct&gt;, `Postal District` &lt;fct&gt;, `Postal Sector` &lt;fct&gt;,\n#   `Planning Region` &lt;fct&gt;, `Planning Area` &lt;fct&gt;, Quarter &lt;fct&gt;\n\ndf.c &lt;- df %&gt;%\n  filter(!grepl('ENBLOC', df$Address))\ndf.c &lt;- df.c %&gt;%\n  filter(`Number of Units` &lt;= 1)\ndf.c_median &lt;- df.c %&gt;%\n  select(`Transacted Price ($)`, `Type of Area`, `Property Type`) %&gt;%\n  group_by(`Property Type`, `Type of Area`) %&gt;%\n  summarise(`Median Transaction Price ($)` = median(`Transacted Price ($)`, .groups = 'drop'))\n  ggplot(df.c_median, aes(x = `Property Type`, \n             y = `Median Transaction Price ($)`, \n             color = `Type of Area`)) +  # Adding color aesthetic based on Type of Area\n  geom_point() +\n  theme_economist() +\n  theme(axis.text.x = element_text(size = 8, angle = 90, vjust = 0.5, hjust=1)) +\n  scale_y_continuous(labels = scales::comma) +\n  labs(color = \"Type of Area\")\n\n\n\n\n\n\n\n\nThe link for the peers work: https://va24-ry.netlify.app/take-home%20exercise/take-home_ex01/take-home_ex01#identifying-the-sub-markets\n\n\n2.3 Critique: Clarity and Aesthetics\n\n2.2.1 Clarity\n\nLack of a title makes it difficult to understand what the plot is about.\nDot plot is being used to represent discrete data. The differences between prices are a bit difficult to understand as dot plots are not a very good way to represent discrete data.\nAs a person who wants to understand more from the data, he will be interested in knowing the distribution of data along with the median prices as well. Just the median prices would be insufficient to derive a conclusion about the larger dataset without knowing the distribution of data.\nLack of subtitle makes it difficult for the person viewing the visualization to understand the message the analyst wants to convey through the visualization. In turn, it makes it difficult to understand the analyst’s intention behind construction of the visualization\nLack of caption makes it hard to know about the source of the data.\n\n\n\n2.2.2 Aesthetics\n\nThe colour of dots for Strata matches closely with the background theme. This makes it slightly difficult to separate out.\nThe x axis labels are at 90 degrees to the usual view. This makes it uncomfortable for the reader to read the x-axis labels.\nY-axis gridlines make it easy to read the numbers.\nThe Type of Area has been placed at the top of the graph(in turn replacing the title). This is slightly misleading for the reader.\nA lighter colour could have been chosen for the background. This would have made the visualization stand out more clearly."
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex02/Take-home_Ex02.html#makeover-design",
    "href": "Take-home_Ex/Take-home_Ex02/Take-home_Ex02.html#makeover-design",
    "title": "Take-home Exercise 2",
    "section": "3. Makeover Design",
    "text": "3. Makeover Design\nThe intention behind the makover is to give a more detailed version of distribution of private property prices(based on property types) with area. This makeover adds in the distribution as well. This is because just the median prices won’t give the reader a complete view of the property prices. Also to derive any conclusion from the visualization, it is necessary to know the distribution of data.\n\nThe plotThe code\n\n\n\n\n\n\n\n\n\n\n\n\n\n\ncustom_palette &lt;- c(\"orange\", \"steelblue\")\np &lt;- ggplot(df.c_median, aes(x = `Property Type`, \n             y = `Median Transaction Price ($)`, \n             fill = `Type of Area`)) +\n  geom_bar(stat = \"identity\", position = \"dodge\", alpha = 0.9) +\n  theme(axis.text.x = element_text(size = 9),\n        axis.text.y = element_text(size = 9),\n        axis.title.x = element_text(size = 12),\n        axis.title.y = element_text(size = 12),\n        plot.title = element_text(size = 25, face = \"bold\"),\n        plot.title = element_text(size = 18)) +\n scale_fill_manual(values = custom_palette) +\n  labs(color = \"Type of Area\", title = \"Sale Prices of Private Property types with Type of Area\",\n       subtitle = \"Higher prices for Properties on Land as compared to Strata\") + \n  scale_x_discrete(drop = FALSE)\n\ndf_terracehouse &lt;- df.c %&gt;% filter(`Property Type` == 'Terrace House')\np1 &lt;- ggplot(df_terracehouse, \n             aes(x= `Type of Area`, y = `Transacted Price ($)`, fill = `Type of Area`)) + stat_halfeye(aes(justification = ifelse(`Type of Area` == \"Land\", 1.2, 0),\n               side = ifelse(`Type of Area` == \"Land\", \"left\", \"right\")),\n               adjust = 8,\n               .width = 0,\n               point_colour = NA, alpha = 0.9) +\n  labs(x = \"Terrace Houses\",caption = \"Source: REALIS, URA\") + scale_fill_manual(values = custom_palette) +\n  ylim(0, 15000000) +\n  geom_boxplot(aes(x= `Type of Area`, y = `Transacted Price ($)`, fill = `Type of Area`),\n               outlier.shape = NA, \n               alpha = .5, \n               width = .2, \n               colour = \"black\") +\n  theme(\n    legend.direction = \"horizontal\",\n    legend.position=\"none\",\n    plot.title = element_text(size =12, face = \"bold\"),\n    plot.subtitle = element_text(size = rel(0.8)),\n    plot.caption = element_text(size = rel(0.8)),\n    axis.text.x = element_text(size = rel(0.9)),\n    axis.title.x = element_text(size = rel(0.9)),\n    axis.text.y = element_blank(),\n    axis.title.y = element_blank(),\n    plot.background=element_rect(fill=\"white\",colour=\"white\"))\n\ndf_semidetached &lt;- df.c %&gt;% filter(`Property Type` == 'Semi-Detached House')\n\np2 &lt;- ggplot(df_semidetached, \n             aes(x= `Type of Area`, y = `Transacted Price ($)`, fill = `Type of Area`)) + stat_halfeye(aes(justification = ifelse(`Type of Area` == \"Land\", 1.2, 0),\n               side = ifelse(`Type of Area` == \"Land\", \"left\", \"right\")),\n               adjust = 8,\n               .width = 0,\n               point_colour = NA, alpha = 0.9) +\n  labs(x = \"Semi-Detached Houses\") + scale_fill_manual(values = custom_palette) +\n  ylim(0, 15000000) + geom_boxplot(aes(x= `Type of Area`, y = `Transacted Price ($)`, fill = `Type of Area`),\n               outlier.shape = NA, \n               alpha = .5, \n               width = .2, \n               colour = \"black\") +\n  theme(\n    legend.direction = \"horizontal\",\n    legend.position=\"none\",\n    plot.title = element_text(size =12, face = \"bold\"),\n    plot.subtitle = element_text(size = rel(0.8)),\n    plot.caption = element_text(size = rel(0.8)),\n    axis.text.x = element_text(size = rel(0.9)),\n    axis.title.x = element_text(size = rel(0.9)),\n    axis.title.y = element_blank(),\n    axis.text.y = element_blank(),\n    plot.background=element_rect(fill=\"white\",colour=\"white\"))\n  \ndf_execcondo &lt;- df.c %&gt;% filter(`Property Type` == 'Executive Condominium')\n\np3 &lt;- ggplot(df_execcondo, \n             aes(x= `Type of Area`, y = `Transacted Price ($)`,fill = `Type of Area`)) + stat_halfeye(aes(justification = ifelse(`Type of Area` == \"Land\", 1.2, 0),\n               side = ifelse(`Type of Area` == \"Land\", \"left\", \"right\")),\n               adjust = 8,\n               .width = 0,\n               point_colour = NA, alpha = 0.9) +\n  labs(x = \"Executive Condominium\") + scale_fill_manual(values = \"steelblue\") +\n  ylim(0, 15000000) + geom_boxplot(aes(x= `Type of Area`, y = `Transacted Price ($)`, fill = `Type of Area`),\n               outlier.shape = NA, \n               alpha = .5, \n               width = .2, \n               colour = \"black\") +\n  scale_x_discrete(drop = FALSE) +\n  theme(\n    legend.direction = \"horizontal\",\n    legend.position=\"none\",\n    plot.title = element_text(size =12, face = \"bold\"),\n    plot.subtitle = element_text(size = rel(0.8)),\n    plot.caption = element_text(size = rel(0.8)),\n    axis.text.x = element_text(size = rel(0.9)),\n    axis.title.x = element_text(size = rel(0.9)),\n    axis.title.y = element_blank(),\n    axis.text.y = element_blank(),\n    plot.background=element_rect(fill=\"white\",colour=\"white\"))\n  \n  \ndf_detachedhouse &lt;- df.c %&gt;% filter(`Property Type` == 'Detached House')\n\np4 &lt;- ggplot(df_detachedhouse, \n             aes(x= `Type of Area`, y = `Transacted Price ($)`, fill = `Type of Area`)) + stat_halfeye(aes(justification = ifelse(`Type of Area` == \"Land\", 1.2, 0),\n               side = ifelse(`Type of Area` == \"Land\", \"left\", \"right\")),\n               adjust = 8,\n               .width = 0,\n               point_colour = NA, alpha = 0.9) +\n  labs(x = \"Detached house\") + scale_fill_manual(values = custom_palette) +\n  ylim(0, 15000000) + geom_boxplot(aes(x= `Type of Area`, y = `Transacted Price ($)`, fill = `Type of Area`),\n               outlier.shape = NA, \n               alpha = .5, \n               width = .2, \n               colour = \"black\") +\n  theme(\n    legend.direction = \"horizontal\",\n    legend.position=\"none\",\n    plot.title = element_text(size =12, face = \"bold\"),\n    plot.subtitle = element_text(size = rel(0.8)),\n    plot.caption = element_text(size = rel(0.8)),\n    axis.text.x = element_text(size = rel(0.9)),\n    axis.title.x = element_text(size = rel(0.9)),\n    axis.title.y = element_blank(),\n    axis.text.y = element_blank(),\n    plot.background=element_rect(fill=\"white\",colour=\"white\"))\n\ndf_condo &lt;- df.c %&gt;% filter(`Property Type` == 'Condominium')\n\np5 &lt;- ggplot(df_condo, \n             aes(x= `Type of Area`, y = `Transacted Price ($)`, fill = `Type of Area`)) + stat_halfeye(aes(justification = ifelse(`Type of Area` == \"Land\", 1.2, 0),\n               side = ifelse(`Type of Area` == \"Land\", \"left\", \"right\")),\n               adjust = 8,\n               .width = 0,\n               point_colour = NA, alpha = 0.9) +\n  labs(x = \"Condominium\") + scale_fill_manual(values = \"steelblue\") +\n  ylim(0, 15000000) + geom_boxplot(aes(x= `Type of Area`, y = `Transacted Price ($)`, fill = `Type of Area`),\n               outlier.shape = NA, \n               alpha = .5, \n               width = .2, \n               colour = \"black\") + \n  scale_x_discrete(drop = FALSE) +\n  theme(\n    legend.direction = \"horizontal\",\n    legend.position=\"none\",\n    plot.title = element_text(size =12, face = \"bold\"),\n    plot.subtitle = element_text(size = rel(0.8)),\n    plot.caption = element_text(size = rel(0.8)),\n    axis.text.x = element_text(size = rel(0.9)),\n    axis.title.x = element_text(size = rel(0.9)),\n    axis.title.y = element_blank(),\n    axis.text.y = element_blank(),\n    plot.background=element_rect(fill=\"white\",colour=\"white\"))\n\ndf_apartment &lt;- df.c %&gt;% filter(`Property Type` == 'Apartment')\n\np6 &lt;- ggplot(df_apartment, \n             aes(x= `Type of Area`, y = `Transacted Price ($)`, fill = `Type of Area`)) + stat_halfeye(aes(justification = ifelse(`Type of Area` == \"Land\", 1.2, 0),\n               side = ifelse(`Type of Area` == \"Land\", \"left\", \"right\")),\n               adjust = 8,\n               .width = 0,\n               point_colour = NA, alpha = 0.9) +\n  labs(x = \"Apartment\") + scale_fill_manual(values = custom_palette) +\n  ylim(0, 15000000) + geom_boxplot(aes(x= `Type of Area`, y = `Transacted Price ($)`, fill = `Type of Area`),\n               outlier.shape = NA, \n               alpha = .5, \n               width = .2, \n               colour = \"black\") +\n  theme(\n    legend.direction = \"horizontal\",\n    legend.position=\"none\",\n    plot.title = element_text(size =12, face = \"bold\"),\n    plot.subtitle = element_text(size = rel(0.8)),\n    plot.caption = element_text(size = rel(0.8)),\n    axis.text.x = element_text(size = rel(0.9)),\n    axis.title.x = element_text(size = rel(0.9)),\n    axis.title.y = element_text(size = rel(1.2)),\n    axis.text.y = element_text(size = rel(0.9)),\n    \n    plot.background=element_rect(fill=\"white\",colour=\"white\"))\n\np7 &lt;- p / (p6 |  p5 | p4 | p3 | p2 | p1)\np7\n\n\n\n\n\n\n\n\n\n\nObservations from the Makeover Visualization\n\n\n\n\nIn general, the prices of properties on Land are higher than those on Strata for the same property type.\nThe differences between median sale prices of Terrace houses and Semi-detached houses is slightly lower than Apartments and Detached houses.\nThe detached houses and semi-detached houses have a higher variation in sale prices for Land Properties as compared to the Apartments and Terrace houses.\nThe median sale prices for Condos and Executive Condos are lower than the others."
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex02/Take-home_Ex02.html#learning-points",
    "href": "Take-home_Ex/Take-home_Ex02/Take-home_Ex02.html#learning-points",
    "title": "Take-home Exercise 2",
    "section": "4. Learning Points",
    "text": "4. Learning Points\nThis take-home exercise adds a dimension of critique and makeover of peer works which helps to embed best practices in data visualization. The key takeaways are:\n\nIt is very important to pay attention to detail while critiquing a visualization. Aspects like the title, subtitle, captions, axes labels, legends, colour schemes play a very important role in getting an understanding of the visualiziation.\nTrying to understand the intention of the analyst behind constructing the visualization is of prime importance. As a reader, if the intention behind plotting the visualization is not understood then the reading and understanding of the visualization is incomplete."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex09/Hands-on_Ex09_partb.html",
    "href": "Hands-on_Ex/Hands-on_Ex09/Hands-on_Ex09_partb.html",
    "title": "Hands-on Exercise 9: Visual Correlation Analysis",
    "section": "",
    "text": "Correlation coefficient is a popular statistic that use to measure the type and strength of the relationship between two variables. The values of a correlation coefficient ranges between -1.0 and 1.0. A correlation coefficient of 1 shows a perfect linear relationship between the two variables, while a -1.0 shows a perfect inverse relationship between the two variables. A correlation coefficient of 0.0 shows no linear relationship between the two variables.\nWhen multivariate data are used, the correlation coefficeints of the pair comparisons are displayed in a table form known as correlation matrix or scatterplot matrix.\nThere are three broad reasons for computing a correlation matrix.\n\nTo reveal the relationship between high-dimensional variables pair-wisely.\nTo input into other analyses. For example, people commonly use correlation matrices as inputs for exploratory factor analysis, confirmatory factor analysis, structural equation models, and linear regression when excluding missing values pairwise.\nAs a diagnostic when checking other analyses. For example, with linear regression a high amount of correlations suggests that the linear regression’s estimates will be unreliable.\n\nWhen the data is large, both in terms of the number of observations and the number of variables, Corrgram tend to be used to visually explore and analyse the structure and the patterns of relations among variables. It is designed based on two main schemes:\n\nRendering the value of a correlation to depict its sign and magnitude, and\nReordering the variables in a correlation matrix so that “similar” variables are positioned adjacently, facilitating perception.\n\nIn this hands-on exercise, you will learn how to plot data visualisation for visualising correlation matrix with R. It consists of three main sections. First, you will learn how to create correlation matrix using pairs() of R Graphics. Next, you will learn how to plot corrgram using corrplot package of R. Lastly, you will learn how to create an interactive correlation matrix using plotly R."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex09/Hands-on_Ex09_partb.html#overview",
    "href": "Hands-on_Ex/Hands-on_Ex09/Hands-on_Ex09_partb.html#overview",
    "title": "Hands-on Exercise 9: Visual Correlation Analysis",
    "section": "",
    "text": "Correlation coefficient is a popular statistic that use to measure the type and strength of the relationship between two variables. The values of a correlation coefficient ranges between -1.0 and 1.0. A correlation coefficient of 1 shows a perfect linear relationship between the two variables, while a -1.0 shows a perfect inverse relationship between the two variables. A correlation coefficient of 0.0 shows no linear relationship between the two variables.\nWhen multivariate data are used, the correlation coefficeints of the pair comparisons are displayed in a table form known as correlation matrix or scatterplot matrix.\nThere are three broad reasons for computing a correlation matrix.\n\nTo reveal the relationship between high-dimensional variables pair-wisely.\nTo input into other analyses. For example, people commonly use correlation matrices as inputs for exploratory factor analysis, confirmatory factor analysis, structural equation models, and linear regression when excluding missing values pairwise.\nAs a diagnostic when checking other analyses. For example, with linear regression a high amount of correlations suggests that the linear regression’s estimates will be unreliable.\n\nWhen the data is large, both in terms of the number of observations and the number of variables, Corrgram tend to be used to visually explore and analyse the structure and the patterns of relations among variables. It is designed based on two main schemes:\n\nRendering the value of a correlation to depict its sign and magnitude, and\nReordering the variables in a correlation matrix so that “similar” variables are positioned adjacently, facilitating perception.\n\nIn this hands-on exercise, you will learn how to plot data visualisation for visualising correlation matrix with R. It consists of three main sections. First, you will learn how to create correlation matrix using pairs() of R Graphics. Next, you will learn how to plot corrgram using corrplot package of R. Lastly, you will learn how to create an interactive correlation matrix using plotly R."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex09/Hands-on_Ex09_partb.html#installing-and-launching-r-packages",
    "href": "Hands-on_Ex/Hands-on_Ex09/Hands-on_Ex09_partb.html#installing-and-launching-r-packages",
    "title": "Hands-on Exercise 9: Visual Correlation Analysis",
    "section": "6.2 Installing and Launching R Packages",
    "text": "6.2 Installing and Launching R Packages\nBefore you get started, you are required to open a new Quarto document. Keep the default html authoring format.\nNext, you will use the code chunk below to install and launch corrplot, ggpubr, plotly and tidyverse in RStudio.\n\npacman::p_load(corrplot, ggstatsplot, tidyverse)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex09/Hands-on_Ex09_partb.html#importing-and-preparing-the-data-set",
    "href": "Hands-on_Ex/Hands-on_Ex09/Hands-on_Ex09_partb.html#importing-and-preparing-the-data-set",
    "title": "Hands-on Exercise 9: Visual Correlation Analysis",
    "section": "6.3 Importing and Preparing The Data Set",
    "text": "6.3 Importing and Preparing The Data Set\nIn this hands-on exercise, the Wine Quality Data Set of UCI Machine Learning Repository will be used. The data set consists of 13 variables and 6497 observations. For the purpose of this exercise, we have combined the red wine and white wine data into one data file. It is called wine_quality and is in csv file format.\n\n6.3.1 Importing Data\nFirst, let us import the data into R by using read_csv() of readr package.\n\nwine &lt;- read_csv(\"data/wine_quality.csv\")\n\nNotice that beside quality and type, the rest of the variables are numerical and continuous data type."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex09/Hands-on_Ex09_partb.html#building-correlation-matrix-pairs-method",
    "href": "Hands-on_Ex/Hands-on_Ex09/Hands-on_Ex09_partb.html#building-correlation-matrix-pairs-method",
    "title": "Hands-on Exercise 9: Visual Correlation Analysis",
    "section": "6.4 Building Correlation Matrix: pairs() method",
    "text": "6.4 Building Correlation Matrix: pairs() method\nThere are more than one way to build scatterplot matrix with R. In this section, you will learn how to create a scatterplot matrix by using the pairs function of R Graphics.\nBefore you continue to the next step, you should read the syntax description of pairsfunction.\n\n6.4.1 Building a basic correlation matrix\nFigure below shows the scatter plot matrix of Wine Quality Data. It is a 11 by 11 matrix.\n\npairs(wine[,1:11])\n\n\n\n\n\n\n\n\nThe required input of pairs() can be a matrix or data frame. The code chunk used to create the scatterplot matrix is relatively simple. It uses the default pairs function. Columns 2 to 12 of wine dataframe is used to build the scatterplot matrix. The variables are: fixed acidity, volatile acidity, citric acid, residual sugar, chlorides, free sulfur dioxide, total sulfur dioxide, density, pH, sulphates and alcohol.\n\npairs(wine[,2:12])\n\n\n\n\n\n\n\n\n\n\n6.4.2 Drawing the lower corner\npairs function of R Graphics provided many customisation arguments. For example, it is a common practice to show either the upper half or lower half of the correlation matrix instead of both. This is because a correlation matrix is symmetric.\nTo show the lower half of the correlation matrix, the upper.panel argument will be used as shown in the code chunk below.\n\npairs(wine[,2:12], upper.panel = NULL)\n\n\n\n\n\n\n\n\nSimilarly, you can display the upper half of the correlation matrix by using the code chunk below.\n\npairs(wine[,2:12], lower.panel = NULL)\n\n\n\n\n\n\n\n\n\n\n6.4.3 Including with correlation coefficients\nTo show the correlation coefficient of each pair of variables instead of a scatter plot, panel.cor function will be used. This will also show higher correlations in a larger font.\n\npanel.cor &lt;- function(x, y, digits=2, prefix=\"\", cex.cor, ...) {\nusr &lt;- par(\"usr\")\non.exit(par(usr))\npar(usr = c(0, 1, 0, 1))\nr &lt;- abs(cor(x, y, use=\"complete.obs\"))\ntxt &lt;- format(c(r, 0.123456789), digits=digits)[1]\ntxt &lt;- paste(prefix, txt, sep=\"\")\nif(missing(cex.cor)) cex.cor &lt;- 0.8/strwidth(txt)\ntext(0.5, 0.5, txt, cex = cex.cor * (1 + r) / 2)\n}\n\npairs(wine[,2:12], \n      upper.panel = panel.cor)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex09/Hands-on_Ex09_partb.html#visualising-correlation-matrix-ggcormat",
    "href": "Hands-on_Ex/Hands-on_Ex09/Hands-on_Ex09_partb.html#visualising-correlation-matrix-ggcormat",
    "title": "Hands-on Exercise 9: Visual Correlation Analysis",
    "section": "6.5 Visualising Correlation Matrix: ggcormat()",
    "text": "6.5 Visualising Correlation Matrix: ggcormat()\nOne of the major limitation of the correlation matrix is that the scatter plots appear very cluttered when the number of observations is relatively large (i.e. more than 500 observations). To over come this problem, Corrgram data visualisation technique suggested by D. J. Murdoch and E. D. Chow (1996) and Friendly, M (2002) and will be used.\nThe are at least three R packages provide function to plot corrgram, they are:\n\ncorrgram\nellipse\ncorrplot\n\nOn top that, some R package like ggstatsplot package also provides functions for building corrgram.\nIn this section, you will learn how to visualising correlation matrix by using ggcorrmat() of ggstatsplot package.\n\n6.5.1 The basic plot\nOn of the advantage of using ggcorrmat() over many other methods to visualise a correlation matrix is it’s ability to provide a comprehensive and yet professional statistical report as shown in the figure below.\n\nggstatsplot::ggcorrmat(\n  data = wine, \n  cor.vars = 1:11)\n\n\n\n\n\n\n\n\n\nggstatsplot::ggcorrmat(\n  data = wine, \n  cor.vars = 1:11,\n  ggcorrplot.args = list(outline.color = \"black\", \n                         hc.order = TRUE,\n                         tl.cex = 10),\n  title    = \"Correlogram for wine dataset\",\n  subtitle = \"Four pairs are no significant at p &lt; 0.05\"\n)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex09/Hands-on_Ex09_parta.html",
    "href": "Hands-on_Ex/Hands-on_Ex09/Hands-on_Ex09_parta.html",
    "title": "Hands-on Exercise 9: Ternary Plots",
    "section": "",
    "text": "Ternary plots are a way of displaying the distribution and variability of three-part compositional data. (For example, the proportion of aged, economy active and young population or sand, silt, and clay in soil.) It’s display is a triangle with sides scaled from 0 to 1. Each side represents one of the three components. A point is plotted so that a line drawn perpendicular from the point to each leg of the triangle intersect at the component values of the point.\nIn this hands-on, you will learn how to build ternary plot programmatically using R for visualising and analysing population structure of Singapore."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex09/Hands-on_Ex09_parta.html#overview",
    "href": "Hands-on_Ex/Hands-on_Ex09/Hands-on_Ex09_parta.html#overview",
    "title": "Hands-on Exercise 9: Ternary Plots",
    "section": "",
    "text": "Ternary plots are a way of displaying the distribution and variability of three-part compositional data. (For example, the proportion of aged, economy active and young population or sand, silt, and clay in soil.) It’s display is a triangle with sides scaled from 0 to 1. Each side represents one of the three components. A point is plotted so that a line drawn perpendicular from the point to each leg of the triangle intersect at the component values of the point.\nIn this hands-on, you will learn how to build ternary plot programmatically using R for visualising and analysing population structure of Singapore."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex09/Hands-on_Ex09_parta.html#installing-and-launching-r-packages",
    "href": "Hands-on_Ex/Hands-on_Ex09/Hands-on_Ex09_parta.html#installing-and-launching-r-packages",
    "title": "Hands-on Exercise 9: Ternary Plots",
    "section": "13.2 Installing and launching R packages",
    "text": "13.2 Installing and launching R packages\nFor this exercise, two main R packages will be used in this hands-on exercise, they are:\n\nggtern, a ggplot extension specially designed to plot ternary diagrams. The package will be used to plot static ternary plots.\nPlotly R, an R package for creating interactive web-based graphs via plotly’s JavaScript graphing library, plotly.js . The plotly R libary contains the ggplotly function, which will convert ggplot2 figures into a Plotly object.\n\n\npacman::p_load(plotly, ggtern, tidyverse)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex09/Hands-on_Ex09_parta.html#data-preparation",
    "href": "Hands-on_Ex/Hands-on_Ex09/Hands-on_Ex09_parta.html#data-preparation",
    "title": "Hands-on Exercise 9: Ternary Plots",
    "section": "13.3 Data Preparation",
    "text": "13.3 Data Preparation\n\n13.3.1 The data\nFor the purpose of this hands-on exercise, the Singapore Residents by Planning AreaSubzone, Age Group, Sex and Type of Dwelling, June 2000-2018 data will be used. The data set has been downloaded and included in the data sub-folder of the hands-on exercise folder. It is called respopagsex2000to2018_tidy.csv and is in csv file format.\n\n\n13.3.2 Importing Data\nTo important respopagsex2000to2018_tidy.csv into R, read_csv() function of readr package will be used.\n\n#Reading the data into R environment\npop_data &lt;- read_csv(\"data/respopagsex2000to2018_tidy.csv\") \n\n\n\n13.3.3 Preparing the Data\nNext, use the mutate() function of dplyr package to derive three new measures, namely: young, active, and old.\n\n#Deriving the young, economy active and old measures\nagpop_mutated &lt;- pop_data %&gt;%\n  mutate(`Year` = as.character(Year))%&gt;%\n  spread(AG, Population) %&gt;%\n  mutate(YOUNG = rowSums(.[4:8]))%&gt;%\n  mutate(ACTIVE = rowSums(.[9:16]))  %&gt;%\n  mutate(OLD = rowSums(.[17:21])) %&gt;%\n  mutate(TOTAL = rowSums(.[22:24])) %&gt;%\n  filter(Year == 2018)%&gt;%\n  filter(TOTAL &gt; 0)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex09/Hands-on_Ex09_parta.html#plotting-ternary-diagram-with-r",
    "href": "Hands-on_Ex/Hands-on_Ex09/Hands-on_Ex09_parta.html#plotting-ternary-diagram-with-r",
    "title": "Hands-on Exercise 9: Ternary Plots",
    "section": "13.4 Plotting Ternary Diagram with R",
    "text": "13.4 Plotting Ternary Diagram with R\n\n13.4.1 4.1 Plotting a static ternary diagram\nUse ggtern() function of ggtern package to create a simple ternary plot.\n\n#Building the static ternary plot\nggtern(data=agpop_mutated,aes(x=YOUNG, y=ACTIVE, z=OLD)) +\n  geom_point()\n\n\n\n\n\n\n\n\n\n#Building the static ternary plot\nggtern(data=agpop_mutated, aes(x=YOUNG,y=ACTIVE, z=OLD)) +\n  geom_point() +\n  labs(title=\"Population structure, 2015\") +\n  theme_rgbw()\n\n\n\n\n\n\n\n\n\n\n13.4.2 Plotting an interactive ternary diagram\nThe code below create an interactive ternary plot using plot_ly() function of Plotly R.\n\n# reusable function for creating annotation object\nlabel &lt;- function(txt) {\n  list(\n    text = txt, \n    x = 0.1, y = 1,\n    ax = 0, ay = 0,\n    xref = \"paper\", yref = \"paper\", \n    align = \"center\",\n    font = list(family = \"serif\", size = 15, color = \"white\"),\n    bgcolor = \"#b3b3b3\", bordercolor = \"black\", borderwidth = 2\n  )\n}\n\n# reusable function for axis formatting\naxis &lt;- function(txt) {\n  list(\n    title = txt, tickformat = \".0%\", tickfont = list(size = 10)\n  )\n}\n\nternaryAxes &lt;- list(\n  aaxis = axis(\"Young\"), \n  baxis = axis(\"Active\"), \n  caxis = axis(\"Old\")\n)\n\n# Initiating a plotly visualization \nplot_ly(\n  agpop_mutated, \n  a = ~YOUNG, \n  b = ~ACTIVE, \n  c = ~OLD, \n  color = I(\"black\"), \n  type = \"scatterternary\",\n  mode = \"lines+markers\"\n) %&gt;%\n  layout(\n    annotations = label(\"Ternary Markers\"), \n    ternary = ternaryAxes\n  )"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex09/Hands-on_Ex09_partc.html",
    "href": "Hands-on_Ex/Hands-on_Ex09/Hands-on_Ex09_partc.html",
    "title": "Hands-on Exercise 9: Heatmaps",
    "section": "",
    "text": "Heatmaps visualise data through variations in colouring. When applied to a tabular format, heatmaps are useful for cross-examining multivariate data, through placing variables in the columns and observation (or records) in rowa and colouring the cells within the table. Heatmaps are good for showing variance across multiple variables, revealing any patterns, displaying whether any variables are similar to each other, and for detecting if any correlations exist in-between them.\nIn this hands-on exercise, you will gain hands-on experience on using R to plot static and interactive heatmap for visualising and analysing multivariate data."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex09/Hands-on_Ex09_partc.html#overview",
    "href": "Hands-on_Ex/Hands-on_Ex09/Hands-on_Ex09_partc.html#overview",
    "title": "Hands-on Exercise 9: Heatmaps",
    "section": "",
    "text": "Heatmaps visualise data through variations in colouring. When applied to a tabular format, heatmaps are useful for cross-examining multivariate data, through placing variables in the columns and observation (or records) in rowa and colouring the cells within the table. Heatmaps are good for showing variance across multiple variables, revealing any patterns, displaying whether any variables are similar to each other, and for detecting if any correlations exist in-between them.\nIn this hands-on exercise, you will gain hands-on experience on using R to plot static and interactive heatmap for visualising and analysing multivariate data."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex09/Hands-on_Ex09_partc.html#installing-and-launching-r-packages",
    "href": "Hands-on_Ex/Hands-on_Ex09/Hands-on_Ex09_partc.html#installing-and-launching-r-packages",
    "title": "Hands-on Exercise 9: Heatmaps",
    "section": "9.2 Installing and Launching R Packages",
    "text": "9.2 Installing and Launching R Packages\nNext, you will use the code chunk below to install and launch seriation, heatmaply, dendextend and tidyverse in RStudio.\n\npacman::p_load(seriation, dendextend, heatmaply, tidyverse)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex09/Hands-on_Ex09_partc.html#importing-and-preparing-the-data-set",
    "href": "Hands-on_Ex/Hands-on_Ex09/Hands-on_Ex09_partc.html#importing-and-preparing-the-data-set",
    "title": "Hands-on Exercise 9: Heatmaps",
    "section": "9.3 Importing and Preparing The Data Set",
    "text": "9.3 Importing and Preparing The Data Set\nIn this hands-on exercise, the data of World Happines 2018 report will be used. The data set is downloaded from here. The original data set is in Microsoft Excel format. It has been extracted and saved in csv file called WHData-2018.csv.\n\n9.3.1 Importing the data set\nIn the code chunk below, read_csv() of readr is used to import WHData-2018.csv into R and parsed it into tibble R data frame format.\n\nwh &lt;- read_csv(\"data/WHData-2018.csv\")\n\nThe output tibbled data frame is called wh.\n\n\n9.3.2 Preparing the data\nNext, we need to change the rows by country name instead of row number by using the code chunk below\n\nrow.names(wh) &lt;- wh$Country\n\nNotice that the row number has been replaced into the country name.\n\n\n9.3.3 Transforming the data frame into a matrix\nThe data was loaded into a data frame, but it has to be a data matrix to make your heatmap.\nThe code chunk below will be used to transform wh data frame into a data matrix.\n\nwh1 &lt;- dplyr::select(wh, c(3, 7:12))\nwh_matrix &lt;- data.matrix(wh)\n\nNotice that wh_matrix is in R matrix format."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex09/Hands-on_Ex09_partc.html#static-heatmap",
    "href": "Hands-on_Ex/Hands-on_Ex09/Hands-on_Ex09_partc.html#static-heatmap",
    "title": "Hands-on Exercise 9: Heatmaps",
    "section": "9.4 Static Heatmap",
    "text": "9.4 Static Heatmap\nThere are many R packages and functions can be used to drawing static heatmaps, they are:\n\nheatmap()of R stats package. It draws a simple heatmap.\nheatmap.2() of gplots R package. It draws an enhanced heatmap compared to the R base function.\npheatmap() of pheatmap R package. pheatmap package also known as Pretty Heatmap. The package provides functions to draws pretty heatmaps and provides more control to change the appearance of heatmaps.\nComplexHeatmap package of R/Bioconductor package. The package draws, annotates and arranges complex heatmaps (very useful for genomic data analysis). The full reference guide of the package is available here.\nsuperheat package: A Graphical Tool for Exploring Complex Datasets Using Heatmaps. A system for generating extendable and customizable heatmaps for exploring complex datasets, including big data and data with multiple data types. The full reference guide of the package is available here.\n\nIn this section, you will learn how to plot static heatmaps by using heatmap() of R Stats package.\n\n9.4.1 heatmap() of R Stats\nIn this sub-section, we will plot a heatmap by using heatmap() of Base Stats. The code chunk is given below.\n\nwh_heatmap &lt;- heatmap(wh_matrix,\n                      Rowv=NA, Colv=NA)\n\n\n\n\n\n\n\n\nNote:\n\nBy default, heatmap() plots a cluster heatmap. The arguments Rowv=NA and Colv=NA are used to switch off the option of plotting the row and column dendrograms.\n\nTo plot a cluster heatmap, we just have to use the default as shown in the code chunk below.\n\nwh_heatmap &lt;- heatmap(wh_matrix)\n\n\n\n\n\n\n\n\nNote:\n\nThe order of both rows and columns is different compare to the native wh_matrix. This is because heatmap do a reordering using clusterisation: it calculates the distance between each pair of rows and columns and try to order them by similarity. Moreover, the corresponding dendrogram are provided beside the heatmap.\n\nHere, red cells denotes small values, and red small ones. This heatmap is not really informative. Indeed, the Happiness Score variable have relatively higher values, what makes that the other variables with small values all look the same. Thus, we need to normalize this matrix. This is done using the scale argument. It can be applied to rows or to columns following your needs.\nThe code chunk below normalises the matrix column-wise.\n\nwh_heatmap &lt;- heatmap(wh_matrix,\n                      scale=\"column\",\n                      cexRow = 0.6, \n                      cexCol = 0.8,\n                      margins = c(10, 4))\n\n\n\n\n\n\n\n\nNotice that the values are scaled now. Also note that margins argument is used to ensure that the entire x-axis labels are displayed completely and, cexRow and cexCol arguments are used to define the font size used for y-axis and x-axis labels respectively."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex09/Hands-on_Ex09_partc.html#creating-interactive-heatmap",
    "href": "Hands-on_Ex/Hands-on_Ex09/Hands-on_Ex09_partc.html#creating-interactive-heatmap",
    "title": "Hands-on Exercise 9: Heatmaps",
    "section": "9.5 Creating Interactive Heatmap",
    "text": "9.5 Creating Interactive Heatmap\nheatmaply is an R package for building interactive cluster heatmap that can be shared online as a stand-alone HTML file. It is designed and maintained by Tal Galili.\nBefore we get started, you should review the Introduction to Heatmaply to have an overall understanding of the features and functions of Heatmaply package. You are also required to have the user manualof the package handy with you for reference purposes.\nIn this section, you will gain hands-on experience on using heatmaply to design an interactive cluster heatmap. We will still use the wh_matrix as the input data.\n\nheatmaply(mtcars)\n\n\n\n\n\nThe code chunk below shows the basic syntax needed to create n interactive heatmap by using heatmaply package.\n\nheatmaply(wh_matrix[, -c(1, 2, 4, 5)])\n\n\n\n\n\nNote that:\n\nDifferent from heatmap(), for heatmaply() the default horizontal dendrogram is placed on the left hand side of the heatmap.\nThe text label of each raw, on the other hand, is placed on the right hand side of the heat map.\nWhen the x-axis marker labels are too long, they will be rotated by 135 degree from the north.\n\n\n9.5.2 Data trasformation\nWhen analysing multivariate data set, it is very common that the variables in the data sets includes values that reflect different types of measurement. In general, these variables’ values have their own range. In order to ensure that all the variables have comparable values, data transformation are commonly used before clustering.\nThree main data transformation methods are supported by heatmaply(), namely: scale, normalise and percentilse.\n\n9.5.2.1 Scaling method\n\nWhen all variables are came from or assumed to come from some normal distribution, then scaling (i.e.: subtract the mean and divide by the standard deviation) would bring them all close to the standard normal distribution.\nIn such a case, each value would reflect the distance from the mean in units of standard deviation.\nThe scale argument in heatmaply() supports column and row scaling.\n\nThe code chunk below is used to scale variable values columewise.\n\nheatmaply(wh_matrix[, -c(1, 2, 4, 5)],\n          scale = \"column\")\n\n\n\n\n\n\n\n9.5.2.2 Normalising method\n\nWhen variables in the data comes from possibly different (and non-normal) distributions, the normalize function can be used to bring data to the 0 to 1 scale by subtracting the minimum and dividing by the maximum of all observations.\nThis preserves the shape of each variable’s distribution while making them easily comparable on the same “scale”.\n\nDifferent from Scaling, the normalise method is performed on the input data set i.e. wh_matrix as shown in the code chunk below.\n\nheatmaply(normalize(wh_matrix[, -c(1, 2, 4, 5)]))\n\n\n\n\n\n\n\n9.5.2.3 Percentising method\n\nThis is similar to ranking the variables, but instead of keeping the rank values, divide them by the maximal rank.\nThis is done by using the ecdf of the variables on their own values, bringing each value to its empirical percentile.\nThe benefit of the percentize function is that each value has a relatively clear interpretation, it is the percent of observations that got that value or below it.\n\nSimilar to Normalize method, the Percentize method is also performed on the input data set i.e. wh_matrix as shown in the code chunk below.\n\nheatmaply(percentize(wh_matrix[, -c(1, 2, 4, 5)]))\n\n\n\n\n\n\n\n\n9.5.3 Clustering algorithm\nheatmaply supports a variety of hierarchical clustering algorithm. The main arguments provided are:\n\ndistfun: function used to compute the distance (dissimilarity) between both rows and columns. Defaults to dist. The options “pearson”, “spearman” and “kendall” can be used to use correlation-based clustering, which uses as.dist(1 - cor(t(x))) as the distance metric (using the specified correlation method).\nhclustfun: function used to compute the hierarchical clustering when Rowv or Colv are not dendrograms. Defaults to hclust.\ndist_method default is NULL, which results in “euclidean” to be used. It can accept alternative character strings indicating the method to be passed to distfun. By default distfun is “dist”” hence this can be one of “euclidean”, “maximum”, “manhattan”, “canberra”, “binary” or “minkowski”.\nhclust_method default is NULL, which results in “complete” method to be used. It can accept alternative character strings indicating the method to be passed to hclustfun. By default hclustfun is hclust hence this can be one of “ward.D”, “ward.D2”, “single”, “complete”, “average” (= UPGMA), “mcquitty” (= WPGMA), “median” (= WPGMC) or “centroid” (= UPGMC).\n\nIn general, a clustering model can be calibrated either manually or statistically.\n\n\n9.5.4 Manual approach\nIn the code chunk below, the heatmap is plotted by using hierachical clustering algorithm with “Euclidean distance” and “ward.D” method.\n\nheatmaply(normalize(wh_matrix[, -c(1, 2, 4, 5)]),\n          dist_method = \"euclidean\",\n          hclust_method = \"ward.D\")\n\n\n\n\n\n\n\n9.5.5 Statistical approach\nIn order to determine the best clustering method and number of cluster the dend_expend() and find_k() functions of dendextend package will be used.\nFirst, the dend_expend() will be used to determine the recommended clustering method to be used.\n\nwh_d &lt;- dist(normalize(wh_matrix[, -c(1, 2, 4, 5)]), method = \"euclidean\")\ndend_expend(wh_d)[[3]]\n\n  dist_methods hclust_methods     optim\n1      unknown         ward.D 0.6137851\n2      unknown        ward.D2 0.6289186\n3      unknown         single 0.4774362\n4      unknown       complete 0.6434009\n5      unknown        average 0.6701688\n6      unknown       mcquitty 0.5020102\n7      unknown         median 0.5901833\n8      unknown       centroid 0.6338734\n\n\nThe output table shows that “average” method should be used because it gave the high optimum value.\nNext, find_k() is used to determine the optimal number of cluster.\n\nwh_clust &lt;- hclust(wh_d, method = \"average\")\nnum_k &lt;- find_k(wh_clust)\nplot(num_k)\n\n\n\n\n\n\n\n\nFigure above shows that k=3 would be good.\nWith reference to the statistical analysis results, we can prepare the code chunk as shown below.\n\nheatmaply(normalize(wh_matrix[, -c(1, 2, 4, 5)]),\n          dist_method = \"euclidean\",\n          hclust_method = \"average\",\n          k_row = 3)\n\n\n\n\n\n\n\n9.5.6 Seriation\nOne of the problems with hierarchical clustering is that it doesn’t actually place the rows in a definite order, it merely constrains the space of possible orderings. Take three items A, B and C. If you ignore reflections, there are three possible orderings: ABC, ACB, BAC. If clustering them gives you ((A+B)+C) as a tree, you know that C can’t end up between A and B, but it doesn’t tell you which way to flip the A+B cluster. It doesn’t tell you if the ABC ordering will lead to a clearer-looking heatmap than the BAC ordering.\nheatmaply uses the seriation package to find an optimal ordering of rows and columns. Optimal means to optimize the Hamiltonian path length that is restricted by the dendrogram structure. This, in other words, means to rotate the branches so that the sum of distances between each adjacent leaf (label) will be minimized. This is related to a restricted version of the travelling salesman problem.\nHere we meet our first seriation algorithm: Optimal Leaf Ordering (OLO). This algorithm starts with the output of an agglomerative clustering algorithm and produces a unique ordering, one that flips the various branches of the dendrogram around so as to minimize the sum of dissimilarities between adjacent leaves. Here is the result of applying Optimal Leaf Ordering to the same clustering result as the heatmap above.\n\nheatmaply(normalize(wh_matrix[, -c(1, 2, 4, 5)]),\n          seriate = \"OLO\")\n\n\n\n\n\nThe default options is “OLO” (Optimal leaf ordering) which optimizes the above criterion (in O(n^4)). Another option is “GW” (Gruvaeus and Wainer) which aims for the same goal but uses a potentially faster heuristic.\n\nheatmaply(normalize(wh_matrix[, -c(1, 2, 4, 5)]),\n          seriate = \"GW\")\n\n\n\n\n\nThe option “mean” gives the output we would get by default from heatmap functions in other packages such as gplots::heatmap.2.\n\nheatmaply(normalize(wh_matrix[, -c(1, 2, 4, 5)]),\n          seriate = \"mean\")\n\n\n\n\n\nThe option “none” gives us the dendrograms without any rotation that is based on the data matrix.\n\nheatmaply(normalize(wh_matrix[, -c(1, 2, 4, 5)]),\n          seriate = \"none\")\n\n\n\n\n\n\n\n9.5.7 Working with colour palettes\nThe default colour palette uses by heatmaply is viridis. heatmaply users, however, can use other colour palettes in order to improve the aestheticness and visual friendliness of the heatmap.\nIn the code chunk below, the Blues colour palette of rColorBrewer is used\n\nheatmaply(normalize(wh_matrix[, -c(1, 2, 4, 5)]),\n          seriate = \"none\",\n          colors = Blues)\n\n\n\n\n\n\n\n9.5.8 The finishing touch\nBeside providing a wide collection of arguments for meeting the statistical analysis needs, heatmaply also provides many plotting features to ensure cartographic quality heatmap can be produced.\nIn the code chunk below the following arguments are used:\n\nk_row is used to produce 5 groups.\nmargins is used to change the top margin to 60 and row margin to 200.\nfontsizw_row and fontsize_col are used to change the font size for row and column labels to 4.\nmain is used to write the main title of the plot.\nxlab and ylab are used to write the x-axis and y-axis labels respectively.\n\n\nheatmaply(normalize(wh_matrix[, -c(1, 2, 4, 5)]),\n          Colv=NA,\n          seriate = \"none\",\n          colors = Blues,\n          k_row = 5,\n          margins = c(NA,200,60,NA),\n          fontsize_row = 4,\n          fontsize_col = 5,\n          main=\"World Happiness Score and Variables by Country, 2018 \\nDataTransformation using Normalise Method\",\n          xlab = \"World Happiness Indicators\",\n          ylab = \"World Countries\"\n          )"
  }
]